{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6046e42e-66db-4dd1-8fdc-b32792bf089a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "53755e35-a63f-4f09-9159-9b76d70cb220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[12/05/22 12:36:33] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading data from <span style=\"color: #008000; text-decoration-color: #008000\">'center_out_model_spectrogram_indices'</span>           <a href=\"file:///home/ssah/bci-pipeline/lib/python3.8/site-packages/kedro/io/data_catalog.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ssah/bci-pipeline/lib/python3.8/site-packages/kedro/io/data_catalog.py#343\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">343</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"font-weight: bold\">(</span>PartitionedDataSet<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[12/05/22 12:36:33]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading data from \u001b[32m'center_out_model_spectrogram_indices'\u001b[0m           \u001b]8;id=840646;file:///home/ssah/bci-pipeline/lib/python3.8/site-packages/kedro/io/data_catalog.py\u001b\\\u001b[2mdata_catalog.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=746053;file:///home/ssah/bci-pipeline/lib/python3.8/site-packages/kedro/io/data_catalog.py#343\u001b\\\u001b[2m343\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[1m(\u001b[0mPartitionedDataSet\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m                                            \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading data from <span style=\"color: #008000; text-decoration-color: #008000\">'center_out_model_spectrogram_std_pkl'</span>           <a href=\"file:///home/ssah/bci-pipeline/lib/python3.8/site-packages/kedro/io/data_catalog.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ssah/bci-pipeline/lib/python3.8/site-packages/kedro/io/data_catalog.py#343\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">343</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"font-weight: bold\">(</span>PartitionedDataSet<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading data from \u001b[32m'center_out_model_spectrogram_std_pkl'\u001b[0m           \u001b]8;id=306430;file:///home/ssah/bci-pipeline/lib/python3.8/site-packages/kedro/io/data_catalog.py\u001b\\\u001b[2mdata_catalog.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=218787;file:///home/ssah/bci-pipeline/lib/python3.8/site-packages/kedro/io/data_catalog.py#343\u001b\\\u001b[2m343\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[1m(\u001b[0mPartitionedDataSet\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m                                            \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_data_filenames_dict = catalog.load(\"center_out_model_spectrogram_indices\")\n",
    "trial_loading_dict = catalog.load(\"center_out_model_spectrogram_std_pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "93ed71b0-d6fa-4764-b59b-f7b11dd3022d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "48daa731-8c47-46b7-a69e-e220615fed86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[12/05/22 12:36:34] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading data from <span style=\"color: #008000; text-decoration-color: #008000\">'center_out_model_filenames'</span> <span style=\"font-weight: bold\">(</span>PickleDataSet<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>  <a href=\"file:///home/ssah/bci-pipeline/lib/python3.8/site-packages/kedro/io/data_catalog.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ssah/bci-pipeline/lib/python3.8/site-packages/kedro/io/data_catalog.py#343\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">343</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[12/05/22 12:36:34]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading data from \u001b[32m'center_out_model_filenames'\u001b[0m \u001b[1m(\u001b[0mPickleDataSet\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m  \u001b]8;id=778812;file:///home/ssah/bci-pipeline/lib/python3.8/site-packages/kedro/io/data_catalog.py\u001b\\\u001b[2mdata_catalog.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=873517;file:///home/ssah/bci-pipeline/lib/python3.8/site-packages/kedro/io/data_catalog.py#343\u001b\\\u001b[2m343\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_data_filenames = catalog.load(\"center_out_model_filenames\")\n",
    "model_data_filenames = np.array(model_data_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "39ff2d21-5319-444c-a02e-585f939b049a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data_params = context.params['model_data_params']\n",
    "\n",
    "pre_stimulus_time = model_data_params['pre_stimulus_time']\n",
    "post_completion_time = model_data_params['post_completion_time']\n",
    "\n",
    "window_size = model_data_params['window_size']\n",
    "shift = model_data_params['shift']\n",
    "\n",
    "current_experiment = context.params['current_experiment']\n",
    "sessions = context.params['sessions']\n",
    "patient_id = context.params['patient_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "cab3dcfb-90be-4466-8483-31565e85264b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate_trial_filenames_list(model_data_filenames_dict):\n",
    "    trial_filenames_list = []\n",
    "    for partition_key, partition_data_func in model_data_filenames_dict.items():\n",
    "        model_data_dict = partition_data_func()\n",
    "\n",
    "        for state, trial_information_dict in model_data_dict.items():\n",
    "            session_type = trial_information_dict['session_type']\n",
    "            date = trial_information_dict['date']\n",
    "            local_trials_idx_list = trial_information_dict['local_trials_idx_list']\n",
    "            session = trial_information_dict['session']\n",
    "\n",
    "            trial_filenames_list += [f\"{session_type}_{date}_{session}_T{trial_idx}_state{state}\" for trial_idx in local_trials_idx_list]\n",
    "            \n",
    "    return trial_filenames_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "0ef19d56-17dd-4d9f-9c68-2625ebd24121",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate_train_test_split_indices(model_data_filenames_dict, model_data_filenames, model_data_params, current_experiment):\n",
    "    data_split_type = model_data_params[current_experiment]['sel_split_type']\n",
    "\n",
    "    split_type_params = model_data_params[current_experiment]['split_types'][data_split_type]\n",
    "\n",
    "    leave_out = split_type_params['leave_out']\n",
    "    randomized = split_type_params['randomized']\n",
    "    random_seed = split_type_params['random_seed']\n",
    "    sel_session_type = model_data_params[current_experiment]['sel_session_type']\n",
    "\n",
    "    np.random.seed(random_seed)\n",
    "\n",
    "    if data_split_type == 'leave_day_out':\n",
    "        dates_list = []\n",
    "        for partition_key, partition_data_func in model_data_filenames_dict.items():\n",
    "            date = partition_key.split('_')[-2]\n",
    "            session = partition_key.split('_')[-1]\n",
    "            \n",
    "            data_dict = partition_data_func()\n",
    "            \n",
    "            for state, trial_information_dict in data_dict.items():\n",
    "                if sel_session_type != trial_information_dict['session_type']:\n",
    "                    break\n",
    "                \n",
    "                if date not in dates_list:\n",
    "                    dates_list.append(date)\n",
    "                    break\n",
    "        \n",
    "        dates_list = np.array(list(set(dates_list)))\n",
    "\n",
    "        dates_list_permuted = dates_list\n",
    "        if randomized:\n",
    "            dates_list_permuted = np.random.permutation(dates_list)\n",
    "\n",
    "        test_list_dates = dates_list_permuted[:leave_out]\n",
    "        train_list_dates = dates_list_permuted[leave_out:]\n",
    "        \n",
    "        train_list = []\n",
    "        test_list = []\n",
    "        train_labels_list = []\n",
    "        test_labels_list = []\n",
    "        for partition_key, partition_data_func in model_data_filenames_dict.items():\n",
    "            date = partition_key.split('_')[-2]\n",
    "            session = partition_key.split('_')[-1]\n",
    "            \n",
    "            data_dict = partition_data_func()\n",
    "            \n",
    "            for state, trial_information_dict in data_dict.items():\n",
    "                session_type = trial_information_dict['session_type']\n",
    "                \n",
    "                if sel_session_type != session_type:\n",
    "                    continue\n",
    "                \n",
    "                if date in train_list_dates:\n",
    "                    train_list += trial_information_dict['global_trials_idx_list']\n",
    "                    train_labels_list += [state]*len(trial_information_dict['global_trials_idx_list'])\n",
    "                    \n",
    "                elif date in test_list_dates:\n",
    "                    test_list += trial_information_dict['global_trials_idx_list']\n",
    "                    test_labels_list += [state]*len(trial_information_dict['global_trials_idx_list'])\n",
    "\n",
    "    elif data_split_type == 'leave_session_out':\n",
    "        dates_and_sessions_list = []\n",
    "        for partition_key, partition_data_func in model_data_filenames_dict.items():\n",
    "            date = partition_key.split('_')[-2]\n",
    "            session = partition_key.split('_')[-1]\n",
    "            \n",
    "            data_dict = partition_data_func()\n",
    "            \n",
    "            for state, trial_information_dict in data_dict.items():\n",
    "                if sel_session_type != trial_information_dict['session_type']:\n",
    "                    break\n",
    "                \n",
    "                if {'date': date, 'session': session} not in dates_and_sessions_list:\n",
    "                    dates_and_sessions_list.append({'date': date, 'session': session})\n",
    "                    break\n",
    "\n",
    "        dates_and_sessions_list = np.array(dates_and_sessions_list)\n",
    "\n",
    "        dates_and_sessions_list_permuted = dates_and_sessions_list\n",
    "        if randomized:\n",
    "            dates_and_sessions_list_permuted = np.random.permutation(dates_and_sessions_list)\n",
    "        \n",
    "        test_list_dates_and_sessions = dates_and_sessions_list_permuted[:leave_out]\n",
    "        train_list_dates_and_sessions = dates_and_sessions_list_permuted[leave_out:]\n",
    "        \n",
    "        train_list = []\n",
    "        test_list = []\n",
    "        train_labels_list = []\n",
    "        test_labels_list = []\n",
    "        for partition_key, partition_data_func in model_data_filenames_dict.items():\n",
    "            date = partition_key.split('_')[-2]\n",
    "            session = partition_key.split('_')[-1]\n",
    "            \n",
    "            data_dict = partition_data_func ()\n",
    "            for state, trial_information_dict in data_dict.items():\n",
    "                if {'date': date, 'session': session} in train_list_dates_and_sessions:\n",
    "                    train_list += trial_information_dict['global_trials_idx_list']\n",
    "                    train_labels_list += [state]*len(trial_information_dict['global_trials_idx_list'])\n",
    "                    \n",
    "                elif {'date': date, 'session': session} in test_list_dates_and_sessions:\n",
    "                    test_list += trial_information_dict['global_trials_idx_list']\n",
    "                    test_labels_list += [state]*len(trial_information_dict['global_trials_idx_list'])\n",
    "\n",
    "    elif data_split_type == 'leave_trial_out':\n",
    "        trials_list = []\n",
    "        labels_list= []\n",
    "        for partition_key, partition_data_func in model_data_filenames_dict.items():\n",
    "            date = partition_key.split('_')[-2]\n",
    "            session = partition_key.split('_')[-1]\n",
    "            \n",
    "            data_dict = partition_data_func()\n",
    "            \n",
    "            for state, trial_information_dict in data_dict.items():\n",
    "                if sel_session_type != trial_information_dict['session_type']:\n",
    "                    break\n",
    "                    \n",
    "                trials_list += trial_information_dict['global_trials_idx_list']\n",
    "                labels_list += [state]*len(trial_information_dict['global_trials_idx_list'])\n",
    "\n",
    "        trials_list = np.array(trials_list)\n",
    "        labels_list = np.array(labels_list)\n",
    "\n",
    "        permutation_indices = np.arange(len(labels_list))\n",
    "        if randomized:\n",
    "            permutation_indices = np.random.permutation(permutation_indices)\n",
    "\n",
    "        trials_list_permuted = trials_list[permutation_indices]\n",
    "        trials_labels_list_permuted = labels_list[permutation_indices]\n",
    "        \n",
    "        test_list = trials_list_permuted[:leave_out]\n",
    "        train_list = trials_list_permuted[leave_out:]\n",
    "\n",
    "        test_labels_list = trials_labels_list_permuted[:leave_out]\n",
    "        train_labels_list = trials_labels_list_permuted[leave_out:]\n",
    "\n",
    "    \n",
    "    return {\n",
    "        'train_list_idx': np.array(train_list),\n",
    "        'test_list_idx': np.array(test_list),\n",
    "        'train_labels_list': np.array(train_labels_list),\n",
    "        'test_labels_list': np.array(test_labels_list),\n",
    "        'train_filenames': model_data_filenames[np.array(train_list)],\n",
    "        'test_filenames': model_data_filenames[np.array(test_list)]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "a98ef81c-160a-4c39-bdaf-c525b1ad1bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_indices_dict = _generate_train_test_split_indices(model_data_filenames_dict, model_data_filenames, model_data_params, current_experiment)\n",
    "\n",
    "train_list_idx = train_test_indices_dict['train_list_idx']\n",
    "test_list_idx = train_test_indices_dict['test_list_idx']\n",
    "train_labels_list = train_test_indices_dict['train_labels_list'] \n",
    "test_labels_list = train_test_indices_dict['test_labels_list']\n",
    "\n",
    "train_filenames = model_data_filenames[train_list_idx]\n",
    "test_filenames = model_data_filenames[test_list_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "fda96198-70c7-422e-884e-9fdd02ea8d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "\n",
    "def _window_spectrogram(sxx, shift, window_size):\n",
    "    \n",
    "    return np.moveaxis(sliding_window_view(sxx, window_shape=window_size, axis=1), [0, -1], [1, -2])[::shift, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "a67fe68e-7d88-4d30-b849-fd156d8c3469",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CorticomExperimentDataset(Dataset):\n",
    "    def __init__(self, trial_filenames_dict, trial_labels_list, trial_loading_dict):\n",
    "        self.trial_filenames_dict = trial_filenames_dict\n",
    "        self.trial_labels_list = trial_labels_list\n",
    "        self.trial_loading_dict = trial_loading_dict\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.trial_filenames_dict)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filename = self.trial_filenames_dict[idx]\n",
    "        \n",
    "        return self.trial_loading_dict[filename](), self.trial_labels_list[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "2b527a37-10cc-4eea-9e0b-6ceec2ab0312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and testing PyTorch datasets\n",
    "training_dataset = CorticomExperimentDataset(train_filenames, train_labels_list, trial_loading_dict)\n",
    "testing_dataset = CorticomExperimentDataset(test_filenames, test_labels_list, trial_loading_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "b26396f2-9878-4b89-b427-a78a66cf0d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_dataloader_collate(data):\n",
    "    sxx_list = []\n",
    "    labels_list = []\n",
    "    \n",
    "    for sxx, label in data:\n",
    "        windowed_sxx = _window_spectrogram(sxx, shift, window_size)\n",
    "        \n",
    "        sxx_list.append(windowed_sxx)\n",
    "        \n",
    "        # print(windowed_sxx.shape)\n",
    "        \n",
    "        labels_list += [label]*windowed_sxx.shape[0]\n",
    "    \n",
    "    windowed_sxx = np.concatenate(sxx_list)\n",
    "    labels_sxx = np.array(labels_list) - 1\n",
    "    \n",
    "    return windowed_sxx, labels_sxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "5cf4b5a6-1802-4407-885e-d9e95a8b6d22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_loader = torch.utils.data.DataLoader(training_dataset, batch_size=8, shuffle=True, collate_fn=experiment_dataloader_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "1bc44a54-efe5-4e61-b221-b81f7bcd1028",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch, labels = next(iter(training_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "6b44566a-0379-4fce-9bfb-a6d0dcc8e05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "09d5cfaa-538c-48dc-b831-8aacf2f5ad05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch models inherit from torch.nn.Module\n",
    "class GarmentClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GarmentClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(10, 10, (1,3), stride=(1,1), bias=False)\n",
    "        self.conv2 = nn.Conv2d(10, 10, (1,3), stride=(1,1), bias=False )\n",
    "        self.conv3 = nn.Conv2d(10, 10, (1,3), stride=(1,1), bias=False)\n",
    "        self.conv4 = nn.Conv2d(10, 10, (1,3), stride=(1,1), bias=False)\n",
    "        self.conv5 = nn.Conv2d(10, 10, (1,6), stride=(1,1), bias=False)\n",
    "        \n",
    "        self.lstm = nn.LSTM(128, 64, batch_first=True, bias=False)\n",
    "        self.lstm2 = nn.LSTM(64, 32, batch_first=True, bias=False)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d((1, 2), (1, 2))\n",
    "        self.fc1 = nn.Linear(32, 16, bias=False)\n",
    "        self.fc2 = nn.Linear(16, 8, bias=False)\n",
    "        \n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.moveaxis(x, (1, 3), (3, 2))\n",
    "        x = F.elu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.elu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.elu(self.conv3(x))\n",
    "        x = self.pool(F.elu(x))\n",
    "        x = self.conv4(x)\n",
    "        x = self.pool(F.elu(x))\n",
    "        x = F.elu(self.conv5(x))\n",
    "        x = torch.squeeze(x, dim=-1)\n",
    "        x = self.lstm(x)\n",
    "        x = x[0]\n",
    "        x = self.lstm2(x)\n",
    "        x = x[0][:, -1, :]\n",
    "        x = x.reshape(-1, 32)\n",
    "        x = F.elu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        # x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "model = GarmentClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "561d0df7-19b6-4d6c-babf-be6c098ecf46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "==========================================================================================\n",
       "Layer <span style=\"font-weight: bold\">(</span>typ<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:de</span>pth-idx<span style=\"font-weight: bold\">)</span>                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "GarmentClassifier                        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span><span style=\"font-weight: bold\">]</span>                    --\n",
       "├─Conv2d: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>                            <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">127</span><span style=\"font-weight: bold\">]</span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">300</span>\n",
       "├─MaxPool2d: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>                         <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">63</span><span style=\"font-weight: bold\">]</span>          --\n",
       "├─Conv2d: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>                            <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">61</span><span style=\"font-weight: bold\">]</span>          <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">300</span>\n",
       "├─MaxPool2d: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>                         <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span><span style=\"font-weight: bold\">]</span>          --\n",
       "├─Conv2d: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>                            <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span><span style=\"font-weight: bold\">]</span>          <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">300</span>\n",
       "├─MaxPool2d: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>                         <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span><span style=\"font-weight: bold\">]</span>          --\n",
       "├─Conv2d: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>                            <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span><span style=\"font-weight: bold\">]</span>          <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">300</span>\n",
       "├─MaxPool2d: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>                         <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span><span style=\"font-weight: bold\">]</span>           --\n",
       "├─Conv2d: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span>                            <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span>           <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">600</span>\n",
       "├─LSTM: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>                             <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span><span style=\"font-weight: bold\">]</span>               <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">49</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">152</span>\n",
       "├─LSTM: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>                             <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span><span style=\"font-weight: bold\">]</span>               <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">288</span>\n",
       "├─Linear: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>                           <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span><span style=\"font-weight: bold\">]</span>                   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span>\n",
       "├─Linear: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span>                           <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span><span style=\"font-weight: bold\">]</span>                    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>\n",
       "==========================================================================================\n",
       "Total params: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">63</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">880</span>\n",
       "Trainable params: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">63</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">880</span>\n",
       "Non-trainable params: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "Total mult-adds <span style=\"font-weight: bold\">(</span>M<span style=\"font-weight: bold\">)</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.45</span>\n",
       "==========================================================================================\n",
       "Input size <span style=\"font-weight: bold\">(</span>MB<span style=\"font-weight: bold\">)</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.66</span>\n",
       "Forward/backward pass size <span style=\"font-weight: bold\">(</span>MB<span style=\"font-weight: bold\">)</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.35</span>\n",
       "Params size <span style=\"font-weight: bold\">(</span>MB<span style=\"font-weight: bold\">)</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.26</span>\n",
       "Estimated Total Size <span style=\"font-weight: bold\">(</span>MB<span style=\"font-weight: bold\">)</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.27</span>\n",
       "==========================================================================================\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "==========================================================================================\n",
       "Layer \u001b[1m(\u001b[0mtyp\u001b[1;92me:de\u001b[0mpth-idx\u001b[1m)\u001b[0m                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "GarmentClassifier                        \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m8\u001b[0m\u001b[1m]\u001b[0m                    --\n",
       "├─Conv2d: \u001b[1;36m1\u001b[0m-\u001b[1;36m1\u001b[0m                            \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m10\u001b[0m, \u001b[1;36m128\u001b[0m, \u001b[1;36m127\u001b[0m\u001b[1m]\u001b[0m         \u001b[1;36m300\u001b[0m\n",
       "├─MaxPool2d: \u001b[1;36m1\u001b[0m-\u001b[1;36m2\u001b[0m                         \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m10\u001b[0m, \u001b[1;36m128\u001b[0m, \u001b[1;36m63\u001b[0m\u001b[1m]\u001b[0m          --\n",
       "├─Conv2d: \u001b[1;36m1\u001b[0m-\u001b[1;36m3\u001b[0m                            \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m10\u001b[0m, \u001b[1;36m128\u001b[0m, \u001b[1;36m61\u001b[0m\u001b[1m]\u001b[0m          \u001b[1;36m300\u001b[0m\n",
       "├─MaxPool2d: \u001b[1;36m1\u001b[0m-\u001b[1;36m4\u001b[0m                         \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m10\u001b[0m, \u001b[1;36m128\u001b[0m, \u001b[1;36m30\u001b[0m\u001b[1m]\u001b[0m          --\n",
       "├─Conv2d: \u001b[1;36m1\u001b[0m-\u001b[1;36m5\u001b[0m                            \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m10\u001b[0m, \u001b[1;36m128\u001b[0m, \u001b[1;36m28\u001b[0m\u001b[1m]\u001b[0m          \u001b[1;36m300\u001b[0m\n",
       "├─MaxPool2d: \u001b[1;36m1\u001b[0m-\u001b[1;36m6\u001b[0m                         \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m10\u001b[0m, \u001b[1;36m128\u001b[0m, \u001b[1;36m14\u001b[0m\u001b[1m]\u001b[0m          --\n",
       "├─Conv2d: \u001b[1;36m1\u001b[0m-\u001b[1;36m7\u001b[0m                            \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m10\u001b[0m, \u001b[1;36m128\u001b[0m, \u001b[1;36m12\u001b[0m\u001b[1m]\u001b[0m          \u001b[1;36m300\u001b[0m\n",
       "├─MaxPool2d: \u001b[1;36m1\u001b[0m-\u001b[1;36m8\u001b[0m                         \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m10\u001b[0m, \u001b[1;36m128\u001b[0m, \u001b[1;36m6\u001b[0m\u001b[1m]\u001b[0m           --\n",
       "├─Conv2d: \u001b[1;36m1\u001b[0m-\u001b[1;36m9\u001b[0m                            \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m10\u001b[0m, \u001b[1;36m128\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m           \u001b[1;36m600\u001b[0m\n",
       "├─LSTM: \u001b[1;36m1\u001b[0m-\u001b[1;36m10\u001b[0m                             \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m10\u001b[0m, \u001b[1;36m64\u001b[0m\u001b[1m]\u001b[0m               \u001b[1;36m49\u001b[0m,\u001b[1;36m152\u001b[0m\n",
       "├─LSTM: \u001b[1;36m1\u001b[0m-\u001b[1;36m11\u001b[0m                             \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m10\u001b[0m, \u001b[1;36m32\u001b[0m\u001b[1m]\u001b[0m               \u001b[1;36m12\u001b[0m,\u001b[1;36m288\u001b[0m\n",
       "├─Linear: \u001b[1;36m1\u001b[0m-\u001b[1;36m12\u001b[0m                           \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m16\u001b[0m\u001b[1m]\u001b[0m                   \u001b[1;36m512\u001b[0m\n",
       "├─Linear: \u001b[1;36m1\u001b[0m-\u001b[1;36m13\u001b[0m                           \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m8\u001b[0m\u001b[1m]\u001b[0m                    \u001b[1;36m128\u001b[0m\n",
       "==========================================================================================\n",
       "Total params: \u001b[1;36m63\u001b[0m,\u001b[1;36m880\u001b[0m\n",
       "Trainable params: \u001b[1;36m63\u001b[0m,\u001b[1;36m880\u001b[0m\n",
       "Non-trainable params: \u001b[1;36m0\u001b[0m\n",
       "Total mult-adds \u001b[1m(\u001b[0mM\u001b[1m)\u001b[0m: \u001b[1;36m9.45\u001b[0m\n",
       "==========================================================================================\n",
       "Input size \u001b[1m(\u001b[0mMB\u001b[1m)\u001b[0m: \u001b[1;36m0.66\u001b[0m\n",
       "Forward/backward pass size \u001b[1m(\u001b[0mMB\u001b[1m)\u001b[0m: \u001b[1;36m2.35\u001b[0m\n",
       "Params size \u001b[1m(\u001b[0mMB\u001b[1m)\u001b[0m: \u001b[1;36m0.26\u001b[0m\n",
       "Estimated Total Size \u001b[1m(\u001b[0mMB\u001b[1m)\u001b[0m: \u001b[1;36m3.27\u001b[0m\n",
       "==========================================================================================\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(model, input_size=(1, 129, 10, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "1b4a9c3a-fb4e-43bf-8752-ffdc23ee1a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "6c967b70-4067-472b-b97b-9cdd3cce5bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "5a3d535d-4c07-4169-aae0-dceb060a3d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    # Here, we use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "    for i, data in enumerate(training_loader):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data\n",
    "        \n",
    "        labels_pyt = torch.from_numpy(labels).type(torch.float)\n",
    "        inputs_pyt = torch.from_numpy(inputs).type(torch.float)\n",
    "        \n",
    "        len_batch = labels_pyt.shape[0]\n",
    "        \n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs_pyt)\n",
    "        \n",
    "        _, pred = torch.max(outputs, 1)\n",
    "        \n",
    "        # print(inputs_pyt[0, 0, 0, 0])\n",
    "        # print(inputs_pyt[-1, 0, 0, 0])\n",
    "        \n",
    "        print(outputs[:2, :])\n",
    "        print(np.unique(pred))\n",
    "        # print(pred)\n",
    "        # print(labels_pyt)\n",
    "        \n",
    "        print((pred==labels_pyt).sum()/len(pred))\n",
    "        \n",
    "        # print(outputs.shape)\n",
    "        # print(outputs.type())\n",
    "        # print(labels_pyt.type())\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels_pyt.long())\n",
    "        print(loss)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        # if i % 10 == 0:\n",
    "        last_loss = running_loss / len_batch # loss per batch\n",
    "        print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "        # tb_x = epoch_index * len(training_loader) + i + 1\n",
    "        # tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "        running_loss = 0.\n",
    "\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "97deb77e-1535-414f-a73a-f9f2be054273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "tensor([[-0.0003,  0.0007, -0.0013, -0.0005, -0.0013,  0.0003, -0.0022,  0.0007],\n",
      "        [ 0.0004, -0.0001, -0.0005,  0.0016, -0.0006, -0.0005, -0.0013,  0.0005]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 7]\n",
      "tensor(0.1308)\n",
      "tensor(2.0796, grad_fn=<NllLossBackward0>)\n",
      "  batch 1 loss: 0.0005036461119445077\n",
      "tensor([[-0.0024,  0.0013, -0.0019, -0.0002, -0.0033,  0.0018, -0.0020,  0.0015],\n",
      "        [-0.0015,  0.0018, -0.0004, -0.0018, -0.0031,  0.0004, -0.0021,  0.0013]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[1 5 7]\n",
      "tensor(0.2314)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 2 loss: 0.0004969826733860869\n",
      "tensor([[-0.0040,  0.0006, -0.0009, -0.0038, -0.0069,  0.0027, -0.0044,  0.0056],\n",
      "        [-0.0033,  0.0011, -0.0019, -0.0055, -0.0062,  0.0029, -0.0050,  0.0057]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[7]\n",
      "tensor(0.)\n",
      "tensor(2.0807, grad_fn=<NllLossBackward0>)\n",
      "  batch 3 loss: 0.00050307934242706\n",
      "tensor([[-3.6683e-03, -5.4659e-05,  2.0200e-03, -3.9376e-03, -6.0089e-03,\n",
      "          4.5819e-04, -2.8375e-03,  5.3008e-03],\n",
      "        [-3.7825e-03, -8.7036e-04,  1.5595e-03, -3.6312e-03, -6.8886e-03,\n",
      "          5.6921e-04, -4.1019e-03,  6.6483e-03]], grad_fn=<SliceBackward0>)\n",
      "[7]\n",
      "tensor(0.)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 4 loss: 0.0004983337383146855\n",
      "tensor([[-3.5496e-03,  5.0910e-04,  3.5735e-03, -3.8471e-03, -3.9377e-03,\n",
      "         -3.8404e-04, -2.3113e-03,  4.9724e-03],\n",
      "        [-3.1635e-03,  2.0792e-05,  3.4662e-03, -4.2937e-03, -3.9916e-03,\n",
      "         -1.2662e-03, -3.2189e-03,  4.6219e-03]], grad_fn=<SliceBackward0>)\n",
      "[2 7]\n",
      "tensor(0.0336)\n",
      "tensor(2.0807, grad_fn=<NllLossBackward0>)\n",
      "  batch 5 loss: 0.0005035606958512992\n",
      "tensor([[-0.0030, -0.0008,  0.0039, -0.0031, -0.0028, -0.0021, -0.0018,  0.0029],\n",
      "        [-0.0025, -0.0002,  0.0035, -0.0034, -0.0015, -0.0019, -0.0017,  0.0030]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[2 7]\n",
      "tensor(0.1234)\n",
      "tensor(2.0793, grad_fn=<NllLossBackward0>)\n",
      "  batch 6 loss: 0.0005032068762174534\n",
      "tensor([[-3.5528e-03, -6.4383e-05,  5.4158e-03, -4.1714e-03,  1.6128e-03,\n",
      "         -3.2329e-03,  9.0171e-04,  2.0155e-03],\n",
      "        [-3.5164e-03, -9.5122e-05,  5.8450e-03, -2.8759e-03,  6.8381e-04,\n",
      "         -3.0326e-03,  9.0007e-04,  2.2311e-03]], grad_fn=<SliceBackward0>)\n",
      "[2 7]\n",
      "tensor(0.)\n",
      "tensor(2.0813, grad_fn=<NllLossBackward0>)\n",
      "  batch 7 loss: 0.0005046872116777067\n",
      "tensor([[-0.0024, -0.0003,  0.0043, -0.0009, -0.0003, -0.0019,  0.0014,  0.0012],\n",
      "        [-0.0023, -0.0005,  0.0026, -0.0008, -0.0002, -0.0012,  0.0008,  0.0017]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[2 4 6 7]\n",
      "tensor(0.1282)\n",
      "tensor(2.0798, grad_fn=<NllLossBackward0>)\n",
      "  batch 8 loss: 0.0004985114186287841\n",
      "tensor([[-6.3842e-04, -7.0977e-05,  1.3283e-03, -6.6042e-04,  2.1875e-03,\n",
      "         -9.7940e-04,  1.2743e-03,  4.5400e-04],\n",
      "        [-1.2180e-03,  2.4560e-04,  1.6866e-03, -9.3527e-04,  8.3180e-04,\n",
      "         -4.7286e-04,  5.2046e-04, -8.3252e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1382)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 9 loss: 0.0005022917392749142\n",
      "tensor([[-4.7795e-05,  3.6064e-04, -2.0909e-04, -8.2181e-05, -8.1830e-04,\n",
      "          7.9785e-04,  7.4088e-04, -5.0585e-04],\n",
      "        [ 8.2900e-05,  2.2024e-04, -1.1910e-03, -7.4611e-04, -9.3205e-04,\n",
      "          1.2196e-03,  4.3305e-04,  1.6189e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1209)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 10 loss: 0.0004989101538960169\n",
      "tensor([[ 7.2424e-04, -3.7405e-04, -3.4510e-03,  1.2188e-03, -2.9448e-04,\n",
      "          1.8363e-03, -1.9593e-04, -7.1891e-04],\n",
      "        [ 2.1243e-03, -9.1757e-04, -5.1122e-03,  9.5091e-04, -1.0811e-03,\n",
      "          2.6062e-03, -8.7193e-04, -1.3287e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 3 4 5 6 7]\n",
      "tensor(0.0447)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 11 loss: 0.0004999810154835288\n",
      "tensor([[ 3.3011e-03, -4.3942e-04, -4.4325e-03,  1.3027e-03, -7.3714e-04,\n",
      "          1.1434e-03, -8.9262e-04, -9.8418e-04],\n",
      "        [ 2.9828e-03, -1.3581e-03, -4.4355e-03,  1.9091e-03, -9.3904e-04,\n",
      "          1.8302e-03, -1.1620e-03,  2.6594e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 3 5]\n",
      "tensor(0.2476)\n",
      "tensor(2.0793, grad_fn=<NllLossBackward0>)\n",
      "  batch 12 loss: 0.0005032139733823202\n",
      "tensor([[ 0.0039, -0.0010, -0.0057,  0.0022, -0.0021,  0.0025, -0.0019,  0.0004],\n",
      "        [ 0.0037, -0.0006, -0.0066,  0.0007, -0.0013,  0.0033, -0.0019,  0.0005]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[0 3 5]\n",
      "tensor(0.0336)\n",
      "tensor(2.0800, grad_fn=<NllLossBackward0>)\n",
      "  batch 13 loss: 0.0005059553683166578\n",
      "tensor([[ 0.0037, -0.0004, -0.0073, -0.0004, -0.0015,  0.0044, -0.0021,  0.0008],\n",
      "        [ 0.0044, -0.0008, -0.0069,  0.0005, -0.0019,  0.0032, -0.0024,  0.0002]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[0 5]\n",
      "tensor(0.0671)\n",
      "tensor(2.0790, grad_fn=<NllLossBackward0>)\n",
      "  batch 14 loss: 0.000499770102592615\n",
      "tensor([[ 0.0054, -0.0005, -0.0098,  0.0015, -0.0043,  0.0062, -0.0042,  0.0009],\n",
      "        [ 0.0053, -0.0008, -0.0097,  0.0012, -0.0045,  0.0060, -0.0039,  0.0013]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[0 5]\n",
      "tensor(0.)\n",
      "tensor(2.0811, grad_fn=<NllLossBackward0>)\n",
      "  batch 15 loss: 0.000500388660233707\n",
      "tensor([[ 5.3547e-03,  8.6747e-04, -9.8512e-03,  3.6639e-04, -3.5504e-03,\n",
      "          5.4585e-03, -3.2519e-03,  4.1807e-05],\n",
      "        [ 7.0084e-03,  8.8011e-04, -1.0646e-02,  6.8123e-04, -2.8950e-03,\n",
      "          5.6866e-03, -4.3560e-03,  3.3962e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 5]\n",
      "tensor(0.0749)\n",
      "tensor(2.0812, grad_fn=<NllLossBackward0>)\n",
      "  batch 16 loss: 0.0004962267168488\n",
      "tensor([[ 0.0045,  0.0003, -0.0084,  0.0009, -0.0033,  0.0051, -0.0033,  0.0009],\n",
      "        [ 0.0046,  0.0001, -0.0069,  0.0005, -0.0030,  0.0039, -0.0039,  0.0012]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[0 5]\n",
      "tensor(0.2448)\n",
      "tensor(2.0769, grad_fn=<NllLossBackward0>)\n",
      "  batch 17 loss: 0.0005014185051248017\n",
      "tensor([[ 0.0049,  0.0013, -0.0081,  0.0001, -0.0038,  0.0058, -0.0043,  0.0009],\n",
      "        [ 0.0053,  0.0015, -0.0077, -0.0007, -0.0023,  0.0051, -0.0033,  0.0003]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[0 5]\n",
      "tensor(0.2201)\n",
      "tensor(2.0778, grad_fn=<NllLossBackward0>)\n",
      "  batch 18 loss: 0.0005024965902049423\n",
      "tensor([[ 0.0074,  0.0016, -0.0108, -0.0013, -0.0042,  0.0063, -0.0067,  0.0016],\n",
      "        [ 0.0069,  0.0006, -0.0096, -0.0003, -0.0038,  0.0048, -0.0061,  0.0013]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[0 5]\n",
      "tensor(0.0978)\n",
      "tensor(2.0812, grad_fn=<NllLossBackward0>)\n",
      "  batch 19 loss: 0.0004941230712339975\n",
      "tensor([[ 5.9618e-03,  1.8180e-03, -9.3096e-03, -1.6213e-03, -1.5927e-03,\n",
      "          4.8120e-03, -4.5297e-03,  8.1049e-04],\n",
      "        [ 5.9673e-03,  1.8978e-03, -9.8615e-03, -1.4519e-06, -3.5306e-03,\n",
      "          6.1402e-03, -5.0340e-03,  5.9087e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 5]\n",
      "tensor(0.0112)\n",
      "tensor(2.0791, grad_fn=<NllLossBackward0>)\n",
      "  batch 20 loss: 0.0004940791615061887\n",
      "tensor([[ 0.0074,  0.0014, -0.0109, -0.0006, -0.0043,  0.0056, -0.0076,  0.0025],\n",
      "        [ 0.0080,  0.0024, -0.0118, -0.0011, -0.0030,  0.0064, -0.0072,  0.0014]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[0 5]\n",
      "tensor(0.)\n",
      "tensor(2.0811, grad_fn=<NllLossBackward0>)\n",
      "  batch 21 loss: 0.0004969302426094995\n",
      "tensor([[ 0.0082,  0.0019, -0.0112, -0.0007, -0.0036,  0.0064, -0.0076,  0.0021],\n",
      "        [ 0.0075,  0.0019, -0.0096, -0.0014, -0.0041,  0.0056, -0.0068,  0.0016]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[0 5]\n",
      "tensor(0.2573)\n",
      "tensor(2.0762, grad_fn=<NllLossBackward0>)\n",
      "  batch 22 loss: 0.0005006588939761495\n",
      "tensor([[ 0.0077,  0.0022, -0.0106, -0.0005, -0.0035,  0.0053, -0.0081,  0.0015],\n",
      "        [ 0.0090,  0.0020, -0.0111, -0.0006, -0.0042,  0.0059, -0.0091,  0.0019]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[0 5]\n",
      "tensor(0.2489)\n",
      "tensor(2.0783, grad_fn=<NllLossBackward0>)\n",
      "  batch 23 loss: 0.000500684415136754\n",
      "tensor([[ 0.0093,  0.0032, -0.0127, -0.0012, -0.0033,  0.0068, -0.0096,  0.0022],\n",
      "        [ 0.0084,  0.0025, -0.0119, -0.0007, -0.0035,  0.0066, -0.0088,  0.0021]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[0 5]\n",
      "tensor(0.1249)\n",
      "tensor(2.0786, grad_fn=<NllLossBackward0>)\n",
      "  batch 24 loss: 0.0005011080316085595\n",
      "tensor([[ 0.0097,  0.0036, -0.0146, -0.0013, -0.0037,  0.0079, -0.0104,  0.0020],\n",
      "        [ 0.0089,  0.0034, -0.0136, -0.0008, -0.0031,  0.0073, -0.0100,  0.0023]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[0 5]\n",
      "tensor(0.1241)\n",
      "tensor(2.0823, grad_fn=<NllLossBackward0>)\n",
      "  batch 25 loss: 0.0005017644813261837\n",
      "tensor([[ 0.0116,  0.0035, -0.0157, -0.0009, -0.0027,  0.0080, -0.0107,  0.0015],\n",
      "        [ 0.0122,  0.0043, -0.0168, -0.0011, -0.0031,  0.0081, -0.0117,  0.0015]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[0]\n",
      "tensor(0.1236)\n",
      "tensor(2.0813, grad_fn=<NllLossBackward0>)\n",
      "  batch 26 loss: 0.000502482409180218\n",
      "tensor([[ 0.0104,  0.0042, -0.0151, -0.0023, -0.0018,  0.0071, -0.0107,  0.0010],\n",
      "        [ 0.0121,  0.0044, -0.0171, -0.0018, -0.0011,  0.0074, -0.0108,  0.0013]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[0]\n",
      "tensor(0.1239)\n",
      "tensor(2.0810, grad_fn=<NllLossBackward0>)\n",
      "  batch 27 loss: 0.0004995224055795216\n",
      "tensor([[ 0.0103,  0.0051, -0.0138, -0.0032, -0.0012,  0.0069, -0.0099,  0.0007],\n",
      "        [ 0.0105,  0.0049, -0.0149, -0.0026, -0.0009,  0.0077, -0.0098,  0.0005]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[0]\n",
      "tensor(0.1256)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 28 loss: 0.0005003574722884823\n",
      "tensor([[ 1.0427e-02,  3.8907e-03, -1.3849e-02, -2.2668e-03, -4.9648e-04,\n",
      "          6.0534e-03, -9.9932e-03,  8.4097e-04],\n",
      "        [ 1.0570e-02,  4.6233e-03, -1.4428e-02, -2.8228e-03,  6.6420e-05,\n",
      "          6.7955e-03, -9.7400e-03,  2.7128e-04]], grad_fn=<SliceBackward0>)\n",
      "[0]\n",
      "tensor(0.)\n",
      "tensor(2.0756, grad_fn=<NllLossBackward0>)\n",
      "  batch 29 loss: 0.0005008613395875024\n",
      "tensor([[ 0.0106,  0.0054, -0.0142, -0.0029,  0.0015,  0.0064, -0.0091, -0.0007],\n",
      "        [ 0.0108,  0.0057, -0.0144, -0.0037,  0.0013,  0.0068, -0.0096, -0.0013]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[0]\n",
      "tensor(0.)\n",
      "tensor(2.0808, grad_fn=<NllLossBackward0>)\n",
      "  batch 30 loss: 0.0004983893982664554\n",
      "tensor([[ 0.0108,  0.0071, -0.0151, -0.0048,  0.0037,  0.0072, -0.0089, -0.0014],\n",
      "        [ 0.0104,  0.0069, -0.0136, -0.0045,  0.0032,  0.0064, -0.0077, -0.0021]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[0]\n",
      "tensor(0.1236)\n",
      "tensor(2.0758, grad_fn=<NllLossBackward0>)\n",
      "  batch 31 loss: 0.0005009150758213058\n",
      "tensor([[ 0.0114,  0.0088, -0.0185, -0.0056,  0.0048,  0.0086, -0.0101, -0.0019],\n",
      "        [ 0.0123,  0.0085, -0.0186, -0.0056,  0.0054,  0.0083, -0.0105, -0.0024]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[0]\n",
      "tensor(0.1241)\n",
      "tensor(2.0790, grad_fn=<NllLossBackward0>)\n",
      "  batch 32 loss: 0.00050011580455524\n",
      "tensor([[ 0.0142,  0.0116, -0.0224, -0.0059,  0.0081,  0.0102, -0.0105, -0.0033],\n",
      "        [ 0.0125,  0.0120, -0.0208, -0.0065,  0.0080,  0.0103, -0.0094, -0.0044]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[0 1]\n",
      "tensor(0.1260)\n",
      "tensor(2.0796, grad_fn=<NllLossBackward0>)\n",
      "  batch 33 loss: 0.0004982244585710789\n",
      "tensor([[ 0.0121,  0.0095, -0.0196, -0.0054,  0.0090,  0.0082, -0.0096, -0.0033],\n",
      "        [ 0.0128,  0.0111, -0.0208, -0.0062,  0.0087,  0.0088, -0.0099, -0.0039]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[0 1]\n",
      "tensor(0.1236)\n",
      "tensor(2.0831, grad_fn=<NllLossBackward0>)\n",
      "  batch 34 loss: 0.000500032035307534\n",
      "tensor([[ 0.0137,  0.0110, -0.0234, -0.0053,  0.0092,  0.0104, -0.0110, -0.0034],\n",
      "        [ 0.0133,  0.0114, -0.0230, -0.0053,  0.0091,  0.0106, -0.0108, -0.0037]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[0 1]\n",
      "tensor(0.2397)\n",
      "tensor(2.0732, grad_fn=<NllLossBackward0>)\n",
      "  batch 35 loss: 0.0004983711701173048\n",
      "tensor([[ 0.0138,  0.0127, -0.0250, -0.0053,  0.0094,  0.0114, -0.0112, -0.0046],\n",
      "        [ 0.0139,  0.0131, -0.0259, -0.0046,  0.0094,  0.0121, -0.0107, -0.0055]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[0 1]\n",
      "tensor(0.2489)\n",
      "tensor(2.0719, grad_fn=<NllLossBackward0>)\n",
      "  batch 36 loss: 0.0004997382805764934\n",
      "tensor([[ 0.0206,  0.0170, -0.0355, -0.0065,  0.0125,  0.0162, -0.0140, -0.0060],\n",
      "        [ 0.0187,  0.0171, -0.0335, -0.0076,  0.0116,  0.0156, -0.0139, -0.0059]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[0 1 5]\n",
      "tensor(0.2461)\n",
      "tensor(2.0789, grad_fn=<NllLossBackward0>)\n",
      "  batch 37 loss: 0.0005015447430213772\n",
      "tensor([[ 0.0206,  0.0175, -0.0360, -0.0047,  0.0124,  0.0174, -0.0169, -0.0065],\n",
      "        [ 0.0199,  0.0167, -0.0349, -0.0047,  0.0120,  0.0163, -0.0170, -0.0063]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[0]\n",
      "tensor(0.2493)\n",
      "tensor(2.0747, grad_fn=<NllLossBackward0>)\n",
      "  batch 38 loss: 0.0004992003160904416\n",
      "tensor([[ 0.0246,  0.0196, -0.0430, -0.0039,  0.0129,  0.0203, -0.0200, -0.0090],\n",
      "        [ 0.0254,  0.0201, -0.0429, -0.0037,  0.0131,  0.0201, -0.0206, -0.0087]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[0]\n",
      "tensor(0.)\n",
      "tensor(2.0853, grad_fn=<NllLossBackward0>)\n",
      "  batch 39 loss: 0.0004997067733717113\n",
      "tensor([[ 0.0299,  0.0227, -0.0501, -0.0020,  0.0129,  0.0242, -0.0265, -0.0090],\n",
      "        [ 0.0315,  0.0234, -0.0508, -0.0025,  0.0143,  0.0235, -0.0264, -0.0096]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[0]\n",
      "tensor(0.2524)\n",
      "tensor(2.0745, grad_fn=<NllLossBackward0>)\n",
      "  batch 40 loss: 0.0005015691659436696\n",
      "tensor([[ 0.0367,  0.0253, -0.0581,  0.0025,  0.0129,  0.0264, -0.0296, -0.0126],\n",
      "        [ 0.0358,  0.0239, -0.0560,  0.0025,  0.0132,  0.0261, -0.0289, -0.0117]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[0]\n",
      "tensor(0.)\n",
      "tensor(2.0834, grad_fn=<NllLossBackward0>)\n",
      "  batch 41 loss: 0.0005032389636200984\n",
      "tensor([[ 0.0392,  0.0269, -0.0647,  0.0044,  0.0137,  0.0293, -0.0305, -0.0164],\n",
      "        [ 0.0388,  0.0269, -0.0640,  0.0047,  0.0132,  0.0290, -0.0300, -0.0152]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[0]\n",
      "tensor(0.1246)\n",
      "tensor(2.0989, grad_fn=<NllLossBackward0>)\n",
      "  batch 42 loss: 0.0005050369245255648\n",
      "tensor([[ 0.0348,  0.0232, -0.0569,  0.0068,  0.0103,  0.0260, -0.0272, -0.0133],\n",
      "        [ 0.0344,  0.0238, -0.0567,  0.0065,  0.0094,  0.0265, -0.0279, -0.0131]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[0]\n",
      "tensor(0.)\n",
      "tensor(2.0940, grad_fn=<NllLossBackward0>)\n",
      "  batch 43 loss: 0.0005045733394393001\n",
      "tensor([[ 0.0276,  0.0184, -0.0474,  0.0084,  0.0057,  0.0233, -0.0228, -0.0108],\n",
      "        [ 0.0279,  0.0186, -0.0474,  0.0083,  0.0062,  0.0225, -0.0228, -0.0115]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[0]\n",
      "tensor(0.1254)\n",
      "tensor(2.0857, grad_fn=<NllLossBackward0>)\n",
      "  batch 44 loss: 0.0005028261627962413\n",
      "tensor([[ 0.0240,  0.0152, -0.0403,  0.0091,  0.0026,  0.0198, -0.0204, -0.0097],\n",
      "        [ 0.0241,  0.0151, -0.0404,  0.0095,  0.0020,  0.0201, -0.0201, -0.0103]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[0]\n",
      "tensor(0.1271)\n",
      "tensor(2.0940, grad_fn=<NllLossBackward0>)\n",
      "  batch 45 loss: 0.0005040860945178617\n",
      "tensor([[ 0.0183,  0.0116, -0.0309,  0.0073,  0.0012,  0.0155, -0.0167, -0.0073],\n",
      "        [ 0.0190,  0.0117, -0.0316,  0.0085,  0.0007,  0.0151, -0.0169, -0.0080]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[0]\n",
      "tensor(0.1230)\n",
      "tensor(2.0826, grad_fn=<NllLossBackward0>)\n",
      "  batch 46 loss: 0.000496341116207912\n",
      "tensor([[ 0.0149,  0.0086, -0.0241,  0.0061, -0.0008,  0.0117, -0.0153, -0.0053],\n",
      "        [ 0.0152,  0.0087, -0.0252,  0.0068, -0.0005,  0.0129, -0.0154, -0.0055]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[0]\n",
      "tensor(0.1258)\n",
      "tensor(2.0785, grad_fn=<NllLossBackward0>)\n",
      "  batch 47 loss: 0.000500847575176193\n",
      "tensor([[ 0.0119,  0.0063, -0.0186,  0.0061, -0.0013,  0.0095, -0.0118, -0.0037],\n",
      "        [ 0.0129,  0.0068, -0.0197,  0.0058, -0.0004,  0.0098, -0.0121, -0.0040]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[0 5]\n",
      "tensor(0.1230)\n",
      "tensor(2.0814, grad_fn=<NllLossBackward0>)\n",
      "  batch 48 loss: 0.0005002055022613958\n",
      "tensor([[ 0.0110,  0.0045, -0.0159,  0.0058, -0.0016,  0.0080, -0.0100, -0.0035],\n",
      "        [ 0.0099,  0.0050, -0.0150,  0.0057, -0.0019,  0.0076, -0.0099, -0.0027]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[0 5]\n",
      "tensor(0.1249)\n",
      "tensor(2.0812, grad_fn=<NllLossBackward0>)\n",
      "  batch 49 loss: 0.0005019696737566376\n",
      "tensor([[ 0.0077,  0.0029, -0.0117,  0.0044, -0.0010,  0.0059, -0.0083, -0.0021],\n",
      "        [ 0.0070,  0.0028, -0.0106,  0.0046, -0.0015,  0.0058, -0.0074, -0.0020]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[0 5]\n",
      "tensor(0.0002)\n",
      "tensor(2.0825, grad_fn=<NllLossBackward0>)\n",
      "  batch 50 loss: 0.0005035093144245259\n",
      "tensor([[ 0.0064,  0.0025, -0.0095,  0.0037, -0.0016,  0.0052, -0.0070, -0.0018],\n",
      "        [ 0.0053,  0.0022, -0.0088,  0.0034, -0.0014,  0.0049, -0.0061, -0.0016]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[0 5]\n",
      "tensor(0.0024)\n",
      "tensor(2.0804, grad_fn=<NllLossBackward0>)\n",
      "  batch 51 loss: 0.0005042161169528268\n",
      "tensor([[ 0.0044,  0.0014, -0.0069,  0.0027, -0.0015,  0.0028, -0.0051, -0.0015],\n",
      "        [ 0.0039,  0.0009, -0.0061,  0.0024, -0.0012,  0.0030, -0.0051, -0.0007]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[0 3 5]\n",
      "tensor(0.1260)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 52 loss: 0.0005020209984293541\n",
      "tensor([[ 0.0040,  0.0006, -0.0053,  0.0018, -0.0006,  0.0026, -0.0040, -0.0007],\n",
      "        [ 0.0036,  0.0008, -0.0050,  0.0020, -0.0004,  0.0026, -0.0038, -0.0007]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[0 3 5]\n",
      "tensor(0.2534)\n",
      "tensor(2.0789, grad_fn=<NllLossBackward0>)\n",
      "  batch 53 loss: 0.0005026236032378974\n",
      "tensor([[ 2.4089e-03,  7.3275e-04, -3.2370e-03,  1.5950e-03, -3.9783e-04,\n",
      "          1.9910e-03, -2.1634e-03,  1.3024e-04],\n",
      "        [ 2.2780e-03,  2.8459e-04, -4.3870e-03,  2.1088e-03, -8.2655e-04,\n",
      "          2.7434e-03, -2.1773e-03,  9.2172e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 3 5]\n",
      "tensor(0.0547)\n",
      "tensor(2.0803, grad_fn=<NllLossBackward0>)\n",
      "  batch 54 loss: 0.0005052973409286251\n",
      "tensor([[ 1.5924e-03, -5.7562e-05, -2.1329e-03,  1.0561e-03, -4.7549e-04,\n",
      "          1.4932e-03, -1.8899e-03, -5.8327e-04],\n",
      "        [ 1.5640e-03,  3.8423e-04, -2.0613e-03,  6.7632e-04, -4.7177e-04,\n",
      "          8.1158e-04, -2.0524e-03, -2.4879e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 3 5]\n",
      "tensor(0.1294)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 55 loss: 0.0005009312194331644\n",
      "tensor([[ 2.4563e-04,  8.8609e-05, -7.6690e-04,  2.6339e-04, -4.0345e-04,\n",
      "          4.3286e-04, -6.0218e-04, -4.7695e-04],\n",
      "        [ 7.4588e-04,  1.6611e-04, -1.3912e-03,  6.0665e-04, -2.5600e-04,\n",
      "          1.0799e-03, -5.6485e-04, -5.2788e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 7]\n",
      "tensor(0.1238)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 56 loss: 0.0005008352629711174\n",
      "tensor([[ 8.8732e-04,  5.2100e-05, -1.1659e-03,  4.2316e-04,  3.5022e-04,\n",
      "          2.6567e-04, -4.2033e-04, -2.6014e-04],\n",
      "        [ 4.8438e-04, -5.7435e-05, -1.2094e-03,  6.2870e-04,  2.2220e-04,\n",
      "          2.7829e-04, -8.0344e-04, -8.7447e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.0503)\n",
      "tensor(2.0797, grad_fn=<NllLossBackward0>)\n",
      "  batch 57 loss: 0.0004984789589564616\n",
      "tensor([[-1.0816e-04, -2.3856e-04,  1.7733e-05, -2.6600e-04,  2.4401e-04,\n",
      "          2.0819e-05,  2.5885e-05,  3.4969e-04],\n",
      "        [-2.9743e-04,  1.4500e-04,  3.8042e-04, -2.4974e-04,  8.0916e-04,\n",
      "          1.8502e-04,  5.0518e-04, -2.9878e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1313)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 58 loss: 0.0005030076631786861\n",
      "tensor([[-4.4190e-04, -1.9589e-04,  2.5647e-04, -4.0401e-04,  2.5082e-04,\n",
      "         -3.6434e-04, -2.1109e-06,  1.5387e-04],\n",
      "        [ 1.8308e-04,  1.2000e-05, -3.8257e-05,  3.5607e-05,  5.6694e-05,\n",
      "         -6.0965e-04, -3.5397e-04, -3.7509e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1761)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 59 loss: 0.0004954401697463753\n",
      "tensor([[-0.0008, -0.0001,  0.0021, -0.0002,  0.0005, -0.0011,  0.0012,  0.0002],\n",
      "        [-0.0005,  0.0002,  0.0013, -0.0004,  0.0008, -0.0009,  0.0006, -0.0002]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1265)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 60 loss: 0.0005039854992724597\n",
      "tensor([[-2.7045e-04, -7.6419e-06,  6.7727e-04, -6.4542e-04,  3.5044e-04,\n",
      "         -4.7919e-04,  3.4055e-04,  8.9421e-05],\n",
      "        [-8.9558e-04, -3.5809e-04,  1.3961e-03, -6.0085e-04,  2.9091e-04,\n",
      "         -6.0727e-04,  7.0853e-04,  3.5422e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1522)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 61 loss: 0.0005038585274624483\n",
      "tensor([[-4.1992e-04,  2.8880e-04,  1.1454e-04, -7.4769e-04,  7.5284e-04,\n",
      "         -2.3601e-05,  4.6098e-04, -6.5327e-04],\n",
      "        [-1.7086e-04,  1.3648e-05,  8.4899e-04, -7.2384e-04,  1.0027e-03,\n",
      "         -6.1074e-04,  6.2041e-04, -1.7026e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1218)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 62 loss: 0.0004975968612156065\n",
      "tensor([[-2.6105e-04,  7.5292e-05,  3.6328e-04, -5.1988e-04,  3.5263e-04,\n",
      "         -4.3709e-04,  2.7287e-04,  2.4540e-04],\n",
      "        [-8.4557e-04,  2.3483e-05,  1.8042e-03, -1.2932e-03,  1.1416e-03,\n",
      "         -1.0845e-03,  9.7150e-04, -6.3477e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.0803)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 63 loss: 0.0005001071096900107\n",
      "tensor([[-1.0296e-04, -2.0456e-04,  5.2159e-04, -2.6725e-05,  1.3936e-03,\n",
      "         -1.4772e-03,  9.9524e-04,  2.8570e-04],\n",
      "        [-3.7179e-04, -4.2047e-05,  1.3481e-03, -4.6807e-04,  9.5820e-04,\n",
      "         -1.4102e-03,  8.0896e-04,  1.3742e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.2010)\n",
      "tensor(2.0792, grad_fn=<NllLossBackward0>)\n",
      "  batch 64 loss: 0.0004986076332110581\n",
      "tensor([[-5.4163e-04,  1.1192e-05,  1.2416e-03, -1.0594e-03,  4.8125e-04,\n",
      "         -8.8982e-04,  5.2080e-04,  2.2043e-04],\n",
      "        [-5.1447e-04, -3.7361e-04,  6.6512e-04, -5.5059e-04,  1.0005e-03,\n",
      "         -6.1256e-04,  8.8947e-04,  2.3438e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 4 5 6 7]\n",
      "tensor(0.0019)\n",
      "tensor(2.0800, grad_fn=<NllLossBackward0>)\n",
      "  batch 65 loss: 0.0005041307693422274\n",
      "tensor([[-9.6483e-04,  1.0012e-04,  1.5336e-03, -4.7891e-04,  7.8578e-04,\n",
      "         -1.2414e-03,  1.0584e-03, -2.2093e-04],\n",
      "        [-5.3053e-04,  6.2609e-05,  1.1547e-03, -8.4043e-04,  1.0408e-03,\n",
      "         -1.0699e-03,  6.5483e-04,  3.7922e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 4 6 7]\n",
      "tensor(0.1495)\n",
      "tensor(2.0793, grad_fn=<NllLossBackward0>)\n",
      "  batch 66 loss: 0.000500424014388726\n",
      "tensor([[-1.1359e-03,  3.1032e-05,  2.0925e-03, -8.9528e-04,  1.3571e-03,\n",
      "         -1.4139e-03,  1.5250e-03,  9.6308e-05],\n",
      "        [-1.1594e-03,  1.1800e-05,  1.8356e-03, -7.6800e-04,  8.7366e-04,\n",
      "         -1.2032e-03,  1.4179e-03, -1.1831e-04]], grad_fn=<SliceBackward0>)\n",
      "[1 2 4 6 7]\n",
      "tensor(0.2104)\n",
      "tensor(2.0797, grad_fn=<NllLossBackward0>)\n",
      "  batch 67 loss: 0.0004926986305726645\n",
      "tensor([[-0.0011,  0.0006,  0.0014, -0.0005,  0.0009, -0.0013,  0.0009,  0.0003],\n",
      "        [-0.0013,  0.0002,  0.0016, -0.0009,  0.0005, -0.0011,  0.0007,  0.0002]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1220)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 68 loss: 0.0004976049625408595\n",
      "tensor([[-1.0762e-03,  5.3439e-05,  1.2222e-03, -1.1124e-03, -2.2488e-04,\n",
      "         -6.6927e-04,  1.4252e-04,  6.3804e-04],\n",
      "        [-2.6494e-04, -2.9701e-04,  1.0553e-03, -4.5506e-04,  2.4950e-04,\n",
      "         -1.3401e-03,  3.3777e-04,  2.9246e-04]], grad_fn=<SliceBackward0>)\n",
      "[1 2 4 5 6 7]\n",
      "tensor(0.0120)\n",
      "tensor(2.0801, grad_fn=<NllLossBackward0>)\n",
      "  batch 69 loss: 0.0005007499562586278\n",
      "tensor([[-0.0004,  0.0004,  0.0016, -0.0006,  0.0010, -0.0015,  0.0016, -0.0001],\n",
      "        [-0.0007,  0.0003,  0.0012, -0.0003,  0.0002, -0.0009,  0.0014, -0.0002]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[1 2 4 6 7]\n",
      "tensor(0.2012)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 70 loss: 0.0005003666510595738\n",
      "tensor([[-5.7790e-04, -3.2110e-04,  1.3345e-03, -5.1571e-04,  8.8878e-04,\n",
      "         -6.0773e-04,  8.2343e-04,  7.5304e-05],\n",
      "        [-3.6124e-04, -5.0827e-05,  1.3480e-03, -6.3999e-04,  9.2453e-04,\n",
      "         -1.0052e-03,  1.2055e-03,  1.8874e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 4 5 6 7]\n",
      "tensor(0.1223)\n",
      "tensor(2.0797, grad_fn=<NllLossBackward0>)\n",
      "  batch 71 loss: 0.0005006390692353191\n",
      "tensor([[-1.2383e-03, -8.4674e-05,  1.1086e-03, -5.5455e-04,  3.6789e-04,\n",
      "         -6.0741e-04,  6.3588e-04, -1.3377e-05],\n",
      "        [-6.1165e-04,  7.1607e-04,  1.1238e-03, -6.6632e-04, -1.2724e-04,\n",
      "          2.6353e-05,  4.7798e-04, -1.0637e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 4 5 6 7]\n",
      "tensor(0.1259)\n",
      "tensor(2.0791, grad_fn=<NllLossBackward0>)\n",
      "  batch 72 loss: 0.0005006338928281443\n",
      "tensor([[-5.9676e-04,  3.1631e-04,  9.1963e-04, -4.2660e-04,  2.4701e-04,\n",
      "         -7.9688e-04,  5.5034e-04, -6.9033e-05],\n",
      "        [-1.2737e-03, -2.6486e-05,  1.8410e-03, -1.0843e-03,  6.4207e-04,\n",
      "         -7.5937e-04,  1.3085e-03, -1.5239e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1258)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 73 loss: 0.0005013167340822137\n",
      "tensor([[-3.9414e-04,  5.8362e-05,  4.1781e-04, -3.5265e-04, -2.8851e-04,\n",
      "         -1.2493e-04,  6.6265e-04,  4.0675e-05],\n",
      "        [-1.1019e-03, -1.3382e-04,  1.3867e-03, -6.7043e-04,  3.5891e-04,\n",
      "         -8.0804e-04,  9.3763e-04,  1.0902e-06]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.0630)\n",
      "tensor(2.0793, grad_fn=<NllLossBackward0>)\n",
      "  batch 74 loss: 0.0004998383613733145\n",
      "tensor([[ 5.1957e-05,  2.9705e-04,  1.0835e-03, -9.6106e-04,  5.8893e-04,\n",
      "         -6.2880e-04,  9.3312e-04, -2.1065e-05],\n",
      "        [-3.1037e-04,  3.8712e-04,  1.9324e-04, -6.0840e-04,  1.7699e-04,\n",
      "          2.3371e-04,  4.5302e-04, -1.1578e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1262)\n",
      "tensor(2.0793, grad_fn=<NllLossBackward0>)\n",
      "  batch 75 loss: 0.0005006732178285499\n",
      "EPOCH 2:\n",
      "tensor([[-1.4079e-04, -3.7012e-04,  5.3427e-04, -3.8963e-04,  5.2308e-04,\n",
      "         -4.6076e-04,  7.2341e-04, -2.4228e-04],\n",
      "        [-8.2407e-04,  2.6901e-04,  7.0817e-04, -6.2137e-04,  2.3067e-04,\n",
      "         -5.3919e-04,  3.2231e-05,  6.8160e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.0325)\n",
      "tensor(2.0796, grad_fn=<NllLossBackward0>)\n",
      "  batch 1 loss: 0.0005001536122074833\n",
      "tensor([[-7.4187e-04,  4.7884e-06,  1.3518e-03, -1.0367e-03,  1.4455e-04,\n",
      "         -3.8488e-04,  6.3757e-04,  2.4285e-04],\n",
      "        [-1.4185e-03,  3.0015e-04,  1.2011e-03, -5.6957e-04,  4.0363e-04,\n",
      "         -7.5337e-05,  6.5990e-04,  6.4290e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.0952)\n",
      "tensor(2.0793, grad_fn=<NllLossBackward0>)\n",
      "  batch 2 loss: 0.0005049278227781543\n",
      "tensor([[-4.1588e-04,  5.6710e-04,  1.0010e-03, -8.9554e-04,  4.0902e-04,\n",
      "         -5.5664e-04,  5.9554e-04, -3.5669e-06],\n",
      "        [-4.3157e-04,  3.3285e-04,  8.9928e-04, -6.2683e-04,  8.7049e-04,\n",
      "         -9.4366e-04,  2.7712e-04, -1.7286e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.2702)\n",
      "tensor(2.0791, grad_fn=<NllLossBackward0>)\n",
      "  batch 3 loss: 0.0005002760680623647\n",
      "tensor([[-7.3445e-04,  5.0200e-04,  9.8457e-04, -1.0703e-03,  2.6727e-04,\n",
      "         -6.2548e-05,  7.2087e-04,  6.0063e-05],\n",
      "        [-3.4607e-04,  4.1300e-04,  1.0667e-03, -1.3287e-03,  2.1767e-04,\n",
      "         -4.6487e-04,  3.6602e-04, -7.0084e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1243)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 4 loss: 0.0005020275604085954\n",
      "tensor([[-8.7846e-04,  1.2245e-04,  7.5276e-04, -4.6741e-04,  8.1140e-05,\n",
      "         -5.1526e-04,  3.7593e-04,  4.4930e-04],\n",
      "        [-9.3700e-04, -6.9637e-05,  1.0775e-03, -8.2533e-04,  4.5486e-04,\n",
      "         -6.6284e-04,  2.4721e-04,  3.1590e-04]], grad_fn=<SliceBackward0>)\n",
      "[1 2 4 5 6 7]\n",
      "tensor(0.1137)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 5 loss: 0.0005018075345565913\n",
      "tensor([[-1.2166e-03,  4.4029e-04,  1.1806e-03, -1.4559e-04,  5.5752e-05,\n",
      "         -7.3242e-04,  8.1765e-04, -5.2236e-05],\n",
      "        [-7.1018e-04,  1.4758e-04,  7.8216e-04, -7.2952e-04,  8.1564e-04,\n",
      "         -1.2940e-04,  9.6069e-04,  3.1658e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 4 5 6 7]\n",
      "tensor(0.1347)\n",
      "tensor(2.0793, grad_fn=<NllLossBackward0>)\n",
      "  batch 6 loss: 0.0004955484710271525\n",
      "tensor([[-0.0014,  0.0002,  0.0019, -0.0011,  0.0003, -0.0009,  0.0011, -0.0002],\n",
      "        [-0.0010,  0.0003,  0.0016, -0.0008,  0.0003, -0.0004,  0.0012, -0.0002]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1365)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 7 loss: 0.0005025203358210937\n",
      "tensor([[-5.7279e-04,  1.3958e-04,  8.9630e-04, -3.5121e-04,  4.6168e-04,\n",
      "         -7.3060e-04,  7.7301e-04,  6.8927e-05],\n",
      "        [-7.4303e-04,  7.0216e-04,  1.7462e-03, -7.8510e-04,  7.5318e-04,\n",
      "         -7.2722e-04,  1.0915e-03,  2.2414e-04]], grad_fn=<SliceBackward0>)\n",
      "[1 2 4 6 7]\n",
      "tensor(0.1423)\n",
      "tensor(2.0791, grad_fn=<NllLossBackward0>)\n",
      "  batch 8 loss: 0.0005014824855747397\n",
      "tensor([[-0.0006,  0.0005,  0.0014, -0.0004,  0.0006, -0.0004,  0.0009, -0.0002],\n",
      "        [-0.0007,  0.0007,  0.0011, -0.0011,  0.0009, -0.0006,  0.0010,  0.0001]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[1 2 4 6 7]\n",
      "tensor(0.3197)\n",
      "tensor(2.0792, grad_fn=<NllLossBackward0>)\n",
      "  batch 9 loss: 0.0005028332014902615\n",
      "tensor([[-4.0356e-04,  8.0891e-04,  1.1644e-03, -5.7167e-04,  8.6704e-04,\n",
      "         -9.3887e-04,  1.3501e-03, -1.9235e-04],\n",
      "        [-4.0264e-04,  6.5987e-04,  7.3930e-04, -1.1938e-03,  2.6440e-04,\n",
      "         -7.3832e-04,  7.1631e-04,  3.5048e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.0414)\n",
      "tensor(2.0793, grad_fn=<NllLossBackward0>)\n",
      "  batch 10 loss: 0.0005037059155545493\n",
      "tensor([[-1.2550e-03,  4.4738e-04,  1.1255e-03, -1.2666e-03,  5.1851e-04,\n",
      "         -5.2673e-04,  8.6549e-04, -1.3930e-04],\n",
      "        [-9.8484e-04,  6.7055e-04,  8.7416e-04, -1.0539e-03,  4.7916e-04,\n",
      "         -5.2424e-04,  9.2649e-04, -4.1882e-05]], grad_fn=<SliceBackward0>)\n",
      "[1 2 4 6 7]\n",
      "tensor(0.1163)\n",
      "tensor(2.0801, grad_fn=<NllLossBackward0>)\n",
      "  batch 11 loss: 0.0005030478070407854\n",
      "tensor([[-1.1425e-03,  6.1893e-05,  2.0625e-03, -7.0908e-04,  8.4932e-04,\n",
      "         -1.4014e-03,  1.4304e-03,  1.4073e-04],\n",
      "        [-1.1608e-03,  4.1046e-04,  1.9379e-03, -4.7945e-04,  4.4450e-04,\n",
      "         -8.5439e-04,  1.0814e-03, -1.7441e-04]], grad_fn=<SliceBackward0>)\n",
      "[1 2 4 6 7]\n",
      "tensor(0.1342)\n",
      "tensor(2.0792, grad_fn=<NllLossBackward0>)\n",
      "  batch 12 loss: 0.0004894486479391037\n",
      "tensor([[-1.3614e-03,  8.3192e-04,  1.8087e-03, -1.4548e-03,  1.6421e-04,\n",
      "         -9.1049e-04,  1.0692e-03,  2.7946e-04],\n",
      "        [-1.6639e-04,  8.4203e-04,  7.3104e-04, -9.6910e-04,  1.2454e-03,\n",
      "         -8.3236e-04,  1.0126e-03,  1.2694e-05]], grad_fn=<SliceBackward0>)\n",
      "[1 2 4 6 7]\n",
      "tensor(0.1272)\n",
      "tensor(2.0796, grad_fn=<NllLossBackward0>)\n",
      "  batch 13 loss: 0.0005027934245952554\n",
      "tensor([[-0.0012,  0.0006,  0.0012, -0.0015,  0.0008, -0.0007,  0.0012,  0.0002],\n",
      "        [-0.0008,  0.0004,  0.0006, -0.0007,  0.0005, -0.0007,  0.0009,  0.0003]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[1 2 4 6]\n",
      "tensor(0.0106)\n",
      "tensor(2.0797, grad_fn=<NllLossBackward0>)\n",
      "  batch 14 loss: 0.0005032056300368402\n",
      "tensor([[-1.2005e-03,  5.8639e-04,  1.5926e-03, -1.5166e-03,  8.4797e-04,\n",
      "         -1.6935e-04,  1.6603e-03,  4.1005e-05],\n",
      "        [-7.2631e-04,  6.5420e-04,  1.2790e-03, -1.2965e-03,  6.6027e-04,\n",
      "         -8.5634e-04,  1.1730e-03, -2.9863e-04]], grad_fn=<SliceBackward0>)\n",
      "[1 2 4 6]\n",
      "tensor(0.0106)\n",
      "tensor(2.0798, grad_fn=<NllLossBackward0>)\n",
      "  batch 15 loss: 0.0005003234816480779\n",
      "tensor([[-8.8585e-04,  4.2597e-04,  1.4995e-03, -1.3383e-03,  3.6938e-04,\n",
      "         -7.9096e-04,  6.5010e-04,  1.9143e-04],\n",
      "        [-8.1531e-04,  3.3699e-05,  8.8972e-04, -7.8953e-04,  8.5137e-04,\n",
      "         -4.6843e-04,  1.0542e-03,  1.6632e-04]], grad_fn=<SliceBackward0>)\n",
      "[1 2 4 6 7]\n",
      "tensor(0.0097)\n",
      "tensor(2.0800, grad_fn=<NllLossBackward0>)\n",
      "  batch 16 loss: 0.0005028994908876991\n",
      "tensor([[-1.1915e-03,  1.3258e-04,  1.8993e-03, -1.0166e-03,  1.0997e-03,\n",
      "         -7.6710e-04,  1.4480e-03, -7.9933e-05],\n",
      "        [-6.4630e-04,  1.9925e-04,  1.4902e-03, -1.0661e-03, -1.0266e-04,\n",
      "         -6.8053e-04,  1.0748e-03, -1.9823e-04]], grad_fn=<SliceBackward0>)\n",
      "[1 2 4 6 7]\n",
      "tensor(0.0373)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 17 loss: 0.0005035211618529682\n",
      "tensor([[-1.2392e-03,  7.7876e-04,  1.8025e-03, -1.4962e-03,  5.7552e-04,\n",
      "         -7.5827e-04,  7.7549e-04, -1.2090e-04],\n",
      "        [-1.0670e-03,  7.4383e-04,  1.1796e-03, -8.0076e-04,  5.4140e-04,\n",
      "          1.0632e-05,  5.7328e-04, -2.4207e-04]], grad_fn=<SliceBackward0>)\n",
      "[1 2 4 6 7]\n",
      "tensor(0.0775)\n",
      "tensor(2.0793, grad_fn=<NllLossBackward0>)\n",
      "  batch 18 loss: 0.0005019956139307101\n",
      "tensor([[-7.9090e-04,  8.0713e-04,  1.0661e-03, -7.4372e-04,  6.8264e-04,\n",
      "         -4.8193e-04,  1.0675e-03, -9.4065e-05],\n",
      "        [-1.0663e-03,  3.4301e-04,  1.2478e-03, -1.4181e-03,  9.4720e-04,\n",
      "         -8.5893e-04,  4.2979e-04, -1.6513e-05]], grad_fn=<SliceBackward0>)\n",
      "[1 2 4 5 6 7]\n",
      "tensor(0.2236)\n",
      "tensor(2.0791, grad_fn=<NllLossBackward0>)\n",
      "  batch 19 loss: 0.000499783456325531\n",
      "tensor([[-1.5110e-03,  5.0772e-04,  1.1166e-03, -1.2437e-03,  3.1137e-05,\n",
      "         -2.7535e-04,  1.1899e-03,  3.6225e-04],\n",
      "        [-9.2121e-04,  4.7837e-04,  7.1758e-04, -7.9753e-04,  6.0224e-04,\n",
      "         -1.3402e-04,  1.0383e-03,  8.2088e-05]], grad_fn=<SliceBackward0>)\n",
      "[1 2 4 5 6 7]\n",
      "tensor(0.0822)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 20 loss: 0.0005010533045573407\n",
      "tensor([[-8.7734e-04,  1.3616e-04,  5.0582e-04, -8.3002e-04, -9.6193e-05,\n",
      "         -3.3263e-04,  9.0623e-04,  4.4990e-04],\n",
      "        [-1.0773e-03,  4.1653e-04,  6.3049e-04, -1.0820e-03,  3.5143e-04,\n",
      "          4.3726e-05,  6.6556e-04,  1.4053e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 4 5 6 7]\n",
      "tensor(0.1272)\n",
      "tensor(2.0796, grad_fn=<NllLossBackward0>)\n",
      "  batch 21 loss: 0.0005030494181499657\n",
      "tensor([[-1.1341e-03,  6.0709e-04,  1.3239e-03, -1.0157e-03,  8.3135e-04,\n",
      "         -1.1416e-04,  1.1218e-03, -1.3603e-04],\n",
      "        [-1.1367e-03,  9.9133e-04,  1.3437e-03, -1.1721e-03,  1.0382e-03,\n",
      "          4.7797e-05,  1.3558e-03, -2.5351e-04]], grad_fn=<SliceBackward0>)\n",
      "[1 2 3 4 5 6 7]\n",
      "tensor(0.1691)\n",
      "tensor(2.0792, grad_fn=<NllLossBackward0>)\n",
      "  batch 22 loss: 0.0005007746821423716\n",
      "tensor([[-1.6864e-03,  5.3359e-05,  1.4443e-03, -6.4454e-04, -5.1446e-04,\n",
      "         -6.4886e-04,  7.6701e-04,  2.3927e-06],\n",
      "        [-1.4139e-03,  6.5803e-04,  1.4971e-03, -1.1501e-03, -8.9937e-05,\n",
      "         -4.8069e-04,  1.0785e-03, -1.0964e-04]], grad_fn=<SliceBackward0>)\n",
      "[1 2 4 5 6 7]\n",
      "tensor(0.0742)\n",
      "tensor(2.0801, grad_fn=<NllLossBackward0>)\n",
      "  batch 23 loss: 0.0004981150458142218\n",
      "tensor([[-1.0192e-03,  4.4296e-04,  7.6670e-04, -6.8433e-04,  7.3346e-05,\n",
      "         -1.1022e-04,  4.4966e-04, -1.7349e-04],\n",
      "        [-3.3322e-04,  2.2231e-04,  3.1365e-04, -4.0521e-04,  1.0021e-03,\n",
      "         -2.8075e-04,  1.0303e-03, -2.1702e-04]], grad_fn=<SliceBackward0>)\n",
      "[1 2 4 5 6 7]\n",
      "tensor(0.0602)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 24 loss: 0.0005029922645912115\n",
      "tensor([[-0.0010,  0.0002,  0.0013, -0.0007,  0.0009, -0.0008,  0.0012,  0.0005],\n",
      "        [-0.0011,  0.0005,  0.0009, -0.0009,  0.0008, -0.0005,  0.0009, -0.0002]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[0 1 2 4 5 6 7]\n",
      "tensor(0.0069)\n",
      "tensor(2.0800, grad_fn=<NllLossBackward0>)\n",
      "  batch 25 loss: 0.0004960599049104872\n",
      "tensor([[-0.0013,  0.0004,  0.0005, -0.0003, -0.0005,  0.0004,  0.0011,  0.0001],\n",
      "        [-0.0003,  0.0008,  0.0011, -0.0009,  0.0005, -0.0003,  0.0010, -0.0003]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1870)\n",
      "tensor(2.0792, grad_fn=<NllLossBackward0>)\n",
      "  batch 26 loss: 0.0005010129744748035\n",
      "tensor([[-0.0010,  0.0004,  0.0008, -0.0005, -0.0003,  0.0002,  0.0008, -0.0004],\n",
      "        [-0.0011,  0.0004,  0.0006, -0.0004, -0.0003,  0.0005,  0.0005, -0.0001]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.0260)\n",
      "tensor(2.0796, grad_fn=<NllLossBackward0>)\n",
      "  batch 27 loss: 0.0005007510641067252\n",
      "tensor([[-3.2469e-04,  7.7139e-05,  5.3883e-06, -3.5132e-04, -1.9509e-04,\n",
      "         -4.8855e-04,  1.5638e-04, -4.1595e-04],\n",
      "        [-5.5962e-04,  1.0236e-04,  6.0154e-04, -7.9337e-04,  1.3706e-04,\n",
      "         -2.0358e-04, -1.3674e-04,  4.1863e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1848)\n",
      "tensor(2.0792, grad_fn=<NllLossBackward0>)\n",
      "  batch 28 loss: 0.0005004120791144894\n",
      "tensor([[-2.3267e-04,  1.6750e-04,  1.0774e-03, -8.2082e-04, -5.3130e-05,\n",
      "         -4.8320e-04,  8.0558e-04, -2.0710e-04],\n",
      "        [-3.9154e-04,  1.6853e-05,  5.5379e-04, -6.1422e-04,  3.3679e-04,\n",
      "         -6.0506e-04,  5.4770e-04, -9.3769e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.0724)\n",
      "tensor(2.0796, grad_fn=<NllLossBackward0>)\n",
      "  batch 29 loss: 0.0004982323982410587\n",
      "tensor([[-9.7978e-04, -5.8650e-06,  7.6575e-04, -6.8068e-06, -4.3293e-04,\n",
      "          1.7730e-04,  9.5020e-04,  5.4756e-04],\n",
      "        [-4.7128e-04,  1.4163e-04,  3.8106e-04,  2.7913e-04, -2.1695e-04,\n",
      "         -1.1970e-04,  7.2848e-04,  4.7593e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1071)\n",
      "tensor(2.0796, grad_fn=<NllLossBackward0>)\n",
      "  batch 30 loss: 0.0005003755429940687\n",
      "tensor([[ 0.0002,  0.0004,  0.0004, -0.0007,  0.0005, -0.0006,  0.0006, -0.0003],\n",
      "        [-0.0005,  0.0003,  0.0009, -0.0006,  0.0003, -0.0005,  0.0007, -0.0002]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.0802)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 31 loss: 0.0005025291512011329\n",
      "tensor([[-2.6077e-04,  4.9553e-04,  3.2043e-04, -9.4658e-05,  3.4981e-04,\n",
      "         -6.5007e-04,  7.3929e-05,  1.5407e-04],\n",
      "        [-4.2282e-04,  5.5393e-04,  6.2370e-04, -2.3597e-04,  5.5576e-05,\n",
      "         -7.3690e-05,  3.9592e-04, -1.7726e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.0717)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 32 loss: 0.0005003618322047508\n",
      "tensor([[-3.3475e-04,  1.5257e-04,  1.1605e-04,  2.9494e-04,  5.1554e-04,\n",
      "          4.1058e-04,  6.6287e-04, -1.0969e-04],\n",
      "        [-5.4804e-04, -2.1487e-04,  8.1295e-04,  2.2047e-04,  6.7770e-05,\n",
      "         -4.6010e-04,  3.3978e-04,  2.3299e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.0799)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 33 loss: 0.0005020633059270943\n",
      "tensor([[-3.1072e-04,  1.8926e-04,  2.5906e-04, -3.2242e-04, -5.2981e-05,\n",
      "          5.7970e-04,  7.1966e-04, -7.8711e-05],\n",
      "        [ 2.2006e-04,  3.0972e-04,  1.1358e-04, -2.6065e-04,  1.2533e-04,\n",
      "         -3.1773e-04, -3.5352e-04, -9.8559e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.0808)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 34 loss: 0.0005048564059782387\n",
      "tensor([[-4.2932e-04, -9.8874e-05,  1.0788e-05,  1.8223e-04, -4.7460e-04,\n",
      "          2.0326e-05,  1.9718e-04,  1.4902e-05],\n",
      "        [-2.1288e-04,  6.3800e-05,  1.6046e-04, -2.8030e-04, -5.4036e-05,\n",
      "         -1.0737e-04, -1.6188e-04, -4.0867e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1464)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 35 loss: 0.0004998587071895599\n",
      "tensor([[-1.9230e-04,  9.4660e-05, -3.4446e-04,  1.2173e-04, -1.4929e-04,\n",
      "          2.5200e-04, -2.6344e-04, -2.5365e-04],\n",
      "        [-1.5883e-04, -8.5397e-05,  2.3020e-04,  3.1666e-04,  3.7907e-05,\n",
      "          1.1022e-04,  2.4783e-04,  7.2881e-06]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1111)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 36 loss: 0.0004987931131430169\n",
      "tensor([[ 4.9808e-04,  1.9981e-04, -6.5024e-04, -1.0710e-04,  5.1497e-04,\n",
      "          3.9907e-04,  3.8362e-04, -2.3604e-04],\n",
      "        [ 4.0427e-04, -3.6145e-04, -9.2090e-05,  3.3978e-04, -3.3793e-04,\n",
      "         -1.1316e-04,  9.9892e-05, -2.0751e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1850)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 37 loss: 0.0004976946181118802\n",
      "tensor([[-1.4017e-04, -3.7134e-04, -3.0158e-04,  6.3742e-04, -3.9294e-04,\n",
      "          2.0776e-04, -6.8698e-04,  4.0932e-04],\n",
      "        [ 2.2961e-04,  3.0035e-04, -4.4133e-04, -1.4119e-05,  6.9215e-05,\n",
      "          8.2342e-05, -5.8765e-04, -2.9813e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.0979)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 38 loss: 0.0005027862766494604\n",
      "tensor([[ 0.0005,  0.0004, -0.0005,  0.0004, -0.0005,  0.0003, -0.0004, -0.0003],\n",
      "        [ 0.0010,  0.0001, -0.0006,  0.0004, -0.0003, -0.0002, -0.0008, -0.0004]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1240)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 39 loss: 0.0005045867434869372\n",
      "tensor([[ 2.3354e-04, -1.6984e-04,  1.1828e-04,  4.9310e-04, -4.4396e-04,\n",
      "         -2.8143e-05, -6.6974e-05, -2.1026e-04],\n",
      "        [ 4.7422e-04, -5.7675e-04, -8.5814e-04,  4.3868e-04, -5.1571e-04,\n",
      "          4.1109e-04, -2.8313e-05, -8.0893e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.0948)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 40 loss: 0.0005031472512316017\n",
      "tensor([[ 7.8811e-04, -9.2292e-04, -6.8662e-04,  9.4137e-04, -8.3206e-04,\n",
      "         -2.5477e-04, -8.0647e-04, -1.6983e-04],\n",
      "        [ 3.3425e-04,  1.9141e-05, -1.1286e-03,  3.7892e-04, -1.6607e-05,\n",
      "          4.0356e-04, -2.3246e-04,  5.1387e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1954)\n",
      "tensor(2.0793, grad_fn=<NllLossBackward0>)\n",
      "  batch 41 loss: 0.0004961413263108389\n",
      "tensor([[-1.3811e-04,  2.2750e-04, -7.0728e-05,  2.4414e-04, -4.9810e-04,\n",
      "          2.8322e-04, -4.7055e-04, -4.1419e-04],\n",
      "        [ 6.6631e-04, -3.4565e-05, -5.9372e-04,  1.2874e-04,  1.6829e-04,\n",
      "         -6.8640e-05, -1.2697e-04, -5.7801e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.0607)\n",
      "tensor(2.0797, grad_fn=<NllLossBackward0>)\n",
      "  batch 42 loss: 0.000502594315873188\n",
      "tensor([[-1.4597e-05, -3.2304e-05, -4.0161e-04,  6.9598e-04, -7.6652e-04,\n",
      "          5.7390e-04, -3.8105e-04, -2.1984e-04],\n",
      "        [ 7.5957e-04,  3.7527e-04, -1.3340e-03,  8.7353e-04, -4.2711e-04,\n",
      "          8.8762e-04, -8.5498e-04, -3.0846e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1807)\n",
      "tensor(2.0793, grad_fn=<NllLossBackward0>)\n",
      "  batch 43 loss: 0.0005003187493479401\n",
      "tensor([[ 0.0003,  0.0002, -0.0002,  0.0005, -0.0003,  0.0003, -0.0002, -0.0004],\n",
      "        [ 0.0006, -0.0006, -0.0010,  0.0010, -0.0007,  0.0005, -0.0007, -0.0002]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1709)\n",
      "tensor(2.0793, grad_fn=<NllLossBackward0>)\n",
      "  batch 44 loss: 0.0004991205392179155\n",
      "tensor([[ 0.0004, -0.0004, -0.0007,  0.0012, -0.0007,  0.0005, -0.0011, -0.0001],\n",
      "        [ 0.0006, -0.0001, -0.0006,  0.0009, -0.0007, -0.0002, -0.0009, -0.0001]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 7]\n",
      "tensor(0.1401)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 45 loss: 0.000497007404185162\n",
      "tensor([[ 0.0002,  0.0001, -0.0005,  0.0009, -0.0005,  0.0006, -0.0008, -0.0008],\n",
      "        [ 0.0003,  0.0001, -0.0006,  0.0005, -0.0004,  0.0003, -0.0010, -0.0004]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.0298)\n",
      "tensor(2.0797, grad_fn=<NllLossBackward0>)\n",
      "  batch 46 loss: 0.0004994442666756431\n",
      "tensor([[ 7.4097e-04, -4.7099e-04, -7.3464e-04,  1.3926e-03, -2.3280e-04,\n",
      "         -3.3538e-05, -4.7356e-04, -4.9108e-05],\n",
      "        [ 7.5937e-04, -6.1495e-04, -5.3756e-04,  1.2244e-03, -5.4170e-04,\n",
      "         -8.7030e-06, -7.5732e-04, -2.1220e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 7]\n",
      "tensor(0.1740)\n",
      "tensor(2.0791, grad_fn=<NllLossBackward0>)\n",
      "  batch 47 loss: 0.0005003961271614231\n",
      "tensor([[ 9.8980e-04, -2.7709e-04, -1.6328e-03,  1.4391e-03, -5.9470e-04,\n",
      "          8.9910e-04, -9.2354e-04, -3.3578e-05],\n",
      "        [ 7.5955e-04, -5.1631e-04, -8.0571e-04,  9.6044e-04, -5.4056e-04,\n",
      "          2.6340e-04, -6.5208e-04, -2.0543e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 7]\n",
      "tensor(0.0221)\n",
      "tensor(2.0797, grad_fn=<NllLossBackward0>)\n",
      "  batch 48 loss: 0.0004993292750144491\n",
      "tensor([[ 3.7895e-04, -2.2282e-04, -3.2931e-04,  9.9463e-04, -6.2633e-04,\n",
      "         -2.0433e-05, -2.4915e-04, -6.7009e-05],\n",
      "        [ 7.3354e-04, -1.8039e-04, -7.4045e-04,  5.7557e-04, -7.1834e-04,\n",
      "          2.7363e-04, -1.0844e-03, -2.4917e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 7]\n",
      "tensor(0.1470)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 49 loss: 0.0005034888339100392\n",
      "tensor([[ 1.6013e-03, -6.4524e-04, -1.7229e-03,  1.7206e-03, -1.0593e-03,\n",
      "          3.1390e-04, -1.2563e-03, -5.4917e-05],\n",
      "        [ 9.6520e-04, -3.9241e-04, -1.1569e-03,  1.0692e-03, -6.6732e-04,\n",
      "          5.4567e-04, -8.8826e-04, -4.1385e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 7]\n",
      "tensor(0.2064)\n",
      "tensor(2.0791, grad_fn=<NllLossBackward0>)\n",
      "  batch 50 loss: 0.000501356557216419\n",
      "tensor([[ 6.3756e-04, -7.8081e-05, -6.6047e-04,  1.0255e-03, -3.1746e-04,\n",
      "          5.5375e-04, -7.9939e-04, -6.4216e-05],\n",
      "        [ 1.1662e-03, -3.9099e-05, -5.0740e-04,  7.5699e-04, -6.0820e-04,\n",
      "          1.7073e-04, -9.4705e-04, -2.8664e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 3 5 7]\n",
      "tensor(0.0497)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 51 loss: 0.0004993878111715619\n",
      "tensor([[ 9.7767e-04, -4.3963e-04, -7.2349e-04,  1.0102e-03, -5.9876e-04,\n",
      "          1.1655e-04, -9.7885e-04, -1.9100e-04],\n",
      "        [ 4.1339e-04, -4.5045e-05, -8.7021e-04,  6.9160e-04, -5.4972e-04,\n",
      "          6.5735e-04, -1.0598e-03, -9.1292e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 3 4 5 7]\n",
      "tensor(0.1869)\n",
      "tensor(2.0793, grad_fn=<NllLossBackward0>)\n",
      "  batch 52 loss: 0.0005046960798282068\n",
      "tensor([[ 7.0306e-04, -2.2995e-04, -7.1333e-04,  8.7436e-04, -9.0956e-04,\n",
      "          5.0116e-04, -1.1735e-03, -8.1368e-05],\n",
      "        [ 1.1837e-03,  1.3941e-04, -1.1461e-03,  1.1292e-03, -5.4553e-04,\n",
      "          8.0581e-04, -1.1493e-03, -8.2696e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 3 4 5 7]\n",
      "tensor(0.0527)\n",
      "tensor(2.0796, grad_fn=<NllLossBackward0>)\n",
      "  batch 53 loss: 0.0004958476006103573\n",
      "tensor([[ 0.0011, -0.0001, -0.0010,  0.0014, -0.0003,  0.0004, -0.0008, -0.0001],\n",
      "        [ 0.0008,  0.0001, -0.0013,  0.0014, -0.0003,  0.0008, -0.0004, -0.0003]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[0 3 4 5 7]\n",
      "tensor(0.0970)\n",
      "tensor(2.0798, grad_fn=<NllLossBackward0>)\n",
      "  batch 54 loss: 0.000498263071642347\n",
      "tensor([[ 1.6160e-04, -9.3996e-05,  5.9718e-05,  8.5655e-04, -9.8406e-04,\n",
      "          6.0106e-04, -5.3877e-04, -2.7205e-04],\n",
      "        [ 2.9812e-04, -4.8308e-04, -6.3656e-04,  8.6554e-04, -8.4756e-04,\n",
      "          6.2502e-04, -1.1112e-03,  8.2756e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 3 5 7]\n",
      "tensor(0.0362)\n",
      "tensor(2.0797, grad_fn=<NllLossBackward0>)\n",
      "  batch 55 loss: 0.0005024525531106134\n",
      "tensor([[ 8.1089e-04, -4.5220e-04, -1.3505e-03,  1.1071e-03, -8.4940e-04,\n",
      "          8.8257e-04, -1.3892e-03, -2.0112e-04],\n",
      "        [ 1.9807e-04, -3.3497e-04, -9.3884e-04,  8.1035e-04, -5.2164e-04,\n",
      "          9.0532e-04, -8.1363e-04,  1.0903e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 3 5]\n",
      "tensor(0.)\n",
      "tensor(2.0800, grad_fn=<NllLossBackward0>)\n",
      "  batch 56 loss: 0.0004980758232175162\n",
      "tensor([[-2.3787e-05, -5.5574e-04, -1.1348e-04,  8.2255e-04, -8.9590e-04,\n",
      "          8.8713e-05, -6.8250e-04, -4.1526e-04],\n",
      "        [ 4.6007e-04, -4.5486e-04, -5.2607e-04,  4.1944e-04, -4.1331e-04,\n",
      "          5.7192e-04, -7.0115e-04, -5.9967e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 3 4 5 7]\n",
      "tensor(0.0491)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 57 loss: 0.0005008411774975257\n",
      "tensor([[ 1.1333e-03,  9.7532e-06, -3.7332e-04,  9.6123e-04,  5.3932e-05,\n",
      "         -9.8886e-05, -4.6123e-04, -4.9074e-04],\n",
      "        [ 9.0433e-04, -2.2464e-04, -9.5055e-04,  1.0410e-03, -1.1165e-03,\n",
      "          7.7073e-04, -9.0518e-04, -2.1242e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 2 3 4 5 6 7]\n",
      "tensor(0.1773)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 58 loss: 0.0005002161732137505\n",
      "tensor([[ 7.5354e-04, -3.6107e-04, -3.2350e-04,  8.3492e-04, -2.7507e-04,\n",
      "          3.9879e-04, -1.0353e-03, -3.6229e-04],\n",
      "        [ 7.5204e-04, -4.7558e-04, -5.4205e-04,  9.7858e-05, -2.4563e-04,\n",
      "          4.6532e-05, -1.0471e-03, -4.1872e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 7]\n",
      "tensor(0.1599)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 59 loss: 0.0004962889846583255\n",
      "tensor([[-2.6395e-04,  1.2239e-04, -6.3660e-04,  4.6426e-04, -5.5978e-04,\n",
      "          9.4709e-04, -5.8845e-04,  9.7163e-05],\n",
      "        [ 2.3023e-04, -4.4850e-04, -9.9909e-05,  7.3543e-04, -5.7835e-04,\n",
      "         -1.4097e-04, -5.8346e-04, -4.1289e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.2047)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 60 loss: 0.0004984184971020297\n",
      "tensor([[-4.8371e-05, -4.8929e-04, -4.9797e-04,  1.1497e-03, -2.7235e-04,\n",
      "          6.5750e-04, -1.0402e-03,  5.2988e-04],\n",
      "        [ 8.8871e-04, -3.7246e-04, -1.3058e-03,  1.0050e-03, -7.2989e-05,\n",
      "          7.9476e-04, -9.1082e-04, -5.2934e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 7]\n",
      "tensor(0.1440)\n",
      "tensor(2.0793, grad_fn=<NllLossBackward0>)\n",
      "  batch 61 loss: 0.0004982802612502141\n",
      "tensor([[ 3.7302e-06, -2.1450e-04, -3.9013e-04,  5.1601e-04, -1.2524e-04,\n",
      "          4.9054e-04, -2.9482e-04,  2.7298e-04],\n",
      "        [-2.3653e-04, -3.4359e-04, -2.6889e-04,  8.7459e-04, -1.1634e-04,\n",
      "          6.1304e-04, -2.9642e-04,  4.8347e-06]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 7]\n",
      "tensor(0.1516)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 62 loss: 0.0004997276910306513\n",
      "tensor([[ 6.3206e-04, -4.1006e-04, -4.5800e-04,  9.2799e-04, -5.3973e-04,\n",
      "         -4.2754e-04, -1.0989e-03, -3.8340e-04],\n",
      "        [ 4.5444e-04, -4.2645e-04, -3.2682e-04,  8.3376e-04,  1.0631e-05,\n",
      "         -2.6210e-04, -8.3009e-04, -5.6613e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 7]\n",
      "tensor(0.0413)\n",
      "tensor(2.0796, grad_fn=<NllLossBackward0>)\n",
      "  batch 63 loss: 0.0004998941261034745\n",
      "tensor([[-5.3588e-05, -4.2179e-04,  3.9534e-05,  4.7304e-04, -7.2445e-04,\n",
      "          4.8984e-04, -2.3629e-04, -2.8131e-04],\n",
      "        [ 9.4080e-04, -3.6911e-04, -1.3960e-03,  1.1862e-03, -1.2441e-04,\n",
      "          7.5018e-04, -4.9374e-04,  1.2179e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 7]\n",
      "tensor(0.1857)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 64 loss: 0.0005022696250878671\n",
      "tensor([[ 8.1094e-04, -8.6914e-04, -4.4703e-04,  6.2873e-04, -6.5178e-04,\n",
      "          4.1791e-04, -1.0509e-03,  3.2190e-04],\n",
      "        [ 8.0939e-05, -4.3157e-04,  4.9629e-05,  6.5140e-04, -8.0558e-04,\n",
      "          4.7316e-04, -3.5912e-04,  3.1750e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 7]\n",
      "tensor(0.0403)\n",
      "tensor(2.0796, grad_fn=<NllLossBackward0>)\n",
      "  batch 65 loss: 0.0005018339424059658\n",
      "tensor([[ 0.0001, -0.0005, -0.0003,  0.0008, -0.0008,  0.0008, -0.0011,  0.0001],\n",
      "        [-0.0003, -0.0006, -0.0004,  0.0008, -0.0009,  0.0009, -0.0013,  0.0003]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 7]\n",
      "tensor(0.0084)\n",
      "tensor(2.0798, grad_fn=<NllLossBackward0>)\n",
      "  batch 66 loss: 0.0005006637490593475\n",
      "tensor([[ 1.6810e-04,  1.8085e-04, -2.6323e-04,  1.8353e-04, -1.9665e-04,\n",
      "          7.7879e-04, -7.3811e-04, -1.0534e-04],\n",
      "        [ 1.8121e-04, -3.8275e-04, -6.0169e-04,  2.3896e-04, -2.9625e-04,\n",
      "          5.1396e-04, -6.1474e-04,  6.9735e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1174)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 67 loss: 0.0005014231327444149\n",
      "tensor([[-6.1110e-05, -2.9242e-04, -7.8409e-05,  3.4043e-04, -3.5808e-04,\n",
      "         -2.3843e-04, -3.8986e-04, -3.0269e-04],\n",
      "        [-3.0518e-04, -1.2731e-04, -3.3742e-04,  3.9559e-04, -8.1960e-04,\n",
      "          1.6270e-04, -6.9637e-04,  7.0327e-06]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1610)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 68 loss: 0.0005005847736224568\n",
      "tensor([[ 9.6899e-05, -6.9617e-04,  1.3683e-04,  8.7253e-04, -2.5178e-04,\n",
      "          1.4769e-04, -4.7715e-04,  1.8699e-04],\n",
      "        [ 5.2571e-04, -7.5267e-04, -2.6738e-04,  8.2247e-04,  5.6393e-05,\n",
      "         -4.3518e-04, -2.8088e-04,  6.0518e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1227)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 69 loss: 0.0004965279254895113\n",
      "tensor([[ 3.5763e-04, -3.1855e-05, -5.2408e-04,  8.9187e-04,  7.5778e-07,\n",
      "          3.1139e-04, -7.4320e-04, -1.4596e-04],\n",
      "        [ 3.5386e-05,  9.2641e-05,  7.2282e-05,  2.0445e-04, -2.9342e-04,\n",
      "          3.5859e-04, -4.6920e-04, -1.0320e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.0863)\n",
      "tensor(2.0796, grad_fn=<NllLossBackward0>)\n",
      "  batch 70 loss: 0.0004987088896387773\n",
      "tensor([[-1.6825e-04, -4.7150e-04,  2.4228e-04,  4.6266e-04, -6.1081e-04,\n",
      "          1.4468e-04, -6.7697e-04,  3.4613e-04],\n",
      "        [ 4.3934e-04, -3.9653e-05, -2.0129e-04, -8.6100e-06, -3.5590e-04,\n",
      "          2.3318e-04, -6.1493e-04, -1.8007e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.0926)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 71 loss: 0.0005026577116643746\n",
      "tensor([[ 2.1549e-04, -4.6075e-04,  6.0046e-05,  2.7803e-04, -8.6844e-04,\n",
      "         -1.0490e-05, -7.1500e-04, -3.1573e-04],\n",
      "        [ 5.2427e-06, -3.7521e-04, -2.2173e-04,  1.7375e-04, -2.8650e-04,\n",
      "          3.4642e-04, -7.7282e-04, -1.7034e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1489)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 72 loss: 0.0004961624887330353\n",
      "tensor([[-1.9194e-06, -3.8617e-04,  2.6602e-04, -5.2000e-05, -9.1188e-04,\n",
      "         -2.6706e-04, -5.4428e-04, -2.8806e-04],\n",
      "        [-4.5467e-04, -5.7296e-04,  3.4226e-04,  2.8994e-04, -4.9210e-04,\n",
      "          2.8520e-04, -1.9930e-04,  9.4776e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.0595)\n",
      "tensor(2.0796, grad_fn=<NllLossBackward0>)\n",
      "  batch 73 loss: 0.0004991823472028962\n",
      "tensor([[ 1.0595e-04,  2.2159e-04, -3.9018e-04,  5.4772e-04, -1.1506e-04,\n",
      "          3.2831e-04, -8.7364e-04, -2.8564e-04],\n",
      "        [ 5.7290e-04, -3.4392e-05, -3.0510e-05,  5.5148e-04, -1.2107e-04,\n",
      "         -3.2815e-04, -5.9789e-04, -9.3275e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.2072)\n",
      "tensor(2.0793, grad_fn=<NllLossBackward0>)\n",
      "  batch 74 loss: 0.0005032211282477143\n",
      "tensor([[-2.0182e-04, -3.0814e-04,  4.8244e-04,  5.9276e-04,  8.4069e-05,\n",
      "         -4.1223e-04, -5.8973e-04,  2.9297e-04],\n",
      "        [-9.7416e-04, -7.8656e-05,  4.6250e-04, -1.0689e-04, -5.0128e-04,\n",
      "          3.1627e-04, -1.1816e-04, -6.2334e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1558)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 75 loss: 0.0005021450514380006\n",
      "EPOCH 3:\n",
      "tensor([[-7.9019e-06, -2.2488e-04,  2.2468e-04,  1.9308e-04, -3.6859e-04,\n",
      "         -2.4948e-04, -2.5957e-04, -7.5181e-05],\n",
      "        [-3.9948e-04,  1.9740e-04, -7.6372e-05, -4.7537e-05, -2.6550e-04,\n",
      "          3.4365e-04, -4.3292e-04,  1.8035e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1610)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 1 loss: 0.0004996143242076633\n",
      "tensor([[-5.5098e-04, -3.2093e-04,  6.6963e-05,  3.5191e-04, -4.1643e-04,\n",
      "          1.3268e-04, -2.6040e-04, -7.8129e-05],\n",
      "        [-1.5539e-04,  3.1806e-04,  3.0953e-04,  2.1290e-04, -6.9302e-04,\n",
      "          6.1719e-04, -3.5990e-04, -3.6823e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1017)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 2 loss: 0.0005048543222033303\n",
      "tensor([[-5.5976e-04, -1.6539e-04,  1.6465e-04,  3.2338e-04, -6.1807e-04,\n",
      "          2.3387e-04, -4.9452e-04, -2.5861e-05],\n",
      "        [ 1.0611e-04, -5.1820e-04,  7.0370e-05,  2.8283e-04, -3.9282e-04,\n",
      "          1.2913e-04,  7.9700e-05, -2.0265e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.0651)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 3 loss: 0.0004994026407613764\n",
      "tensor([[ 6.5469e-04,  3.3539e-05, -4.0750e-04,  3.1720e-04,  2.1867e-04,\n",
      "          3.4610e-04, -5.7343e-04, -2.6705e-04],\n",
      "        [ 4.0406e-05, -3.1857e-04,  3.9615e-04,  3.2690e-05, -3.9898e-04,\n",
      "          3.7089e-04, -3.7419e-04, -4.8040e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1197)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 4 loss: 0.0005037467493567356\n",
      "tensor([[-1.8161e-04, -1.7181e-04, -2.9580e-04,  7.5055e-04, -6.7314e-04,\n",
      "          6.2975e-04, -3.0201e-04,  2.1749e-04],\n",
      "        [-3.2923e-04, -1.8740e-04,  1.3750e-04, -1.0807e-04, -3.6153e-04,\n",
      "         -7.1589e-05,  3.1825e-04, -8.0410e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1367)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 5 loss: 0.0005003454251514247\n",
      "tensor([[-1.8722e-04, -3.9684e-04, -2.6235e-04,  3.7794e-04, -7.2512e-04,\n",
      "          5.8378e-04, -4.4316e-04,  3.5021e-04],\n",
      "        [-1.8980e-05, -2.5812e-04,  1.9193e-04,  2.7530e-04, -2.3461e-04,\n",
      "         -3.2148e-04, -3.8608e-04, -1.5439e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.0975)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 6 loss: 0.0004946500998695729\n",
      "tensor([[-5.4999e-04, -9.5916e-05,  1.9249e-04, -1.5268e-04, -2.6070e-04,\n",
      "          3.8823e-04, -2.8963e-04,  2.3026e-04],\n",
      "        [ 2.9675e-04,  1.0058e-04, -1.0830e-03,  6.1940e-05,  1.4843e-04,\n",
      "          5.9883e-04, -7.4660e-04,  1.0742e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1006)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 7 loss: 0.0004995102324567103\n",
      "tensor([[-1.7189e-04,  1.5136e-04,  2.2497e-04,  1.4207e-05,  4.5290e-04,\n",
      "         -1.5687e-05,  2.5722e-04, -3.0154e-04],\n",
      "        [-5.3539e-05,  3.7879e-04,  4.4079e-04, -3.4377e-04,  2.6212e-04,\n",
      "         -5.4864e-04, -1.2724e-04, -3.4696e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.0924)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 8 loss: 0.0005027686373638692\n",
      "tensor([[-1.3285e-04, -6.6843e-05, -1.7465e-04, -9.8826e-05,  7.1084e-06,\n",
      "          1.2503e-04,  6.7678e-05,  7.8988e-05],\n",
      "        [ 8.8065e-05, -3.9808e-04, -7.9807e-04,  5.1876e-04, -2.6346e-04,\n",
      "          1.5290e-04, -5.3707e-04,  3.2012e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1064)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 9 loss: 0.0004973563244684379\n",
      "tensor([[ 0.0005, -0.0005, -0.0001,  0.0006, -0.0005, -0.0002, -0.0003,  0.0003],\n",
      "        [ 0.0006, -0.0006, -0.0001,  0.0005,  0.0002, -0.0005, -0.0001,  0.0002]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1295)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 10 loss: 0.0005003411226024757\n",
      "tensor([[ 1.8178e-04,  4.8152e-04, -1.7836e-05, -1.5609e-04,  7.2624e-05,\n",
      "         -1.0328e-04, -8.4438e-05, -2.9180e-04],\n",
      "        [ 2.6039e-04,  2.7080e-04, -4.3076e-05,  2.5427e-04, -1.8637e-04,\n",
      "         -4.0139e-04, -2.3096e-04,  5.0537e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1377)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 11 loss: 0.0004989064929581421\n",
      "tensor([[-1.4908e-04, -5.4288e-04,  5.4837e-05, -1.9504e-04, -3.1975e-04,\n",
      "         -3.0097e-04, -4.1987e-04, -6.3412e-07],\n",
      "        [ 1.1631e-04, -1.7982e-04, -4.1816e-04,  7.6564e-04,  1.7378e-04,\n",
      "         -1.8906e-05, -1.2530e-04, -1.9258e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1482)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 12 loss: 0.0005011776321679606\n",
      "tensor([[-2.1872e-04,  2.1713e-04, -4.6510e-05, -3.0215e-04, -1.7709e-04,\n",
      "          5.4587e-04,  4.6866e-06,  4.5872e-06],\n",
      "        [ 9.7959e-05,  7.6909e-05,  9.9777e-05, -5.8346e-04, -2.2148e-04,\n",
      "          7.7860e-05, -3.5629e-04, -1.2554e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.0825)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 13 loss: 0.000503262788028477\n",
      "tensor([[-9.9827e-05, -6.7077e-05,  4.9159e-04, -8.1958e-05,  8.9860e-04,\n",
      "         -5.6071e-04,  9.4818e-05, -6.5169e-05],\n",
      "        [ 5.6908e-04,  5.1921e-04, -6.2504e-04,  1.6737e-04,  2.2497e-04,\n",
      "         -6.8916e-06, -4.0419e-04, -1.7667e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1022)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 14 loss: 0.0004998694245631878\n",
      "tensor([[-4.2291e-04,  4.1191e-04, -5.8713e-05,  2.9748e-04, -1.2168e-04,\n",
      "         -2.0947e-04, -3.2617e-04,  3.8415e-04],\n",
      "        [-4.7805e-04,  1.3169e-09, -2.6427e-04,  3.7622e-04, -4.9280e-04,\n",
      "          7.6648e-04, -5.9223e-04, -1.5327e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1050)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 15 loss: 0.0005017960854018517\n",
      "tensor([[ 6.4518e-05,  3.5000e-04, -3.5689e-04,  3.5678e-04,  9.6240e-06,\n",
      "          2.4773e-04, -6.2543e-04, -3.0815e-04],\n",
      "        [ 5.5686e-04,  7.7064e-05,  1.1332e-05,  3.6087e-04,  2.4256e-05,\n",
      "         -4.1171e-04, -3.6394e-04, -1.2447e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1066)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 16 loss: 0.0005015540226496076\n",
      "tensor([[-2.1397e-04, -1.2518e-05,  2.8387e-04,  5.5094e-05,  3.2047e-05,\n",
      "          3.5890e-04, -3.7134e-04, -1.3424e-04],\n",
      "        [-3.7616e-04,  3.5482e-04,  3.3076e-04,  2.5165e-04,  1.2545e-04,\n",
      "         -6.6273e-05,  2.3988e-04, -3.7519e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1123)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 17 loss: 0.0005024030721829865\n",
      "tensor([[ 5.9352e-05, -1.8866e-04,  1.4441e-04, -4.1873e-05, -4.9889e-04,\n",
      "         -1.5810e-05, -6.4825e-05, -1.5389e-04],\n",
      "        [-1.9091e-04, -3.7570e-05,  7.2781e-04, -7.2374e-05, -7.2173e-05,\n",
      "         -9.9546e-05,  6.8636e-04,  1.1889e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1179)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 18 loss: 0.0004983107706010984\n",
      "tensor([[ 1.0948e-05,  5.6932e-04, -7.5417e-06, -3.2362e-04, -9.1195e-05,\n",
      "          1.6207e-04, -3.4998e-04, -1.9523e-04],\n",
      "        [ 4.5243e-04, -8.8187e-06,  1.1509e-04, -1.6975e-04, -6.2360e-05,\n",
      "         -3.2508e-04, -2.1377e-04,  5.2895e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1175)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 19 loss: 0.0005007090408946129\n",
      "tensor([[ 0.0003, -0.0002, -0.0005, -0.0002, -0.0003,  0.0003, -0.0007,  0.0004],\n",
      "        [ 0.0004, -0.0003, -0.0004,  0.0005,  0.0004, -0.0006, -0.0004,  0.0002]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.0813)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 20 loss: 0.0005018071893559459\n",
      "tensor([[-7.1507e-04,  3.1732e-04,  3.4071e-04,  2.3187e-04,  1.5677e-06,\n",
      "          1.9486e-04,  2.6709e-04, -3.7623e-06],\n",
      "        [ 1.7488e-04, -3.7468e-05, -1.1622e-05,  4.1173e-04, -1.0651e-04,\n",
      "         -2.4210e-05,  4.7166e-04, -1.0839e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1496)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 21 loss: 0.0004960431056168244\n",
      "tensor([[ 4.3188e-04,  3.3889e-04, -1.5484e-04,  3.0356e-04,  8.2596e-05,\n",
      "          4.4395e-04,  4.1100e-04,  8.8619e-05],\n",
      "        [-6.7609e-04, -4.5686e-04,  5.9968e-04,  8.9678e-05, -7.3913e-05,\n",
      "          1.2773e-05, -1.2246e-04,  1.6489e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1192)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 22 loss: 0.000503985672625765\n",
      "tensor([[-3.4743e-04,  5.8482e-04, -8.6572e-04,  2.5106e-05, -4.0455e-04,\n",
      "          8.5972e-04,  4.2708e-04, -5.3421e-04],\n",
      "        [-4.0941e-04,  2.9936e-04,  4.4111e-04, -2.2519e-04, -5.4024e-04,\n",
      "         -4.5031e-04,  2.9357e-04, -5.9018e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1296)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 23 loss: 0.0005048384623609721\n",
      "tensor([[-5.3246e-05, -1.6517e-04, -4.1175e-04,  2.7028e-04, -1.5615e-04,\n",
      "          3.6988e-05, -2.4162e-04,  1.5575e-04],\n",
      "        [ 8.4391e-04,  5.1271e-05, -4.9051e-04,  3.2857e-04,  1.6599e-04,\n",
      "         -9.1380e-06, -4.1517e-04, -1.0148e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1298)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 24 loss: 0.0004915912100609313\n",
      "tensor([[ 4.1596e-05,  2.6955e-04,  3.9184e-04,  4.2027e-04,  6.2436e-04,\n",
      "         -2.4489e-04,  6.0061e-04, -1.4137e-05],\n",
      "        [ 4.0402e-04, -1.5925e-04, -1.5385e-05, -1.2491e-04, -8.7374e-05,\n",
      "         -1.2427e-04, -9.5959e-05, -7.6773e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1510)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 25 loss: 0.0005022737714979384\n",
      "tensor([[-2.9604e-05,  1.9824e-04, -2.0031e-04, -2.1611e-04,  2.3338e-04,\n",
      "          1.3926e-04, -3.3005e-04,  7.6605e-05],\n",
      "        [-2.4225e-04,  3.4791e-05, -5.1843e-04, -3.3581e-05,  5.1829e-04,\n",
      "          4.9292e-04, -7.4607e-04,  5.3956e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1509)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 26 loss: 0.0005004622302187335\n",
      "tensor([[-3.8898e-04, -7.0158e-05, -5.4744e-04, -1.3934e-04, -4.3276e-04,\n",
      "          5.8698e-04, -8.4849e-05, -7.8821e-05],\n",
      "        [-7.9524e-05, -6.0293e-04, -1.7338e-06,  3.7482e-04, -7.5304e-04,\n",
      "         -6.5970e-04, -1.3916e-04, -1.0533e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1401)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 27 loss: 0.0005032496323082361\n",
      "tensor([[ 1.3917e-04,  2.5306e-04, -4.3459e-04,  1.3644e-05,  1.1266e-04,\n",
      "          6.4223e-04, -5.7968e-04, -4.0944e-04],\n",
      "        [ 1.3247e-04, -1.9115e-04, -5.9813e-04,  3.4793e-05, -3.8122e-05,\n",
      "          4.0482e-04, -6.7851e-05, -3.5591e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1368)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 28 loss: 0.0004999818753726094\n",
      "tensor([[ 2.8518e-05, -2.8251e-04, -2.2709e-04,  7.7746e-05, -4.2627e-04,\n",
      "         -4.9283e-04, -2.8847e-04, -1.0504e-04],\n",
      "        [ 2.5631e-05, -5.3425e-05, -4.5295e-04,  4.6491e-04, -3.5055e-04,\n",
      "         -1.3243e-04, -1.8276e-04, -1.1036e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1127)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 29 loss: 0.0005039896597517848\n",
      "tensor([[-1.0941e-04,  7.4213e-05, -2.4614e-04,  3.6491e-04, -2.3453e-04,\n",
      "          5.5473e-04, -2.1337e-04,  7.4479e-05],\n",
      "        [ 4.0310e-06, -5.8318e-04, -2.8206e-04,  1.0056e-03, -6.2424e-04,\n",
      "          1.8291e-04, -1.8073e-04,  7.4038e-06]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.0939)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 30 loss: 0.0004993955408805385\n",
      "tensor([[-4.5718e-04,  7.9172e-06, -5.6892e-05, -2.2636e-04, -8.0315e-04,\n",
      "          8.4695e-05, -7.5723e-04,  4.2443e-04],\n",
      "        [ 3.3264e-04, -3.5476e-04, -1.4131e-04,  3.8553e-04, -5.4966e-04,\n",
      "         -3.8759e-04, -6.6175e-04,  1.9735e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1421)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 31 loss: 0.000497590243231597\n",
      "tensor([[ 2.4152e-04, -6.4318e-05,  1.9868e-04,  4.5710e-04,  2.1457e-04,\n",
      "         -3.6857e-04,  5.9479e-04, -7.3106e-05],\n",
      "        [ 4.5538e-04,  1.1538e-04,  2.5675e-04, -1.7614e-04,  1.5798e-04,\n",
      "         -1.6412e-04, -2.0329e-05, -2.6884e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1751)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 32 loss: 0.0004988952241337459\n",
      "tensor([[-1.1890e-04,  1.6697e-05, -1.3610e-04,  5.1189e-04,  2.1981e-04,\n",
      "          1.2039e-04,  2.2083e-04,  4.4913e-04],\n",
      "        [-6.3309e-04,  1.8239e-04,  2.1818e-04,  1.5686e-05,  9.7978e-05,\n",
      "          3.1766e-04,  4.5237e-04,  2.7845e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1577)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 33 loss: 0.0005005807559766847\n",
      "tensor([[-3.4042e-04,  1.4433e-04,  3.5255e-04, -5.6014e-04, -5.2275e-04,\n",
      "         -4.3029e-04, -1.6529e-04, -4.7910e-05],\n",
      "        [ 3.9253e-04, -1.7836e-05,  3.0208e-04, -2.7936e-04, -1.4768e-05,\n",
      "         -8.2375e-04, -2.6912e-04,  1.3540e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1016)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 34 loss: 0.0004980712593672518\n",
      "tensor([[-3.0481e-04, -2.7176e-04,  1.7670e-04, -2.7248e-04, -3.0464e-04,\n",
      "          2.2147e-04,  9.5715e-05, -1.6116e-04],\n",
      "        [-3.9600e-04, -2.9545e-05,  4.3540e-05, -2.7822e-04,  8.4546e-05,\n",
      "          4.1014e-04, -5.6350e-04, -2.6422e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1187)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 35 loss: 0.0005008297504028144\n",
      "tensor([[-0.0004, -0.0004,  0.0003,  0.0002, -0.0002, -0.0003, -0.0002,  0.0004],\n",
      "        [-0.0004, -0.0004,  0.0004,  0.0004, -0.0002, -0.0003,  0.0003,  0.0002]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1308)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 36 loss: 0.0005001037266461995\n",
      "tensor([[-1.6754e-04,  1.6408e-04,  9.2539e-05,  2.3910e-04,  2.7784e-05,\n",
      "          1.7726e-04, -4.4554e-05,  5.8900e-05],\n",
      "        [ 3.6749e-04,  2.1013e-04,  2.5219e-04, -2.2831e-05, -3.1254e-04,\n",
      "         -1.7831e-04, -2.6376e-04, -1.5298e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1569)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 37 loss: 0.0005017873403188345\n",
      "tensor([[-2.8259e-04,  1.1084e-04,  3.7310e-04,  3.9167e-04,  3.2389e-04,\n",
      "         -1.8352e-04,  6.9497e-05, -2.0991e-04],\n",
      "        [-9.2515e-04,  3.2749e-04,  6.3515e-04, -7.2080e-04,  5.4897e-04,\n",
      "          9.4290e-05,  4.2611e-04,  1.2199e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1806)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 38 loss: 0.0004992534848106724\n",
      "tensor([[ 3.7140e-04, -3.1896e-06, -1.8250e-04, -2.3809e-04,  1.9170e-04,\n",
      "          1.2673e-04, -1.3193e-04, -3.2908e-04],\n",
      "        [-1.4459e-04,  1.0653e-05, -2.3529e-04, -2.4121e-04,  4.7487e-04,\n",
      "         -1.3852e-04,  7.2260e-05, -5.0635e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1050)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 39 loss: 0.000502041087295628\n",
      "tensor([[-8.1276e-04,  7.8128e-05, -4.0664e-04, -8.6605e-05, -2.6195e-04,\n",
      "          5.9615e-04, -3.5139e-04,  2.4308e-04],\n",
      "        [-3.1400e-04, -1.4604e-04,  3.5615e-04,  3.3064e-04, -3.8787e-04,\n",
      "          5.7964e-05, -6.5930e-04,  1.2804e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1625)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 40 loss: 0.0005021481604945743\n",
      "tensor([[-3.2226e-04,  5.9368e-05,  1.9235e-04, -1.1525e-04, -1.5355e-04,\n",
      "          6.4445e-04,  1.5798e-04, -3.0195e-05],\n",
      "        [ 1.0118e-04,  1.5966e-04,  1.8708e-04, -8.5221e-05, -7.4173e-05,\n",
      "         -2.6139e-04, -7.7134e-04, -7.6630e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1249)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 41 loss: 0.0005024062979477677\n",
      "tensor([[-3.8160e-04, -4.1843e-05, -1.4317e-05, -5.3593e-04,  4.6545e-04,\n",
      "          6.5838e-05, -3.9061e-04, -1.8910e-04],\n",
      "        [-6.0907e-04, -1.4743e-05,  5.6453e-04,  1.3505e-04,  4.7409e-04,\n",
      "         -1.9640e-04,  4.7816e-04, -1.1525e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.0945)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 42 loss: 0.0004976136914335617\n",
      "tensor([[ 2.0429e-05, -2.3765e-04,  3.3580e-04,  3.4698e-04, -6.7409e-05,\n",
      "         -1.5878e-04,  5.1794e-04, -2.8933e-04],\n",
      "        [-6.1909e-05, -4.3612e-04,  5.2079e-05,  5.1273e-04, -4.5611e-04,\n",
      "         -2.6237e-04, -1.4992e-04, -1.1148e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.0917)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 43 loss: 0.0005032633650337507\n",
      "tensor([[-1.3007e-04,  2.5016e-04, -3.5455e-04, -1.3629e-04,  2.0897e-04,\n",
      "          3.0720e-04, -3.4981e-04,  4.3926e-05],\n",
      "        [-7.2596e-04,  4.3562e-04,  2.6090e-04, -4.2492e-05, -1.3364e-04,\n",
      "         -2.0957e-04, -3.7644e-04, -3.3403e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1207)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 44 loss: 0.0004991473799076895\n",
      "tensor([[-2.5260e-04, -2.2480e-04,  2.9712e-04,  5.4658e-05, -1.0585e-04,\n",
      "         -3.4035e-05, -1.3403e-04, -1.6535e-04],\n",
      "        [-4.9485e-04, -6.3940e-04, -1.4365e-04,  4.5790e-04, -5.5238e-04,\n",
      "          7.4559e-04, -6.0331e-04,  3.2554e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1817)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 45 loss: 0.0005029909381211294\n",
      "tensor([[-1.2090e-04,  5.6378e-04,  6.1414e-04,  2.4220e-05, -3.0973e-04,\n",
      "         -2.5069e-04,  2.7141e-04, -2.4274e-04],\n",
      "        [-1.1744e-04,  3.7024e-04,  1.5216e-04, -1.7991e-04,  1.2230e-04,\n",
      "         -3.7650e-05,  3.7909e-05,  1.5812e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1239)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 46 loss: 0.0005013074226526539\n",
      "tensor([[-1.2181e-04, -1.2548e-04, -7.3521e-05, -2.6859e-05, -6.1887e-05,\n",
      "          5.4648e-05, -3.4393e-04, -1.0833e-04],\n",
      "        [-3.4182e-04, -1.1259e-04,  8.6522e-05, -2.8890e-04, -7.3951e-05,\n",
      "          2.3930e-04, -7.9793e-04,  3.8109e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1258)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 47 loss: 0.0005010685288762472\n",
      "tensor([[-2.3040e-04, -3.2953e-04, -6.9063e-05,  4.0820e-04, -3.3291e-04,\n",
      "          2.0407e-04, -8.0126e-05,  3.7802e-05],\n",
      "        [-3.2326e-04,  2.6426e-04,  6.8629e-05,  7.9366e-05, -5.4271e-05,\n",
      "         -5.7261e-05, -3.4014e-04,  8.8289e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1825)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 48 loss: 0.000500687570018479\n",
      "tensor([[-2.2090e-04, -1.6468e-05, -6.9948e-04,  2.1556e-04, -3.0610e-05,\n",
      "          1.1569e-03, -4.6272e-04,  3.2993e-04],\n",
      "        [-3.8075e-04, -1.0021e-04,  4.0182e-04,  1.7248e-04, -1.9992e-05,\n",
      "         -7.8597e-05, -3.5524e-04,  5.2506e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1191)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 49 loss: 0.0004991480094334625\n",
      "tensor([[ 1.9946e-04, -1.0410e-04,  2.7027e-04,  5.4933e-04, -3.7296e-04,\n",
      "          1.4068e-04, -2.5452e-04,  1.0280e-04],\n",
      "        [ 3.8190e-04,  6.0317e-05,  5.2036e-05,  2.4886e-04, -3.1431e-04,\n",
      "         -2.2185e-04, -5.9012e-04, -2.1757e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1138)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 50 loss: 0.0004993677139282227\n",
      "tensor([[-1.7359e-04, -5.5084e-04,  1.3664e-04,  5.2218e-04, -6.0925e-05,\n",
      "         -5.1100e-04, -3.2049e-04,  2.5946e-04],\n",
      "        [ 1.2633e-05, -7.4204e-04,  4.0204e-04,  5.4718e-04,  1.9478e-04,\n",
      "         -3.0988e-04,  1.0425e-04,  2.3585e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1085)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 51 loss: 0.000501316331736492\n",
      "tensor([[-4.4995e-04,  4.1693e-04,  5.9710e-04, -3.4523e-05, -4.1231e-04,\n",
      "         -5.5159e-05,  4.4107e-05, -2.6424e-04],\n",
      "        [ 5.8177e-04, -7.0877e-05, -5.7822e-04,  3.4999e-04,  1.2277e-04,\n",
      "          5.7262e-04, -2.8710e-04, -2.9224e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.0660)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 52 loss: 0.0004990409826356958\n",
      "tensor([[-0.0002,  0.0002, -0.0002,  0.0003, -0.0001,  0.0006, -0.0004, -0.0004],\n",
      "        [-0.0013, -0.0004,  0.0004,  0.0004, -0.0002,  0.0005, -0.0003,  0.0003]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1222)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 53 loss: 0.000498196755406042\n",
      "tensor([[-3.4446e-04,  4.4904e-05,  3.3142e-04,  1.0967e-04, -2.9322e-04,\n",
      "          4.3690e-04, -2.1687e-04,  1.2180e-04],\n",
      "        [-5.8868e-04,  2.7826e-04, -2.0808e-04,  2.9954e-04, -2.9549e-04,\n",
      "          5.2183e-04, -1.7817e-04,  1.5658e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1300)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 54 loss: 0.0005005932680735177\n",
      "tensor([[-1.9819e-04,  9.5215e-05,  1.3110e-04,  4.1480e-04,  4.4346e-04,\n",
      "          4.0788e-04, -2.0753e-04, -2.7968e-04],\n",
      "        [-6.3079e-04, -3.6068e-06,  2.5020e-04,  3.1244e-04,  9.2926e-05,\n",
      "         -6.1293e-05, -2.3508e-04,  3.5264e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1570)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 55 loss: 0.0005029879968179039\n",
      "tensor([[-4.3465e-04,  1.2848e-04,  1.3534e-04, -2.6739e-04, -1.3102e-04,\n",
      "          7.8259e-04, -1.0723e-04, -8.9438e-05],\n",
      "        [-7.7171e-04, -1.4913e-05,  3.2864e-05, -1.5440e-04, -7.1940e-04,\n",
      "          3.7739e-04, -3.3820e-04, -2.5483e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1046)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 56 loss: 0.0005035192568134741\n",
      "tensor([[-1.5716e-04, -2.0296e-04,  2.0953e-04,  1.9868e-04,  4.5246e-05,\n",
      "          1.8351e-04, -4.3536e-05, -2.9023e-04],\n",
      "        [-3.3439e-05,  4.0047e-04, -1.6569e-04,  3.3343e-04,  5.8522e-05,\n",
      "          5.8768e-04, -2.9126e-05, -1.8469e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1111)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 57 loss: 0.0004998785945085379\n",
      "tensor([[ 2.5073e-04,  1.3968e-04, -2.9357e-04, -8.6282e-06, -1.6219e-04,\n",
      "          5.1662e-04, -6.8097e-04, -3.3361e-04],\n",
      "        [-8.1177e-04, -4.1752e-04,  7.2639e-05,  3.8684e-04, -4.8882e-04,\n",
      "          2.2599e-04, -6.5157e-04,  3.0129e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1066)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 58 loss: 0.0005013140326180822\n",
      "tensor([[-4.8750e-04, -6.3791e-04,  5.1944e-04,  2.2176e-04, -2.4352e-04,\n",
      "          1.6674e-04, -4.3787e-04,  6.0014e-05],\n",
      "        [-1.5447e-04,  1.6462e-04,  6.3250e-04,  4.9409e-05,  3.6327e-04,\n",
      "         -3.3442e-05, -5.3595e-04, -7.4489e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1178)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 59 loss: 0.0005041106830943714\n",
      "tensor([[ 1.0489e-04, -1.9911e-04, -9.0774e-05, -1.7864e-04, -1.1649e-04,\n",
      "         -3.5800e-05, -5.7019e-04, -2.3306e-05],\n",
      "        [-3.5569e-04, -1.7809e-04, -3.4362e-04,  5.3223e-05, -2.1308e-04,\n",
      "         -7.2462e-05, -9.2408e-04,  1.7616e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.0617)\n",
      "tensor(2.0796, grad_fn=<NllLossBackward0>)\n",
      "  batch 60 loss: 0.0005029291455085506\n",
      "tensor([[ 1.4940e-06, -1.4297e-04, -4.6670e-04,  3.8033e-04, -5.5871e-05,\n",
      "          1.1290e-04, -7.2434e-04,  2.4784e-04],\n",
      "        [-2.9258e-04, -1.3583e-05,  7.7947e-05,  1.8793e-04, -3.2131e-04,\n",
      "          7.7106e-04, -3.1341e-04, -7.7699e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.0559)\n",
      "tensor(2.0796, grad_fn=<NllLossBackward0>)\n",
      "  batch 61 loss: 0.0004990686751224453\n",
      "tensor([[-1.8079e-04,  1.0131e-04, -1.9785e-04,  2.7687e-04, -7.8075e-05,\n",
      "          3.2829e-04, -4.0287e-04,  1.1670e-05],\n",
      "        [-4.8756e-04, -2.7928e-04, -8.2902e-05, -2.4877e-04,  1.0707e-04,\n",
      "          4.5707e-06, -9.9865e-04,  1.3234e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.0656)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 62 loss: 0.0004980815384916203\n",
      "tensor([[-0.0003, -0.0006,  0.0002,  0.0006, -0.0002,  0.0002, -0.0003,  0.0002],\n",
      "        [ 0.0002, -0.0006, -0.0001,  0.0006,  0.0001, -0.0004, -0.0002,  0.0001]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1640)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 63 loss: 0.0004962780595110254\n",
      "tensor([[ 7.9194e-05, -4.4860e-04, -4.0933e-04,  5.2683e-04,  2.6120e-04,\n",
      "          2.7536e-04, -2.2794e-04, -2.8425e-05],\n",
      "        [-2.0121e-04, -6.0614e-04, -4.8265e-04,  9.5042e-04, -3.6264e-04,\n",
      "          2.3610e-04, -4.9514e-04,  5.4368e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.0382)\n",
      "tensor(2.0796, grad_fn=<NllLossBackward0>)\n",
      "  batch 64 loss: 0.0005002550015462141\n",
      "tensor([[-6.2827e-04,  1.2492e-04,  3.5107e-04,  3.2328e-04, -4.6802e-04,\n",
      "          2.9726e-04,  2.6191e-05,  2.4605e-04],\n",
      "        [-7.1891e-05, -6.1285e-04, -2.3541e-04,  8.9604e-05, -2.1564e-05,\n",
      "          1.1462e-04, -2.6519e-04, -1.2538e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1161)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 65 loss: 0.0005018046003511053\n",
      "tensor([[-7.7424e-04, -1.3585e-04,  2.3621e-04,  6.6607e-04, -5.8206e-04,\n",
      "          4.9265e-04, -3.3016e-04,  1.5184e-04],\n",
      "        [-6.7885e-04,  1.4776e-04, -2.0252e-04,  3.9460e-04, -5.9806e-04,\n",
      "          7.9695e-04,  2.5898e-04, -3.4327e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1492)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 66 loss: 0.0004987824189059595\n",
      "tensor([[-9.2539e-04, -1.8092e-05,  7.2234e-04, -2.7710e-04,  1.5419e-04,\n",
      "          2.1197e-05,  2.3202e-04,  2.5847e-04],\n",
      "        [-7.6789e-04,  1.1732e-04,  5.4672e-04, -2.6941e-04,  2.0590e-04,\n",
      "          2.3333e-04,  4.1134e-04, -2.5106e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.0954)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 67 loss: 0.0005020581829783883\n",
      "tensor([[ 1.6043e-04, -2.2207e-04, -5.0267e-04,  3.8544e-04,  6.8669e-05,\n",
      "          3.0311e-04, -1.2657e-04, -1.4763e-04],\n",
      "        [-3.9068e-04, -8.0436e-05, -1.7065e-04, -1.3960e-04, -1.5749e-04,\n",
      "          3.2185e-04, -2.9866e-04, -8.2348e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1581)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 68 loss: 0.0004980663482300535\n",
      "tensor([[-1.7554e-04, -1.7351e-04, -2.5527e-04,  7.3800e-06, -4.1479e-05,\n",
      "          3.4098e-04, -2.8204e-04,  4.2613e-05],\n",
      "        [ 4.9019e-06, -3.6000e-04, -1.7049e-05,  2.5765e-05, -2.7456e-04,\n",
      "          2.7549e-04, -5.1085e-04, -8.4582e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1369)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 69 loss: 0.0004958161070736806\n",
      "tensor([[ 3.7880e-04, -1.8385e-04, -2.6133e-04,  2.6913e-04, -4.0343e-04,\n",
      "          1.1368e-05, -3.0222e-04,  2.3442e-04],\n",
      "        [ 1.7067e-04, -2.7785e-04, -2.1869e-04, -2.9981e-04, -1.0797e-04,\n",
      "         -2.9917e-05, -4.7026e-04,  1.8151e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1198)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 70 loss: 0.0005001102060351938\n",
      "tensor([[ 1.6429e-04, -1.6290e-04, -7.1473e-04,  1.8592e-04, -4.6698e-05,\n",
      "          2.7965e-04, -3.9058e-04,  1.3566e-04],\n",
      "        [ 5.8593e-04,  3.1666e-04, -5.5798e-04,  2.7827e-04,  3.4197e-04,\n",
      "          1.0283e-04, -3.2995e-04, -2.4597e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.0842)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 71 loss: 0.0005030226003852627\n",
      "tensor([[-9.5717e-05,  3.5199e-04, -2.2815e-05, -2.1289e-04,  2.7356e-05,\n",
      "          5.6349e-04, -2.2845e-04, -8.6914e-05],\n",
      "        [-1.2286e-04, -1.1082e-04, -3.4255e-04, -2.2103e-04, -9.2982e-05,\n",
      "          2.9953e-04, -1.1746e-04,  3.5970e-06]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1243)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 72 loss: 0.0005009539642554541\n",
      "tensor([[-1.1391e-04,  2.4772e-04, -4.7962e-05,  1.3975e-04, -1.2573e-04,\n",
      "          1.3753e-04,  2.1118e-04, -5.4239e-06],\n",
      "        [ 5.1146e-06,  2.9019e-04,  2.4747e-05,  1.1772e-04,  4.8127e-05,\n",
      "          2.5771e-04,  1.1906e-04,  2.6027e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.0778)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 73 loss: 0.0004996402168548892\n",
      "tensor([[-7.8291e-05, -2.0752e-04, -1.3894e-04,  3.2798e-04, -8.6226e-05,\n",
      "         -4.8035e-05, -1.5620e-04,  1.0807e-04],\n",
      "        [-5.9389e-05,  3.3977e-04,  5.5446e-04,  6.2334e-05,  1.5195e-04,\n",
      "         -7.4365e-05,  1.4917e-04,  1.9224e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1502)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 74 loss: 0.0005021561058613736\n",
      "tensor([[-3.4910e-04,  2.0632e-04,  2.1019e-04,  3.5710e-04, -3.9927e-04,\n",
      "         -7.3100e-04, -3.5707e-04, -4.1447e-04],\n",
      "        [-4.8692e-04,  2.4806e-04,  1.6147e-04,  3.4525e-05,  8.7476e-05,\n",
      "          2.1252e-04, -9.4219e-05, -1.2042e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1163)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 75 loss: 0.0005015524124903662\n",
      "EPOCH 4:\n",
      "tensor([[-5.0131e-04,  4.5606e-04,  4.5388e-04, -1.8560e-04,  3.3295e-04,\n",
      "         -8.8359e-07,  3.5143e-04, -3.9335e-04],\n",
      "        [-6.1257e-04, -1.8355e-04,  6.9716e-04, -1.0499e-05, -2.6634e-04,\n",
      "         -1.8517e-04,  4.3735e-04, -3.0121e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1466)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 1 loss: 0.0004989024888073415\n",
      "tensor([[-8.4731e-05, -6.9699e-05, -1.3162e-04,  5.7077e-04,  3.7326e-04,\n",
      "          4.8957e-04,  2.4420e-04, -8.4173e-05],\n",
      "        [-4.9115e-04, -4.1172e-04,  6.4939e-04,  4.0538e-04, -2.7796e-05,\n",
      "         -2.5986e-04,  7.4146e-05,  2.5555e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1303)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 2 loss: 0.0005055756108650116\n",
      "tensor([[-1.1079e-04,  1.5223e-04,  3.5915e-04,  1.4035e-04, -3.0371e-04,\n",
      "          1.8085e-04,  1.2997e-04, -2.6004e-04],\n",
      "        [-3.8462e-04,  2.4060e-04,  1.6829e-04,  4.7096e-05,  1.4087e-04,\n",
      "          2.7463e-04,  3.4948e-04, -1.8586e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1232)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 3 loss: 0.0005053286708864233\n",
      "tensor([[ 1.6293e-04, -6.3864e-05,  2.7868e-04,  5.4615e-04,  1.0797e-04,\n",
      "         -3.8883e-04,  2.5958e-04, -1.9933e-04],\n",
      "        [-5.8452e-04,  3.0023e-04,  3.4501e-04, -1.1474e-04,  7.9923e-05,\n",
      "         -2.2772e-04,  1.1241e-04, -4.1628e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1312)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 4 loss: 0.0004986649222797055\n",
      "tensor([[-4.4679e-04, -1.7717e-04,  3.4408e-04, -3.6484e-04,  1.4219e-04,\n",
      "          5.1032e-05, -6.9048e-05,  2.4432e-04],\n",
      "        [ 2.3825e-04, -3.7284e-04,  4.9775e-04, -1.9694e-04,  3.6535e-04,\n",
      "         -4.7741e-04, -1.1154e-04, -2.6512e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1440)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 5 loss: 0.0004974682365307967\n",
      "tensor([[-2.2237e-04, -5.2654e-05,  1.9220e-04,  3.5380e-05,  7.9611e-04,\n",
      "         -5.3201e-05,  3.7910e-04, -1.3106e-04],\n",
      "        [-3.7204e-04,  5.7478e-04, -9.7421e-05, -7.7751e-05, -1.0203e-04,\n",
      "          6.4512e-05, -2.7816e-04,  3.9047e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1053)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 6 loss: 0.0005010719758918486\n",
      "tensor([[ 0.0003,  0.0004,  0.0002, -0.0003,  0.0002, -0.0003, -0.0004, -0.0001],\n",
      "        [ 0.0005,  0.0002, -0.0004, -0.0004,  0.0005,  0.0009, -0.0003,  0.0004]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1207)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 7 loss: 0.000501800055209274\n",
      "tensor([[ 1.8285e-05,  4.0637e-04,  1.7496e-04, -4.4482e-04,  3.2811e-05,\n",
      "         -1.7918e-05,  1.1341e-04,  4.2964e-06],\n",
      "        [ 1.6757e-04,  1.4190e-04, -6.2014e-05, -1.0015e-05,  3.6081e-04,\n",
      "         -4.3024e-04, -2.2597e-04, -2.7145e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1063)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 8 loss: 0.0005013132279266387\n",
      "tensor([[ 3.0768e-04, -2.3761e-05, -3.6060e-04, -1.5232e-04, -3.5581e-05,\n",
      "         -4.4902e-04, -2.1460e-04, -4.3589e-04],\n",
      "        [ 1.8611e-04,  1.5884e-04, -1.5999e-04, -5.8364e-05,  1.5867e-04,\n",
      "         -5.8480e-05, -4.6880e-06, -1.2984e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1196)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 9 loss: 0.0005003497850676932\n",
      "tensor([[-1.9296e-04, -1.4152e-04,  5.6579e-04,  3.6947e-04,  1.6535e-04,\n",
      "         -5.6782e-04, -2.7081e-04,  2.5503e-04],\n",
      "        [-9.2999e-04,  3.2997e-05,  5.4387e-04, -2.7451e-04, -3.5067e-04,\n",
      "          1.2988e-04,  2.7901e-04, -1.4868e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1216)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 10 loss: 0.0004977165311646268\n",
      "tensor([[ 3.3318e-04,  1.3648e-05, -3.8181e-04, -1.4081e-04, -1.0892e-04,\n",
      "          4.5210e-05, -5.3299e-04,  2.1481e-05],\n",
      "        [-1.8132e-04, -1.3425e-04,  1.6003e-04,  5.6928e-05, -9.0674e-05,\n",
      "          6.5810e-05, -1.5195e-04,  1.0787e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1461)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 11 loss: 0.0004989027176159586\n",
      "tensor([[ 1.2313e-04,  3.3208e-04, -1.9647e-04, -3.0349e-05, -1.0591e-04,\n",
      "          5.2597e-04, -1.8586e-04,  4.4428e-05],\n",
      "        [ 4.3651e-04, -3.0843e-04, -1.3938e-04,  3.7617e-04, -3.8587e-04,\n",
      "         -1.8925e-04,  1.5568e-04, -3.7151e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1233)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 12 loss: 0.0004997459119170138\n",
      "tensor([[-3.1915e-04,  3.7160e-04,  4.4766e-04, -4.6547e-04,  2.5258e-05,\n",
      "         -1.8823e-04, -1.7133e-04, -2.1325e-04],\n",
      "        [-1.1048e-04,  1.8926e-04, -1.0731e-04,  1.2905e-04,  2.0274e-05,\n",
      "          5.5348e-04, -4.1329e-04, -1.6920e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1580)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 13 loss: 0.0004993821427183124\n",
      "tensor([[ 3.2585e-04,  4.3494e-05,  2.2426e-04, -8.2398e-05,  3.7584e-04,\n",
      "         -3.6778e-04, -5.0472e-05,  2.5209e-04],\n",
      "        [ 4.5214e-04,  4.8934e-04, -5.5949e-05, -1.9804e-04,  3.6413e-04,\n",
      "         -8.6952e-05,  1.8049e-04,  1.8712e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.0955)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 14 loss: 0.000502766677443248\n",
      "tensor([[-3.3528e-04, -5.1987e-06,  8.7697e-04, -3.5605e-05, -1.4020e-04,\n",
      "         -3.1033e-04,  2.9317e-04, -3.6970e-05],\n",
      "        [-4.3166e-04, -7.0446e-05,  7.2050e-04,  2.1719e-05, -2.5709e-04,\n",
      "         -3.8074e-04,  2.8134e-04, -3.6256e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1136)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 15 loss: 0.000495106265658424\n",
      "tensor([[ 8.9401e-05, -6.1795e-04, -3.9456e-04,  4.1759e-05, -3.7468e-04,\n",
      "         -1.9935e-04, -7.6097e-04,  2.7322e-04],\n",
      "        [-4.6766e-05, -1.0730e-04, -2.7028e-04,  2.3356e-04, -4.2341e-04,\n",
      "          2.2376e-04, -3.1729e-04, -1.3233e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1312)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 16 loss: 0.0004989118699606458\n",
      "tensor([[ 5.8423e-05,  4.6107e-04, -4.5491e-04,  3.5244e-05, -1.0639e-04,\n",
      "          2.9198e-04, -4.0024e-05, -2.4159e-04],\n",
      "        [-1.7970e-04,  3.8476e-04, -6.6951e-04, -3.2984e-04,  1.6820e-04,\n",
      "          3.2066e-04, -3.6899e-04,  7.0656e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1336)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 17 loss: 0.0005025232742811068\n",
      "tensor([[-3.2000e-05, -9.6724e-06,  3.5217e-04, -1.8260e-05,  4.0974e-04,\n",
      "         -3.5737e-04,  3.2360e-04,  1.3820e-04],\n",
      "        [ 5.0712e-05, -4.2752e-04,  1.1272e-04, -4.1379e-04,  1.7305e-04,\n",
      "         -4.9740e-04,  1.4133e-04,  9.6234e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1237)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 18 loss: 0.0005004664190409416\n",
      "tensor([[-2.7656e-04, -2.5352e-04,  7.5658e-04,  2.5115e-04,  3.9027e-04,\n",
      "         -3.6306e-05,  6.0712e-04, -1.8479e-05],\n",
      "        [ 3.3997e-04, -9.8151e-05, -3.2514e-04,  1.5396e-04, -2.0747e-05,\n",
      "         -2.2783e-04, -5.8107e-05,  1.2876e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1293)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 19 loss: 0.000500829348444709\n",
      "tensor([[ 3.2967e-04, -1.5863e-04, -2.3224e-04,  3.0847e-04,  1.4147e-04,\n",
      "          1.5706e-04, -7.2990e-06,  8.2918e-06],\n",
      "        [-3.6444e-05,  3.5388e-05,  3.2484e-04, -6.4072e-04,  2.3349e-05,\n",
      "         -4.2759e-05,  6.7917e-06, -9.6741e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1185)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 20 loss: 0.0004986624065920603\n",
      "tensor([[-3.7948e-04,  8.6073e-05,  1.1345e-04, -2.1238e-04, -5.4263e-04,\n",
      "         -1.7563e-04, -4.6026e-04, -1.3026e-04],\n",
      "        [-4.3869e-06,  5.6785e-04,  3.3672e-05, -2.5045e-04,  2.5882e-04,\n",
      "         -2.2654e-04, -2.5749e-04, -4.2744e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1284)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 21 loss: 0.000499139024383794\n",
      "tensor([[ 4.1143e-04,  5.9086e-05, -4.8565e-05, -3.9655e-04,  1.7171e-04,\n",
      "         -4.0298e-04, -3.3634e-07, -2.2659e-04],\n",
      "        [ 1.4916e-06,  7.6132e-05, -3.2344e-04, -2.1569e-04,  1.8436e-04,\n",
      "         -3.9420e-04, -3.3797e-04, -4.6017e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1407)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 22 loss: 0.0004960469730937754\n",
      "tensor([[-5.8343e-05,  2.3177e-04,  1.0382e-04,  6.3500e-04, -6.3741e-04,\n",
      "          2.2437e-04, -1.6784e-04, -3.7275e-04],\n",
      "        [-2.8328e-04, -7.8382e-04,  1.9827e-04,  3.0680e-04, -2.0259e-04,\n",
      "         -9.1871e-05,  2.5075e-04,  3.5284e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1109)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 23 loss: 0.0004991618590004675\n",
      "tensor([[ 1.5275e-04, -2.3887e-04, -6.1088e-04,  3.0801e-04, -2.4562e-04,\n",
      "         -3.7413e-04, -7.0236e-05, -6.8360e-05],\n",
      "        [-3.3986e-04,  2.3204e-04, -6.3914e-05, -3.5521e-05, -3.4993e-04,\n",
      "         -2.2919e-04,  6.7244e-04, -3.1651e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1167)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 24 loss: 0.0004992724323616165\n",
      "tensor([[ 5.5314e-05,  2.9041e-05,  5.7034e-04,  3.0202e-04, -3.5510e-04,\n",
      "         -5.5823e-04,  1.5705e-04, -6.5529e-04],\n",
      "        [ 1.3218e-04,  1.1642e-04,  7.6434e-04,  7.3558e-04,  1.0618e-04,\n",
      "         -6.2881e-04,  3.1394e-04, -4.8534e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1170)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 25 loss: 0.0004993828870606583\n",
      "tensor([[ 7.3628e-05,  1.8905e-04, -1.1974e-04,  3.0076e-04, -3.7662e-04,\n",
      "         -2.6348e-04, -9.5349e-05, -1.2379e-04],\n",
      "        [-4.5974e-04, -2.0996e-04,  6.3553e-04, -2.8338e-04,  1.2944e-05,\n",
      "         -2.3804e-04,  6.2449e-04, -1.8772e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1410)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 26 loss: 0.0004951079686482747\n",
      "tensor([[ 1.1938e-04, -4.1531e-05,  4.2875e-05, -3.3662e-04, -1.2260e-04,\n",
      "         -1.0584e-04,  1.3260e-04, -2.2975e-04],\n",
      "        [-2.7517e-04, -2.4192e-04,  3.0897e-04, -4.4516e-04,  3.3477e-05,\n",
      "         -2.4113e-04,  1.9203e-04, -2.5979e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1298)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 27 loss: 0.0005007054241427507\n",
      "tensor([[-2.7471e-04, -1.1395e-04, -1.9984e-04,  3.0598e-04, -3.4620e-04,\n",
      "          3.5203e-04,  3.2182e-04,  1.2579e-04],\n",
      "        [-7.9815e-05,  1.0027e-04,  3.5185e-04,  2.2709e-04,  1.4378e-04,\n",
      "         -2.0276e-04,  2.6769e-04, -5.6739e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1030)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 28 loss: 0.0004980745715295483\n",
      "tensor([[ 5.1378e-05, -3.0505e-05,  5.6994e-05, -5.7579e-05,  5.5193e-04,\n",
      "         -7.7469e-05,  3.6131e-04, -1.1342e-04],\n",
      "        [ 3.6577e-04,  5.1850e-05, -2.8061e-04, -2.6957e-04,  1.7211e-04,\n",
      "          2.1650e-04, -2.2534e-04, -5.5589e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1243)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 29 loss: 0.0005027617776416949\n",
      "tensor([[-5.5416e-06, -1.5926e-04,  4.4055e-05,  1.6503e-04, -2.0978e-04,\n",
      "         -3.4396e-04, -1.3626e-04,  9.4965e-05],\n",
      "        [ 7.6765e-04,  1.7879e-04, -6.9092e-04,  2.3646e-04,  1.5081e-04,\n",
      "          1.2270e-04, -3.6585e-04, -5.9169e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1195)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 30 loss: 0.0005010741590017295\n",
      "tensor([[ 2.9917e-04,  3.0151e-04, -4.0453e-04, -2.1846e-04,  2.2133e-04,\n",
      "         -3.2908e-04, -1.4951e-05, -2.6829e-04],\n",
      "        [-3.1926e-05, -9.3661e-05,  4.4156e-04,  5.4525e-05,  7.2558e-05,\n",
      "         -1.7014e-04,  2.0218e-05, -1.4942e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1302)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 31 loss: 0.0005015524124903662\n",
      "tensor([[ 4.0093e-04,  1.8207e-04, -8.8160e-05,  1.1951e-04,  4.6273e-04,\n",
      "          4.6933e-05,  3.1687e-04,  1.3390e-04],\n",
      "        [ 9.4155e-05,  8.2199e-05, -1.0405e-04,  1.6918e-04,  8.9302e-05,\n",
      "         -2.8916e-05, -3.8626e-04, -1.6781e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1300)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 32 loss: 0.0005014336537475439\n",
      "tensor([[ 5.8298e-06,  9.0230e-05,  7.9686e-05,  3.6621e-04, -1.3638e-04,\n",
      "          5.0475e-04,  2.0191e-04, -1.2768e-06],\n",
      "        [ 2.0583e-04,  3.8311e-04, -5.1202e-04,  2.3374e-04,  5.0073e-04,\n",
      "          7.4882e-05, -2.8462e-04,  2.1855e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1470)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 33 loss: 0.0005003448514782316\n",
      "tensor([[ 9.2459e-05,  2.3179e-04, -2.2243e-04, -7.5254e-05, -4.0896e-05,\n",
      "          5.9218e-05, -7.5444e-05, -2.0050e-04],\n",
      "        [-1.3823e-04,  9.0700e-05, -1.6272e-04,  2.3367e-04, -9.5282e-05,\n",
      "          5.3432e-05, -9.1179e-05,  9.9878e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1182)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 34 loss: 0.000503500437332412\n",
      "tensor([[ 4.5622e-04,  1.4149e-05, -1.6791e-04,  5.4907e-05, -2.9482e-04,\n",
      "         -3.0581e-04,  2.6725e-05, -8.4016e-05],\n",
      "        [-2.6651e-04, -8.2739e-05,  4.9091e-04,  3.9946e-04, -5.5880e-05,\n",
      "         -2.3593e-04,  7.0800e-04,  3.9541e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1091)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 35 loss: 0.0005017957977346472\n",
      "tensor([[-5.9977e-04,  2.0955e-04, -5.2264e-04, -2.0489e-04, -9.5699e-05,\n",
      "          5.3506e-04, -1.1642e-04,  1.8438e-04],\n",
      "        [-1.0601e-04, -5.2294e-05,  2.4159e-04,  1.4343e-04, -2.6787e-04,\n",
      "          1.4163e-05, -4.5095e-04,  1.0842e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1327)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 36 loss: 0.0005025217762426687\n",
      "tensor([[ 2.9569e-04,  1.8257e-04, -1.1201e-04, -7.0000e-05,  3.1195e-04,\n",
      "          2.2565e-04, -1.7972e-04, -4.3065e-04],\n",
      "        [-2.8065e-04, -5.4047e-05,  4.6448e-04, -2.1802e-04,  2.8601e-04,\n",
      "         -8.3585e-05,  1.7457e-04, -3.5292e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1176)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 37 loss: 0.000500948048304202\n",
      "tensor([[ 4.6136e-05,  3.6461e-04,  7.9652e-04, -2.4472e-04,  2.1996e-04,\n",
      "         -4.1133e-04,  3.9352e-04,  1.3304e-04],\n",
      "        [-2.6591e-04,  3.9132e-04,  5.2945e-04,  9.3233e-05,  2.9565e-04,\n",
      "         -3.5879e-04,  4.5582e-04,  1.5270e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1146)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 38 loss: 0.0005005893652176249\n",
      "tensor([[ 9.0235e-05,  5.0700e-04, -2.2246e-04, -6.5533e-04,  1.0946e-04,\n",
      "          9.3796e-05, -2.3653e-04, -4.3718e-04],\n",
      "        [ 1.9144e-05, -4.8410e-04,  2.1286e-04,  3.7444e-05, -3.1894e-04,\n",
      "         -3.7787e-04, -2.5283e-04,  3.7185e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1239)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 39 loss: 0.0005024088324772387\n",
      "tensor([[-6.3784e-05,  1.1362e-04, -3.3980e-04,  1.0608e-04, -1.9292e-04,\n",
      "          4.0917e-04,  5.9775e-05, -7.5001e-05],\n",
      "        [ 4.1896e-04, -1.9619e-04,  1.5333e-04, -1.2336e-04,  4.3239e-04,\n",
      "         -2.9733e-04,  2.8266e-05,  2.7040e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1365)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 40 loss: 0.0004989003723276325\n",
      "tensor([[-3.0929e-04,  2.0325e-04,  2.3735e-05, -3.7670e-05,  2.6937e-04,\n",
      "          1.0532e-04,  4.6901e-04,  2.7715e-04],\n",
      "        [-7.3543e-04,  1.4922e-04,  2.9164e-04, -2.3044e-06,  3.3171e-04,\n",
      "          2.1204e-04,  4.9650e-04, -4.2744e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1153)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 41 loss: 0.0004985469103831234\n",
      "tensor([[-1.9999e-05, -3.7168e-04,  1.6185e-04,  2.7656e-04, -2.4604e-04,\n",
      "         -1.0326e-04, -1.8909e-04, -1.8040e-05],\n",
      "        [-1.3903e-04, -5.0096e-04,  3.0824e-04, -7.0740e-06, -1.7233e-04,\n",
      "         -1.2111e-04,  1.3858e-04,  4.3758e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1234)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 42 loss: 0.0004992646472651561\n",
      "tensor([[ 4.1368e-04, -3.8159e-05, -6.0472e-04, -5.2011e-04,  1.8679e-04,\n",
      "          4.3714e-04, -1.6308e-04, -7.9783e-05],\n",
      "        [ 3.8659e-04,  4.0447e-04,  2.9167e-04, -6.1110e-04,  3.2559e-04,\n",
      "         -2.4303e-04, -8.3740e-05, -3.5417e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1323)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 43 loss: 0.000500341179969795\n",
      "tensor([[ 1.1306e-04, -3.8753e-04, -2.3376e-04, -3.4826e-05,  3.1294e-05,\n",
      "         -2.1448e-04, -3.0647e-04, -1.7719e-04],\n",
      "        [ 1.1690e-04, -5.9363e-04, -4.2268e-05,  2.4683e-04, -1.3937e-04,\n",
      "          1.4129e-04,  4.0667e-05, -9.4946e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1277)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 44 loss: 0.000501792978596043\n",
      "tensor([[-2.4542e-06,  2.2830e-04,  2.1264e-04, -1.5971e-04, -9.8861e-05,\n",
      "         -2.1504e-04,  2.3823e-04, -1.1289e-04],\n",
      "        [ 1.1420e-04,  5.0869e-04,  1.0754e-05, -5.5326e-04,  2.0687e-04,\n",
      "         -1.3135e-04,  5.5835e-05, -1.3533e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1444)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 45 loss: 0.0004947563877509601\n",
      "tensor([[-8.4229e-04,  5.6681e-04,  4.4522e-05, -3.5500e-04, -2.0150e-04,\n",
      "          6.0664e-04,  2.6432e-04, -5.2660e-06],\n",
      "        [-3.2895e-04, -1.5373e-05,  5.8531e-04,  4.1575e-05, -1.3561e-04,\n",
      "         -6.2085e-04,  2.5321e-04, -3.3777e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1409)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 46 loss: 0.000501544591716908\n",
      "tensor([[-1.3637e-05,  4.2795e-05,  1.9975e-04, -5.0244e-05, -5.7383e-04,\n",
      "         -6.9451e-04, -8.4124e-04, -1.7117e-04],\n",
      "        [ 3.9086e-04,  5.4375e-04, -8.8334e-05,  3.8543e-05,  9.4495e-05,\n",
      "         -3.3724e-04, -2.8616e-04, -5.7520e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1162)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 47 loss: 0.0005013175962516175\n",
      "tensor([[-4.6066e-05, -1.1373e-05,  5.1232e-04,  4.4334e-06,  3.9246e-04,\n",
      "         -5.2969e-04,  2.9522e-04, -6.4625e-05],\n",
      "        [ 1.4174e-05, -6.8964e-05,  5.7351e-05,  1.2550e-04,  3.9484e-05,\n",
      "         -3.4714e-04,  1.4090e-04, -1.2600e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1546)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 48 loss: 0.0004984196400482382\n",
      "tensor([[-2.1673e-04,  5.9166e-04,  3.8353e-04, -2.1428e-04,  1.4515e-04,\n",
      "         -1.1002e-04,  3.2602e-04, -4.1931e-04],\n",
      "        [-1.3172e-05, -2.0349e-04, -2.4222e-04,  1.2325e-04, -1.5650e-04,\n",
      "          5.1869e-05, -1.0764e-04, -1.2162e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.0855)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 49 loss: 0.000500837100493885\n",
      "tensor([[ 1.0123e-04,  3.3664e-04, -2.8138e-04, -5.4209e-04,  1.0040e-03,\n",
      "         -1.0777e-04,  2.2732e-04, -3.4918e-04],\n",
      "        [ 3.0423e-04,  2.2325e-04, -2.4078e-04, -7.0980e-05,  2.5440e-04,\n",
      "         -1.0692e-04, -2.9593e-04, -5.7296e-06]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1333)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 50 loss: 0.0005014283645000693\n",
      "tensor([[ 2.6313e-04,  6.6735e-04, -2.6857e-04,  1.3910e-04, -1.9779e-04,\n",
      "          1.1180e-04, -1.5990e-04, -3.2235e-04],\n",
      "        [ 7.5376e-04,  3.0076e-04, -2.4922e-04,  5.4617e-05, -2.7776e-05,\n",
      "         -4.8960e-04, -4.3905e-04, -4.6993e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.0837)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 51 loss: 0.0005015744946742484\n",
      "tensor([[ 1.6674e-04,  4.9373e-06, -3.6004e-04,  8.9965e-05, -1.5479e-04,\n",
      "          1.8198e-04, -2.3604e-04, -1.1749e-04],\n",
      "        [-2.7808e-04,  3.2047e-04, -1.0294e-04, -1.0232e-04, -4.6562e-05,\n",
      "          1.8548e-04,  8.6197e-05, -6.2503e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1260)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 52 loss: 0.000502035964346922\n",
      "tensor([[-2.0064e-04, -2.9025e-04,  9.9296e-05, -2.7216e-05, -1.7491e-05,\n",
      "         -2.9893e-04,  6.3073e-05,  3.1216e-04],\n",
      "        [ 3.2441e-04, -9.4717e-05, -3.7696e-04, -2.3233e-04, -7.5422e-05,\n",
      "          8.0094e-06, -5.3913e-04,  7.0344e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1049)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 53 loss: 0.0004992680818665357\n",
      "tensor([[ 5.3855e-04,  1.0484e-04, -2.2768e-04,  2.5205e-04, -3.5536e-04,\n",
      "         -7.1005e-04, -3.7756e-04, -6.2314e-04],\n",
      "        [ 9.7129e-05,  2.3921e-05,  2.4205e-04,  1.5850e-04, -3.1653e-04,\n",
      "         -4.7822e-04, -4.1639e-04, -2.9113e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.0905)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 54 loss: 0.0004902128226798641\n",
      "tensor([[-2.7159e-04, -6.0702e-05, -2.3947e-04,  9.4797e-05, -5.5997e-04,\n",
      "          6.6819e-04, -1.8387e-04,  2.4691e-05],\n",
      "        [-2.7343e-04, -2.8353e-05, -2.3996e-04, -6.7018e-06, -3.0130e-04,\n",
      "          8.9654e-05, -3.1255e-05,  3.4192e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1203)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 55 loss: 0.0005021589846174603\n",
      "tensor([[-5.8230e-05,  2.4741e-04,  1.7111e-04,  4.3416e-04, -1.8153e-04,\n",
      "          2.7014e-05, -7.6940e-05,  6.8544e-05],\n",
      "        [-4.3048e-04,  5.7330e-05,  4.5004e-04,  1.4159e-04, -2.8128e-04,\n",
      "         -3.6502e-04,  8.3850e-05, -2.5874e-06]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1087)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 56 loss: 0.0005033811510575941\n",
      "tensor([[ 8.0024e-05,  1.0261e-04, -2.3234e-04,  2.9533e-04,  9.2633e-05,\n",
      "          1.8186e-04, -2.3426e-05, -2.7111e-05],\n",
      "        [-6.4085e-05,  3.5623e-04, -2.2885e-04,  3.1877e-04,  2.2291e-04,\n",
      "          2.9967e-04, -2.0468e-04, -9.9327e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1239)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 57 loss: 0.0004993862079726631\n",
      "tensor([[ 1.3977e-04, -3.1409e-04, -3.7403e-04, -2.5776e-04,  4.8958e-05,\n",
      "         -1.2762e-04, -1.6058e-04,  2.8004e-04],\n",
      "        [-1.5301e-05, -3.9574e-04, -3.7642e-05, -3.8446e-04, -9.2302e-04,\n",
      "          7.4973e-05, -2.7818e-04, -1.1496e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1406)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 58 loss: 0.0005025171092767655\n",
      "tensor([[ 8.6463e-05,  2.6797e-04,  1.4144e-04,  4.3708e-04, -4.0411e-05,\n",
      "          2.6023e-04,  6.3252e-05, -3.5445e-04],\n",
      "        [ 1.6704e-04,  2.4389e-04, -1.9029e-04, -2.6336e-04,  3.9342e-04,\n",
      "         -1.0202e-05,  2.9938e-04, -6.2508e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1171)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 59 loss: 0.0005001137037584563\n",
      "tensor([[-4.5268e-05,  1.1796e-04, -2.8454e-04, -2.3413e-04,  1.6475e-04,\n",
      "          8.8240e-05,  3.2954e-04,  2.9229e-05],\n",
      "        [ 2.5504e-04, -1.8240e-04, -8.7728e-04,  3.5229e-04, -9.9129e-05,\n",
      "          7.4411e-05, -1.6065e-04,  2.0077e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1135)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 60 loss: 0.0005013160443466907\n",
      "tensor([[ 7.6826e-04,  2.5884e-04,  6.9206e-06, -1.4106e-04,  6.0543e-04,\n",
      "         -1.8596e-04,  3.0704e-04, -6.6842e-04],\n",
      "        [ 3.2017e-04,  5.1238e-05, -8.3751e-05, -2.6338e-04, -3.2508e-04,\n",
      "          1.1708e-04, -7.7323e-05,  2.8288e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1331)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 61 loss: 0.0004994971747012371\n",
      "tensor([[-2.3558e-04,  2.7762e-04,  1.6011e-04,  7.2691e-05, -2.7591e-04,\n",
      "         -2.1810e-04,  1.3605e-04, -6.6680e-05],\n",
      "        [ 1.9043e-04,  1.2023e-04, -2.6859e-04,  4.6800e-06, -1.4599e-04,\n",
      "         -6.1645e-04, -2.9218e-04, -2.2646e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1253)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 62 loss: 0.0005001075110680899\n",
      "tensor([[-1.2971e-04,  2.5163e-04,  2.4821e-04,  1.7884e-04, -2.5060e-04,\n",
      "         -1.9905e-04,  3.1766e-04, -4.1026e-04],\n",
      "        [ 1.1162e-04,  3.2957e-04,  1.6901e-06,  3.5346e-04, -1.6333e-05,\n",
      "         -4.1041e-04,  2.8033e-04, -5.6090e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1311)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 63 loss: 0.0005049629660704114\n",
      "tensor([[ 7.0119e-05,  7.5307e-05, -7.8123e-04, -8.7701e-06,  8.9953e-05,\n",
      "          9.5920e-04, -3.3517e-05,  3.0728e-04],\n",
      "        [-3.5505e-05,  5.2027e-05,  3.0648e-04, -1.5314e-04,  1.2061e-04,\n",
      "         -2.5760e-04,  3.2396e-05,  4.5106e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1058)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 64 loss: 0.0005047292963972369\n",
      "tensor([[ 4.1537e-04,  2.3588e-05, -5.4193e-04,  3.1235e-04,  3.3136e-04,\n",
      "          4.5310e-05,  1.8899e-04, -3.1557e-04],\n",
      "        [-8.6439e-05,  8.7041e-05, -2.0518e-04, -2.7315e-04,  3.3061e-05,\n",
      "          8.2137e-05,  2.6602e-05, -2.7001e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1128)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 65 loss: 0.0005057044762117853\n",
      "tensor([[-5.9570e-05, -3.7331e-04, -6.6608e-06, -2.6216e-04, -1.8743e-04,\n",
      "         -3.6821e-04, -2.2965e-04, -8.1759e-05],\n",
      "        [ 1.9554e-04, -4.1200e-05, -5.1302e-04,  6.8886e-04,  3.3641e-04,\n",
      "         -6.3852e-05,  8.0581e-05, -9.8141e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1048)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 66 loss: 0.0005032583450878693\n",
      "tensor([[ 2.4846e-05,  5.7129e-04, -4.0841e-04, -1.9910e-04,  6.8520e-04,\n",
      "          2.4121e-04,  2.6412e-05, -1.5432e-04],\n",
      "        [-4.0722e-04,  6.8809e-04,  3.9942e-04,  2.6877e-04,  1.7157e-04,\n",
      "         -3.2470e-04,  8.8743e-04, -5.9124e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.0973)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 67 loss: 0.0005008364688454336\n",
      "tensor([[-5.9388e-05, -1.7652e-04,  1.5146e-05,  4.0569e-04, -9.7269e-05,\n",
      "          1.3280e-04, -1.7588e-04,  1.3111e-04],\n",
      "        [ 7.0869e-05,  1.5425e-04, -3.0828e-04, -2.0292e-04,  1.3398e-04,\n",
      "          6.5857e-05,  1.3436e-04, -4.4804e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1064)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 68 loss: 0.0005016811218997969\n",
      "tensor([[-5.0129e-06,  3.0688e-04, -5.4762e-04, -1.3707e-04,  3.5257e-05,\n",
      "          3.0451e-04, -2.3304e-04, -2.2120e-04],\n",
      "        [ 5.0590e-04, -2.6347e-04, -6.9594e-05,  6.7606e-04, -4.2265e-04,\n",
      "         -1.8342e-04,  6.9371e-05,  9.8362e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1188)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 69 loss: 0.0005039891396918692\n",
      "tensor([[-3.7502e-04,  2.6211e-04,  3.8060e-05, -2.4330e-04, -5.6025e-04,\n",
      "          4.7754e-05, -3.8943e-04, -4.0280e-05],\n",
      "        [ 6.0192e-05, -7.8126e-05,  3.8329e-04,  2.6795e-04, -3.3230e-04,\n",
      "         -2.3901e-04, -8.9178e-05, -1.5648e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1551)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 70 loss: 0.0004991433738345889\n",
      "tensor([[ 2.0910e-04, -1.4456e-04, -7.7809e-04,  5.0095e-04, -1.3698e-04,\n",
      "          4.6717e-04, -1.6900e-05, -2.4582e-05],\n",
      "        [ 1.1224e-04, -1.7708e-04, -1.2822e-04,  7.5207e-05, -4.8267e-05,\n",
      "         -5.0027e-05,  1.8277e-04, -1.4819e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1333)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 71 loss: 0.000499622401338767\n",
      "tensor([[ 6.6982e-05,  5.5860e-04,  1.7118e-04, -1.0038e-04,  4.8882e-04,\n",
      "         -2.1840e-04, -9.9646e-05, -7.9203e-05],\n",
      "        [ 1.5983e-04,  4.8192e-07, -2.5413e-04,  1.5597e-04,  2.6442e-04,\n",
      "          1.3112e-04,  9.1761e-05, -2.6738e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1407)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 72 loss: 0.000506190269343925\n",
      "tensor([[ 1.8061e-04, -2.3305e-04, -5.9164e-04,  1.3213e-04, -2.8783e-04,\n",
      "          4.6735e-04, -3.8812e-04, -1.8761e-04],\n",
      "        [ 1.1018e-04,  1.1413e-04, -1.3066e-04,  2.6174e-04, -4.3749e-04,\n",
      "          9.5789e-05, -2.5447e-04, -4.2164e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1069)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 73 loss: 0.0005039890241229991\n",
      "tensor([[ 3.4089e-04, -2.9214e-04, -1.2061e-04,  2.7461e-04, -1.3770e-04,\n",
      "         -1.3988e-04, -5.2402e-05, -9.3162e-05],\n",
      "        [ 3.3859e-04, -4.8254e-04,  4.5811e-04,  5.7474e-04, -8.8129e-04,\n",
      "         -4.0791e-04, -4.2147e-04, -5.6767e-06]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1119)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 74 loss: 0.000496999825391897\n",
      "tensor([[ 1.6847e-04, -1.0615e-05, -5.6357e-04,  3.9539e-04, -4.9531e-04,\n",
      "         -2.1671e-05,  1.6155e-04, -3.3941e-04],\n",
      "        [ 2.6254e-04,  3.5284e-05, -3.3061e-04,  5.9011e-05, -3.9700e-05,\n",
      "         -1.9553e-04, -9.0980e-06,  2.3602e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1487)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 75 loss: 0.000497000053325529\n",
      "EPOCH 5:\n",
      "tensor([[-0.0006,  0.0007, -0.0001, -0.0004, -0.0006,  0.0006, -0.0002, -0.0006],\n",
      "        [-0.0004,  0.0001,  0.0007, -0.0005, -0.0001, -0.0002,  0.0004, -0.0006]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1271)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 1 loss: 0.0004987877374302715\n",
      "tensor([[-3.2977e-04, -1.1424e-04,  3.0469e-05, -3.9518e-04, -2.0277e-04,\n",
      "          1.5352e-04, -3.8270e-04, -2.7339e-04],\n",
      "        [-1.5732e-04,  4.1640e-04,  6.7104e-04, -3.8263e-04, -5.9696e-04,\n",
      "         -1.1868e-04, -1.6096e-05, -2.5185e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1184)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 2 loss: 0.0005013103540286263\n",
      "tensor([[-4.9211e-04, -5.4099e-04,  6.0052e-04, -1.0445e-04, -6.5303e-04,\n",
      "         -2.2064e-04,  4.1591e-04,  8.5168e-05],\n",
      "        [-5.2008e-04, -1.2562e-06,  4.0668e-04, -3.3140e-04, -8.6269e-04,\n",
      "         -7.6737e-05,  1.5666e-04, -2.0645e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1270)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 3 loss: 0.0005030086436130947\n",
      "tensor([[-3.8021e-04,  1.3235e-04,  5.2349e-05, -5.8839e-05,  2.1594e-04,\n",
      "          1.5922e-04,  4.4269e-04,  3.0980e-04],\n",
      "        [-7.7252e-04,  8.9184e-05,  3.2910e-04,  8.7805e-06,  2.8879e-04,\n",
      "          2.5083e-04,  4.5825e-04, -1.4686e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1330)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 4 loss: 0.0005020392453365428\n",
      "tensor([[ 1.5675e-04,  2.2937e-04, -8.4732e-05, -3.6457e-04, -2.1533e-04,\n",
      "          1.0441e-04, -6.6316e-06, -3.0116e-04],\n",
      "        [ 5.4843e-05,  6.6656e-04, -1.0875e-04, -1.9429e-04, -2.4388e-04,\n",
      "          1.4421e-04,  3.8407e-05, -5.8448e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1265)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 5 loss: 0.0005027640257859368\n",
      "tensor([[ 1.4488e-04, -3.6064e-04, -6.2230e-05, -2.6164e-04,  3.6542e-04,\n",
      "         -9.0116e-05, -1.7388e-04,  2.5028e-04],\n",
      "        [-3.0240e-04,  2.5947e-04,  2.5081e-04, -2.9438e-04, -6.7607e-05,\n",
      "         -1.4521e-04, -6.2537e-06, -6.2079e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1191)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 6 loss: 0.0005033759567530385\n",
      "tensor([[-3.0815e-04, -7.4429e-05,  3.3521e-04,  9.7895e-05,  1.1946e-04,\n",
      "         -4.3951e-04,  6.1061e-05, -3.1882e-04],\n",
      "        [-4.0921e-04, -1.6967e-04,  3.6752e-04, -8.9797e-06, -2.1466e-04,\n",
      "         -3.3089e-04,  7.0451e-05,  3.3135e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1274)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 7 loss: 0.0005034948953993384\n",
      "tensor([[ 3.1374e-04,  7.1213e-06,  1.6622e-04, -8.4258e-05,  3.3477e-04,\n",
      "         -2.8138e-04, -1.1706e-04,  2.6653e-04],\n",
      "        [ 4.0727e-04,  4.5344e-04, -9.9784e-05, -1.8887e-04,  3.0432e-04,\n",
      "         -6.1971e-07,  1.1107e-04,  2.0213e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1588)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 8 loss: 0.0005019124855374818\n",
      "tensor([[-3.5649e-05, -5.6240e-04, -4.8984e-04, -2.0958e-04, -1.1281e-05,\n",
      "          4.8741e-04, -3.7663e-04, -1.2406e-04],\n",
      "        [-4.5863e-05, -2.1373e-04, -2.2122e-06,  8.8906e-05, -4.8537e-04,\n",
      "          4.4869e-04, -3.7442e-04,  4.6518e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1227)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 9 loss: 0.0004991470365299952\n",
      "tensor([[ 2.4480e-04,  7.8640e-05, -3.2084e-04, -4.7079e-05, -3.9188e-04,\n",
      "          1.5360e-04, -4.5598e-04, -2.8908e-04],\n",
      "        [ 9.4297e-05,  3.5429e-04, -9.9915e-05,  1.1077e-04, -1.2775e-04,\n",
      "          1.6187e-04,  1.3650e-04, -1.4428e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1118)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 10 loss: 0.0005008306691641982\n",
      "tensor([[ 6.0516e-05, -3.1235e-04, -3.0137e-04,  3.9014e-04, -4.5320e-04,\n",
      "         -8.2964e-05, -3.4809e-05,  3.1931e-05],\n",
      "        [ 3.9305e-04, -5.0795e-04, -1.1156e-04,  3.7385e-04, -4.3575e-05,\n",
      "         -4.8864e-04,  6.4789e-05,  3.8209e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1064)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 11 loss: 0.0005019185855542293\n",
      "tensor([[ 2.0047e-05, -3.1587e-04, -6.1855e-04,  8.2285e-05, -5.4587e-04,\n",
      "          2.8195e-04, -6.9479e-04,  3.2117e-04],\n",
      "        [-5.9825e-04, -4.5574e-04,  3.2898e-04, -1.5982e-05, -3.9153e-04,\n",
      "         -1.7990e-04, -6.2432e-05,  1.8690e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1385)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 12 loss: 0.0005017914827265794\n",
      "tensor([[ 2.5290e-05, -4.1463e-04, -1.7903e-04, -4.9043e-05,  2.9801e-05,\n",
      "         -1.6014e-04, -3.1337e-04, -1.8828e-04],\n",
      "        [ 3.4772e-05, -6.0039e-04,  3.6682e-05,  2.0549e-04, -1.7374e-04,\n",
      "          1.6788e-04, -3.6804e-06, -1.0791e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.0967)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 13 loss: 0.000505463324766108\n",
      "tensor([[ 2.8492e-04,  1.0660e-05,  1.8353e-05,  1.5776e-04, -3.0242e-04,\n",
      "         -1.2936e-04, -1.9974e-04,  4.8110e-05],\n",
      "        [ 4.9284e-04,  2.0056e-04, -7.1735e-04,  6.4693e-05,  3.6378e-05,\n",
      "         -2.0041e-05, -7.8567e-04, -1.6665e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1089)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 14 loss: 0.0005044719653474307\n",
      "tensor([[ 7.4323e-05, -5.9846e-05,  5.9221e-05,  1.6125e-04,  6.2733e-04,\n",
      "         -1.7349e-04,  4.2704e-04, -1.0491e-04],\n",
      "        [-4.6493e-04, -5.3991e-05,  4.7949e-04, -1.1050e-04,  4.7797e-04,\n",
      "         -2.4973e-05,  4.5790e-04,  7.0309e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1141)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 15 loss: 0.0004973573509057553\n",
      "tensor([[-1.2351e-04,  3.8174e-04, -1.6868e-04, -5.9148e-04, -7.0087e-05,\n",
      "          8.5283e-05, -1.4559e-04, -3.3347e-04],\n",
      "        [ 7.6416e-05, -3.1151e-04,  2.3504e-04, -4.6241e-04, -3.1863e-04,\n",
      "         -4.1453e-04, -3.5670e-04, -4.5861e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1282)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 16 loss: 0.0004974733129072418\n",
      "tensor([[-1.3265e-04, -4.5466e-04, -4.7775e-04,  1.0556e-04, -4.7695e-05,\n",
      "          5.1238e-04, -3.1392e-04,  4.8986e-04],\n",
      "        [-3.0591e-04,  1.0045e-04,  4.8469e-05,  3.5090e-04,  2.4042e-04,\n",
      "          2.3399e-04,  3.7147e-04, -6.8932e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1070)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 17 loss: 0.0005022831009205989\n",
      "tensor([[ 1.2055e-04,  1.4220e-04, -2.4928e-05,  1.2982e-04,  6.7197e-04,\n",
      "          2.5654e-04,  1.4578e-04, -3.4448e-04],\n",
      "        [-3.5885e-04,  1.0895e-04,  1.8640e-04,  2.7836e-05,  3.0651e-04,\n",
      "         -2.7143e-04,  2.0457e-04,  2.4008e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1275)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 18 loss: 0.0005049651661447207\n",
      "tensor([[ 2.8698e-05, -2.4348e-05, -2.3720e-05, -1.4566e-04,  1.4456e-04,\n",
      "          6.4417e-04,  2.5780e-04,  2.5205e-04],\n",
      "        [-4.6490e-04, -3.6892e-04,  3.3996e-04,  5.6268e-05, -2.4332e-04,\n",
      "         -4.2875e-04, -1.0042e-04,  2.6083e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1823)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 19 loss: 0.0005000969605585771\n",
      "tensor([[-6.2800e-05, -2.3098e-04,  2.0668e-04,  4.4575e-05,  3.8964e-04,\n",
      "          6.0815e-05,  6.8018e-04, -9.8518e-05],\n",
      "        [-2.5287e-04,  8.4075e-05,  5.4009e-04, -2.4121e-04,  2.6960e-04,\n",
      "          1.1247e-04,  4.3149e-04, -9.8599e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1396)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 20 loss: 0.0004986638931347597\n",
      "tensor([[ 1.8193e-04,  4.6506e-05,  9.1575e-05, -5.0174e-05,  8.6854e-05,\n",
      "         -9.9734e-05, -1.2719e-04, -2.5071e-04],\n",
      "        [-3.3549e-04,  2.5048e-04, -1.7832e-04, -5.5736e-04,  2.2029e-04,\n",
      "          2.8273e-04,  1.4314e-04,  1.2915e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1089)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 21 loss: 0.0005030153913087296\n",
      "tensor([[ 2.1971e-04,  3.9151e-04,  8.8327e-05, -1.6518e-04,  5.1777e-06,\n",
      "         -1.2326e-04,  1.0017e-04, -2.6702e-04],\n",
      "        [ 9.5425e-05,  3.7048e-04,  2.4696e-04, -5.5387e-05,  1.1212e-04,\n",
      "         -9.1924e-05, -3.6146e-04, -1.5707e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1134)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 22 loss: 0.0004952258795719824\n",
      "tensor([[-4.5153e-04,  3.0788e-04,  3.6421e-04, -1.2662e-04,  3.4371e-04,\n",
      "          2.3386e-04,  3.3303e-04, -1.4511e-04],\n",
      "        [ 1.9318e-05,  2.7564e-04,  5.6112e-04,  2.7632e-04, -1.0984e-04,\n",
      "         -9.0011e-04,  3.5952e-04, -1.5284e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1212)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 23 loss: 0.0004989025460094957\n",
      "tensor([[ 2.7747e-04, -2.5689e-04, -6.1957e-05,  2.3584e-04, -1.1588e-04,\n",
      "         -1.4748e-04,  1.4987e-05, -9.4467e-05],\n",
      "        [ 3.0433e-04, -4.4092e-04,  5.0088e-04,  5.3958e-04, -8.4866e-04,\n",
      "         -4.3704e-04, -3.6323e-04, -1.5402e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1289)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 24 loss: 0.0005017938415976565\n",
      "tensor([[-3.5777e-04,  1.5086e-04, -3.2347e-05,  7.3804e-05,  2.1789e-04,\n",
      "          9.9903e-05,  2.6854e-04, -1.7981e-05],\n",
      "        [-2.1282e-04,  4.0959e-04,  2.0130e-04,  1.8577e-04,  1.1085e-04,\n",
      "         -1.8136e-04,  2.0253e-04, -2.5914e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1218)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 25 loss: 0.0004993828870606583\n",
      "tensor([[ 3.1762e-04, -1.2778e-05, -3.1951e-04,  7.2650e-06,  3.0731e-04,\n",
      "         -1.2080e-04,  1.1386e-04, -1.1920e-04],\n",
      "        [-3.9321e-04,  2.7721e-05, -4.2016e-05, -6.5603e-05,  2.1682e-04,\n",
      "         -2.4917e-04, -3.3235e-05,  1.0915e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1378)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 26 loss: 0.0004999854869067483\n",
      "tensor([[ 2.3026e-04, -2.9580e-04, -5.5546e-04,  8.0497e-04, -3.4042e-04,\n",
      "          1.6569e-04,  1.6865e-04, -1.5109e-04],\n",
      "        [ 5.6650e-05, -3.2014e-05, -2.9991e-04, -2.6217e-05, -2.3096e-04,\n",
      "         -2.0115e-05, -3.2125e-04,  6.1906e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1159)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 27 loss: 0.0004990302260499336\n",
      "tensor([[-2.0775e-04, -2.8889e-04, -1.5830e-04,  5.8264e-04, -4.5029e-04,\n",
      "          3.1336e-05,  2.4568e-04,  1.7253e-04],\n",
      "        [-2.7267e-04,  1.3400e-04,  2.4409e-04,  2.7599e-04,  2.7700e-04,\n",
      "          4.7671e-05,  6.6410e-04,  1.5349e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1242)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 28 loss: 0.0005013147223536051\n",
      "tensor([[-7.1272e-05, -3.5016e-04,  2.7931e-04,  1.7274e-04,  2.5851e-04,\n",
      "         -4.6153e-05,  4.4444e-04, -1.4580e-04],\n",
      "        [ 4.9649e-04, -4.3964e-04, -4.2788e-05,  2.2906e-04, -7.3628e-04,\n",
      "         -1.1186e-04,  5.3096e-05, -2.3700e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1129)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 29 loss: 0.0005014380231258925\n",
      "tensor([[-2.9122e-04,  4.3585e-04,  2.7048e-04, -2.6031e-04,  4.4799e-04,\n",
      "         -1.5343e-04,  2.4494e-04, -4.0556e-04],\n",
      "        [ 4.3283e-04,  3.3184e-04, -2.1151e-04,  4.7485e-04,  1.5146e-05,\n",
      "          1.8578e-04, -1.0979e-04, -3.4189e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1082)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 30 loss: 0.0004986682955881389\n",
      "tensor([[-6.3084e-04, -6.6061e-05,  5.9670e-04, -2.7322e-04, -3.5187e-04,\n",
      "         -3.2375e-04, -7.4435e-05, -9.9755e-05],\n",
      "        [ 3.3587e-04,  3.4588e-04, -1.8097e-04, -5.6714e-05,  5.2248e-04,\n",
      "         -1.9201e-04,  2.8858e-05, -6.3432e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1484)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 31 loss: 0.0005059438900355875\n",
      "tensor([[ 4.5095e-04, -3.1983e-05, -2.0084e-04,  1.5421e-04, -2.3685e-04,\n",
      "         -1.5274e-04, -1.5286e-05,  1.7492e-04],\n",
      "        [ 2.8540e-04, -1.1357e-04, -2.1968e-04, -3.5455e-04,  5.1807e-05,\n",
      "         -1.6148e-04, -1.8991e-04,  9.9636e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1041)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 32 loss: 0.0004977206398620167\n",
      "tensor([[-1.4571e-04,  1.3781e-04, -1.5827e-04, -2.8546e-04,  1.8509e-05,\n",
      "          3.8667e-04, -9.2935e-05,  4.3152e-04],\n",
      "        [-1.3792e-04,  2.7346e-05, -1.9049e-04, -2.1638e-04,  2.3655e-04,\n",
      "          1.3366e-04, -1.0631e-05,  2.1250e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1298)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 33 loss: 0.0004972322086350647\n",
      "tensor([[ 8.9438e-05,  8.9592e-06,  1.7187e-04, -3.7471e-08, -7.5936e-05,\n",
      "         -1.5994e-04,  3.7561e-04,  4.4162e-04],\n",
      "        [-2.0813e-04,  4.3763e-04,  1.9024e-04,  1.5030e-04, -6.8871e-05,\n",
      "          1.6409e-05,  5.9733e-04,  6.8090e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1235)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 34 loss: 0.0005015536201097973\n",
      "tensor([[ 3.6717e-04,  6.2731e-05, -3.2564e-05, -3.8630e-04,  1.4016e-04,\n",
      "         -3.8356e-04,  7.1620e-06, -1.6626e-04],\n",
      "        [-3.7662e-05,  7.6105e-05, -3.4660e-04, -2.4397e-04,  1.5752e-04,\n",
      "         -3.3111e-04, -3.3094e-04, -1.4096e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1315)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 35 loss: 0.0004989022599987242\n",
      "tensor([[-2.9681e-04, -3.0034e-04,  1.1103e-03, -8.7959e-05,  1.1549e-04,\n",
      "         -1.0888e-03,  4.1722e-04, -1.1639e-04],\n",
      "        [ 2.2328e-05,  1.8047e-05,  1.0801e-04, -2.0566e-04, -6.4829e-06,\n",
      "         -1.7635e-04, -2.0168e-04, -9.3808e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1099)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 36 loss: 0.0005013209299733117\n",
      "tensor([[-4.5924e-06,  1.6849e-04, -5.8431e-05, -1.8640e-04,  2.3286e-04,\n",
      "          2.4532e-04,  5.0533e-04,  1.9060e-04],\n",
      "        [-1.9513e-04,  6.6087e-04,  1.3471e-04, -4.7438e-04,  4.7720e-04,\n",
      "          3.4442e-04,  3.5146e-04,  7.4773e-06]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1231)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 37 loss: 0.0005001079124461693\n",
      "tensor([[-1.9895e-06,  1.8723e-04, -9.9679e-05,  1.0047e-05,  3.2050e-04,\n",
      "         -1.2582e-04,  2.8194e-04, -2.1784e-04],\n",
      "        [ 1.1922e-04, -1.8997e-04,  9.2221e-05,  6.5040e-05, -1.1458e-05,\n",
      "         -4.3161e-04,  3.6793e-04, -1.6769e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1218)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 38 loss: 0.0005044705193346996\n",
      "tensor([[ 3.7207e-04, -2.1489e-04,  3.3114e-04,  1.1249e-04, -2.4892e-04,\n",
      "         -4.8465e-04,  8.5515e-05, -2.6729e-04],\n",
      "        [ 1.3878e-04, -2.5526e-04,  2.7567e-04,  1.0016e-04,  1.8952e-04,\n",
      "         -3.7123e-04,  2.4941e-04,  1.7733e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1560)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 39 loss: 0.0004990221013947302\n",
      "tensor([[ 9.5151e-04, -1.4941e-04, -1.1892e-03, -3.0052e-04,  5.8435e-04,\n",
      "          2.5560e-05, -3.4380e-04,  9.2312e-05],\n",
      "        [ 2.1230e-04,  1.6229e-04, -2.7875e-04, -3.6020e-04,  5.6466e-04,\n",
      "         -1.0974e-04, -1.2711e-04, -3.8614e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1283)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 40 loss: 0.0004967547351529139\n",
      "tensor([[-4.4612e-04, -2.1165e-04,  6.9285e-04, -2.0652e-04, -4.1373e-04,\n",
      "         -5.7850e-04,  2.3127e-04, -3.2491e-04],\n",
      "        [-1.6924e-04, -9.2918e-06,  3.8303e-04, -5.5909e-04, -4.1238e-05,\n",
      "         -7.0135e-05,  2.4430e-04, -5.5338e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1105)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 41 loss: 0.0005028931665016921\n",
      "tensor([[-2.4636e-04, -3.0721e-04,  2.6686e-04, -1.6418e-04, -1.9789e-04,\n",
      "          1.0752e-04, -1.0340e-04,  1.9009e-05],\n",
      "        [ 3.0661e-05,  7.0529e-05, -2.8421e-05,  1.5271e-04,  1.4717e-04,\n",
      "          1.1549e-04,  1.5924e-06,  1.3122e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1191)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 42 loss: 0.0005035007837032291\n",
      "tensor([[-7.5023e-04, -2.6397e-04,  2.0850e-04, -1.2915e-04,  1.3047e-04,\n",
      "          5.6174e-04, -2.8748e-04,  9.8640e-05],\n",
      "        [-3.0146e-04,  4.8425e-05,  4.1079e-04, -1.0228e-04, -5.3311e-04,\n",
      "          1.9824e-04,  1.7461e-04, -1.7011e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1195)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 43 loss: 0.0004948695916780002\n",
      "tensor([[ 7.9125e-05, -3.2688e-04,  2.8992e-05, -7.3004e-05,  7.7604e-05,\n",
      "         -2.4494e-04, -9.2671e-06, -7.7638e-05],\n",
      "        [ 4.5111e-04, -4.9742e-04,  6.6153e-06, -8.6307e-05,  3.3535e-04,\n",
      "         -3.5167e-04, -1.1685e-04,  2.7426e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1575)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 44 loss: 0.000496869617038303\n",
      "tensor([[ 8.8955e-05,  1.9842e-04, -1.7707e-04,  3.6842e-04, -3.5435e-04,\n",
      "         -1.4457e-04,  1.0420e-04, -3.9506e-04],\n",
      "        [ 4.0947e-04, -1.6934e-04, -9.0491e-05,  4.4372e-04,  5.4244e-04,\n",
      "          2.6548e-05,  6.3930e-05, -1.1725e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1174)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 45 loss: 0.0005001071096900107\n",
      "tensor([[-1.0326e-04, -2.2234e-04,  7.6395e-04,  2.7848e-04, -3.2352e-04,\n",
      "         -2.9128e-04,  4.8253e-04, -3.1250e-04],\n",
      "        [-3.6278e-05,  2.8352e-04, -1.0403e-04,  1.0356e-04,  5.2926e-04,\n",
      "         -2.2044e-04,  2.6807e-04, -3.1729e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1215)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 46 loss: 0.0005003469740690465\n",
      "tensor([[ 1.7887e-04,  9.3921e-05, -4.2601e-04,  5.2112e-05,  6.3322e-05,\n",
      "          2.2669e-04,  2.0822e-04,  3.6083e-05],\n",
      "        [ 6.0138e-04, -1.7430e-04, -2.8664e-04, -7.2700e-05,  1.0044e-05,\n",
      "         -1.6536e-04, -1.9296e-04,  2.6036e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1726)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 47 loss: 0.0004999722446149059\n",
      "tensor([[-9.5873e-04, -2.0335e-04,  5.7031e-04, -1.7668e-04, -7.9452e-04,\n",
      "         -3.5804e-04,  2.4686e-05,  8.1141e-06],\n",
      "        [-2.6508e-04,  2.9350e-04,  2.3305e-04, -3.4430e-04, -3.7983e-04,\n",
      "         -1.4988e-04,  1.8144e-04, -1.0922e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1064)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 48 loss: 0.0004962911469270619\n",
      "tensor([[-1.0326e-05, -1.4551e-04,  8.1121e-05,  1.1261e-04, -2.2402e-04,\n",
      "         -3.7610e-04, -1.3529e-04,  1.1951e-04],\n",
      "        [ 7.4686e-04,  1.6915e-04, -6.7101e-04,  1.6776e-04,  1.4724e-04,\n",
      "          7.5237e-05, -3.0757e-04, -5.7832e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.0995)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 49 loss: 0.0005032661346590645\n",
      "tensor([[ 8.0098e-05,  2.6842e-04, -2.5457e-04, -5.8487e-04,  1.0175e-03,\n",
      "         -9.0549e-05,  2.4248e-04, -2.9092e-04],\n",
      "        [ 1.9902e-04,  1.7016e-04, -1.4451e-04, -1.3601e-04,  2.6488e-04,\n",
      "         -1.2616e-04, -2.6415e-04,  3.3794e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1221)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 50 loss: 0.0004999846843436063\n",
      "tensor([[ 0.0005, -0.0002, -0.0005, -0.0003, -0.0003,  0.0001, -0.0005,  0.0004],\n",
      "        [ 0.0006, -0.0003, -0.0005,  0.0004,  0.0004, -0.0007, -0.0002,  0.0002]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1122)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 51 loss: 0.0005005864954706448\n",
      "tensor([[-9.1928e-05, -9.3153e-05,  4.1659e-04, -4.3640e-04, -1.4497e-04,\n",
      "          5.8173e-05,  1.2579e-04,  1.1833e-04],\n",
      "        [-9.1886e-04,  3.9838e-05,  3.5594e-04, -4.5774e-05, -1.8248e-05,\n",
      "          2.6327e-04,  1.5670e-04,  5.9034e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1246)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 52 loss: 0.0004991402262057242\n",
      "tensor([[-4.3302e-04,  5.5725e-04,  5.1165e-04, -2.4109e-04,  4.0009e-04,\n",
      "         -1.1210e-04,  4.9215e-04, -4.9382e-04],\n",
      "        [-4.7620e-04, -9.5159e-06,  7.3306e-04, -1.0246e-04, -1.4453e-04,\n",
      "         -3.3705e-04,  6.1243e-04, -4.0981e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1139)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 53 loss: 0.0005005885616884704\n",
      "tensor([[ 3.6037e-05,  1.4003e-07,  4.5746e-04, -1.5133e-04,  1.0242e-03,\n",
      "         -6.4988e-04,  2.1220e-04, -1.0799e-05],\n",
      "        [ 6.4995e-04,  6.3079e-04, -6.2141e-04,  1.3480e-04,  3.7265e-04,\n",
      "         -8.7551e-05, -2.6059e-04, -2.3550e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1066)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 54 loss: 0.0005003546612898356\n",
      "tensor([[ 1.7810e-05,  6.0925e-05, -6.8474e-04, -3.2542e-05,  1.0841e-04,\n",
      "          9.0221e-04, -7.3307e-06,  3.1058e-04],\n",
      "        [-6.1612e-05,  5.8395e-05,  3.4059e-04, -1.9312e-04,  1.5248e-04,\n",
      "         -2.4159e-04,  3.4524e-05,  4.4629e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1126)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 55 loss: 0.0005011957908257084\n",
      "tensor([[-3.0671e-04, -3.8178e-05,  3.8561e-04, -2.9216e-04,  5.4779e-04,\n",
      "         -7.6818e-04,  7.5458e-05, -2.9880e-04],\n",
      "        [-3.5072e-04, -1.2743e-04,  3.0854e-04, -5.3881e-04,  1.1096e-04,\n",
      "         -6.6947e-04, -5.5429e-05,  2.7742e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1268)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 56 loss: 0.0005022794728117865\n",
      "tensor([[ 2.5240e-04, -1.0556e-04, -1.3018e-05,  3.0340e-04,  4.3045e-04,\n",
      "         -8.2379e-05,  1.0078e-04,  1.9778e-04],\n",
      "        [ 8.8475e-04,  2.6702e-05, -6.7101e-04, -2.6637e-04,  1.0766e-04,\n",
      "         -8.0136e-05, -3.7101e-04, -3.7162e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1309)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 57 loss: 0.0005032547676551722\n",
      "tensor([[-8.1696e-05,  1.3793e-06,  3.5792e-04, -4.4959e-05, -3.0894e-04,\n",
      "         -4.6304e-04,  2.4322e-04, -1.6364e-04],\n",
      "        [-3.1976e-04,  4.3953e-04,  1.2855e-05, -2.0959e-04, -1.4909e-05,\n",
      "          2.9012e-05,  1.8247e-05, -9.0578e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1007)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 58 loss: 0.0005007124280114361\n",
      "tensor([[-1.4851e-05, -3.6613e-04,  4.8625e-05,  1.5173e-04,  8.7505e-05,\n",
      "         -1.3553e-04, -2.7859e-04,  4.2161e-04],\n",
      "        [ 2.3776e-04, -2.4481e-04, -1.2809e-05,  6.4166e-04, -4.5798e-05,\n",
      "          3.0996e-04, -9.6311e-06,  3.2850e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1236)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 59 loss: 0.0004991479522038467\n",
      "tensor([[ 1.1509e-03,  4.4067e-04, -4.5575e-04,  3.2362e-04,  4.3226e-04,\n",
      "         -3.2392e-04,  2.2270e-06, -2.3982e-04],\n",
      "        [ 4.4569e-04,  2.9746e-04, -3.5809e-04,  1.8101e-04, -2.3530e-04,\n",
      "         -2.4412e-05,  3.2046e-04, -4.3422e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1215)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 60 loss: 0.0005004662468975631\n",
      "tensor([[-1.4444e-05, -2.8828e-04,  5.6029e-04,  4.8907e-04, -2.5775e-05,\n",
      "         -9.1946e-05,  4.7389e-04, -2.2561e-04],\n",
      "        [-5.5838e-05,  2.6081e-04,  1.8157e-04,  3.2433e-04, -2.0648e-04,\n",
      "         -2.1374e-04, -1.2688e-04,  2.0177e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1356)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 61 loss: 0.0005026467041834443\n",
      "tensor([[-8.0932e-07, -2.1033e-04,  1.2560e-04,  3.9375e-04, -4.1302e-04,\n",
      "         -1.6003e-04,  2.9612e-04, -1.4632e-04],\n",
      "        [ 4.1060e-04,  3.2661e-04, -2.9530e-05,  6.2046e-04,  7.1065e-05,\n",
      "         -4.6214e-04,  1.1250e-04, -4.8268e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1166)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 62 loss: 0.0005020461526831125\n",
      "tensor([[-3.2135e-04,  1.1746e-04,  1.2553e-04, -2.5548e-04, -1.9180e-04,\n",
      "          1.1624e-04, -3.6848e-04, -5.5886e-06],\n",
      "        [-2.2603e-04,  1.1086e-04, -2.3502e-04, -3.7798e-04, -4.6902e-04,\n",
      "          8.5917e-05, -6.1829e-04,  1.6031e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1440)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 63 loss: 0.0005023954685945734\n",
      "tensor([[-3.5793e-04,  5.0779e-04,  3.7995e-04, -2.4217e-04, -1.2610e-04,\n",
      "          3.7465e-04, -1.3149e-04, -5.2641e-04],\n",
      "        [-5.7008e-04,  1.3796e-06,  5.1477e-04, -2.4249e-04,  3.5728e-04,\n",
      "          2.1134e-05,  4.8076e-05, -1.9050e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1255)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 64 loss: 0.0005007107057486447\n",
      "tensor([[ 2.9760e-04, -4.7299e-05,  1.1113e-04, -1.3838e-05, -8.2588e-05,\n",
      "         -3.4963e-04, -2.3103e-04,  6.8837e-04],\n",
      "        [ 1.7694e-04,  2.6617e-04, -2.7157e-04, -5.1072e-04,  2.9199e-05,\n",
      "          1.0704e-04,  2.9540e-05,  1.1555e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1311)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 65 loss: 0.0004983064855799068\n",
      "tensor([[-4.1254e-04, -2.7116e-04,  2.1413e-04,  3.8167e-04, -3.2197e-04,\n",
      "         -1.9554e-04,  2.1467e-04,  7.4561e-05],\n",
      "        [ 9.0685e-05, -7.3203e-06,  1.7507e-04,  1.0615e-04, -1.5226e-04,\n",
      "         -2.3129e-04,  3.8227e-04,  6.7986e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1082)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 66 loss: 0.0004934694283824427\n",
      "tensor([[-3.6513e-04,  5.3691e-04,  3.8436e-04, -1.4401e-04, -3.1333e-04,\n",
      "          3.8115e-04,  4.6511e-04, -2.0506e-04],\n",
      "        [-2.6319e-04,  6.1843e-04,  7.8524e-05, -7.2576e-04,  8.3194e-05,\n",
      "          3.8591e-04,  5.3797e-04, -1.8358e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1310)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 67 loss: 0.000499871143927941\n",
      "tensor([[ 9.6281e-05,  2.4728e-04,  7.8638e-05, -2.0350e-04, -2.5326e-04,\n",
      "         -6.6492e-05, -1.9171e-04, -1.2679e-04],\n",
      "        [ 4.0387e-04,  3.9855e-04, -3.5069e-04,  2.3886e-04, -8.8776e-05,\n",
      "          2.8780e-04, -8.3703e-05, -7.8862e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1293)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 68 loss: 0.0004998671893890088\n",
      "tensor([[-4.0653e-04, -1.7902e-04,  1.2002e-04,  1.9591e-04,  1.2514e-04,\n",
      "         -1.7324e-04,  7.1303e-06,  1.3675e-04],\n",
      "        [-2.0289e-05, -4.3548e-04,  8.9497e-05,  8.1664e-05, -3.8901e-04,\n",
      "         -2.4952e-04, -3.0346e-04, -2.6260e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1466)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 69 loss: 0.0004973521046705777\n",
      "tensor([[-1.5875e-04,  3.3073e-05,  9.6052e-05,  3.7297e-05, -2.0713e-04,\n",
      "         -3.6117e-04,  1.7380e-04, -5.3841e-04],\n",
      "        [ 6.2144e-05, -1.4724e-04, -3.3900e-04,  2.9349e-04, -2.0551e-04,\n",
      "          2.1458e-04, -1.1385e-04, -8.8010e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1200)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 70 loss: 0.0004998702269334059\n",
      "tensor([[ 4.4166e-04, -4.2598e-04, -1.4791e-04, -5.0715e-05, -3.3520e-05,\n",
      "         -3.7489e-04, -2.5798e-04, -1.4793e-04],\n",
      "        [ 1.0388e-04, -8.0168e-06,  9.7239e-05,  4.5019e-05, -2.8594e-04,\n",
      "          1.3704e-04, -8.1803e-05,  1.8413e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1440)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 71 loss: 0.0004980685753736667\n",
      "tensor([[ 3.6958e-05, -9.3831e-05, -1.6150e-04, -1.5882e-04,  6.1873e-05,\n",
      "          3.4011e-05, -1.9367e-04, -3.6331e-05],\n",
      "        [-1.2630e-04, -1.7118e-04,  3.0080e-05, -5.0076e-04, -2.0582e-05,\n",
      "          1.5750e-04, -5.3154e-04,  3.9697e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1530)\n",
      "tensor(2.0794, grad_fn=<NllLossBackward0>)\n",
      "  batch 72 loss: 0.0004947454963954551\n",
      "tensor([[-3.6108e-04, -3.6805e-04,  2.9215e-04, -2.0021e-04,  1.1579e-04,\n",
      "          2.1060e-05,  5.2344e-04,  2.5488e-05],\n",
      "        [ 4.0275e-05,  3.0413e-04, -1.8701e-04, -4.5371e-04, -2.6369e-04,\n",
      "          3.4960e-04, -2.2646e-04, -5.5170e-05]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.0997)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 73 loss: 0.0005030131420768512\n",
      "tensor([[ 4.5952e-04, -1.7112e-05,  8.2917e-05, -1.9809e-04, -2.5858e-04,\n",
      "         -6.8785e-04, -9.1551e-05, -2.3148e-04],\n",
      "        [-1.0078e-04,  3.3201e-04,  3.5124e-04, -4.7850e-05, -2.6926e-04,\n",
      "         -3.4225e-04,  2.6468e-04, -2.1204e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1252)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 74 loss: 0.0005065652542950611\n",
      "tensor([[ 2.8109e-05,  4.1126e-04,  8.7536e-05, -3.6672e-04,  8.9821e-05,\n",
      "          5.5409e-04, -2.2476e-04, -1.6125e-04],\n",
      "        [-1.0022e-04,  5.4602e-04,  2.6325e-04, -1.6966e-04,  2.2583e-04,\n",
      "         -5.3675e-04,  2.3569e-04, -3.6650e-04]], grad_fn=<SliceBackward0>)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "tensor(0.1080)\n",
      "tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
      "  batch 75 loss: 0.0005003519076585081\n"
     ]
    }
   ],
   "source": [
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "# writer = SummaryWriter('runs/fashion_trainer_{}'.format(timestamp))\n",
    "epoch_number = 0\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('EPOCH {}:'.format(epoch_number + 1))\n",
    "\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch(epoch_number)\n",
    "\n",
    "    # We don't need gradients on to do reporting\n",
    "    model.train(False)\n",
    "\n",
    "#     running_vloss = 0.0\n",
    "#     for i, vdata in enumerate(validation_loader):\n",
    "#         vinputs, vlabels = vdata\n",
    "#         voutputs = model(vinputs)\n",
    "#         vloss = loss_fn(voutputs, vlabels)\n",
    "#         running_vloss += vloss\n",
    "\n",
    "#     avg_vloss = running_vloss / (i + 1)\n",
    "#     print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "\n",
    "    # Log the running loss averaged per batch\n",
    "    # for both training and validation\n",
    "    # writer.add_scalars('Training vs. Validation Loss',\n",
    "    #                 { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "    #                 epoch_number + 1)\n",
    "    # writer.flush()\n",
    "\n",
    "    # Track best performance, and save the model's state\n",
    "    # if avg_vloss < best_vloss:\n",
    "    #     best_vloss = avg_vloss\n",
    "    #     model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n",
    "    #     torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4d2690-9ac0-4779-9a0d-0200660fd239",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf463e6-5b59-4a00-aebe-4b324cf0130d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.from_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "18d82f31-b0b4-45f1-bb16-2fbc934ec965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'torch.LongTensor'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'torch.LongTensor'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.conv1.weight.long().type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "a886c563-1b7f-45d3-a163-2cafb4e9dcd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 60000 instances\n",
      "Validation set has 10000 instances\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# PyTorch TensorBoard support\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Create datasets for training & validation, download if necessary\n",
    "training_set = torchvision.datasets.FashionMNIST('./data', train=True, transform=transform, download=True)\n",
    "validation_set = torchvision.datasets.FashionMNIST('./data', train=False, transform=transform, download=True)\n",
    "\n",
    "# Create data loaders for our datasets; shuffle for training, not for validation\n",
    "training_loader = torch.utils.data.DataLoader(training_set, batch_size=4, shuffle=True, num_workers=2)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=4, shuffle=False, num_workers=2)\n",
    "\n",
    "# Class labels\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
    "\n",
    "# Report split sizes\n",
    "print('Training set has {} instances'.format(len(training_set)))\n",
    "print('Validation set has {} instances'.format(len(validation_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "92f0ab37-f36a-40b5-b1c2-f103893d37f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dress  T-shirt/top  Coat  T-shirt/top\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Helper function for inline image display\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "dataiter = iter(training_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Create a grid from the images and show them\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "matplotlib_imshow(img_grid, one_channel=True)\n",
    "print('  '.join(classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "2851c9b4-cce1-4e0f-aa23-e328583587d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'torch.FloatTensor'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'torch.FloatTensor'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels.type(torch.float).type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7b967e47-1fdf-4aea-b29a-c5d380bffcb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.tensor([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67b21d5-4b59-4f38-b4d3-de6fdf0ce2a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kedro (decoding_pipeline)",
   "language": "python",
   "name": "kedro_decoding_pipeline"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
